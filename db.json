{"meta":{"version":1,"warehouse":"6.0.0"},"models":{"Asset":[{"_id":"source/images/箱线图.png","path":"images/箱线图.png","modified":0,"renderable":0},{"_id":"source/images/Z_table.png","path":"images/Z_table.png","modified":0,"renderable":0},{"_id":"node_modules/hexo-theme-landscape/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-landscape/source/js/jquery-3.6.4.min.js","path":"js/jquery-3.6.4.min.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-landscape/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-landscape/source/fancybox/jquery.fancybox.min.css","path":"fancybox/jquery.fancybox.min.css","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-landscape/source/fancybox/jquery.fancybox.min.js","path":"fancybox/jquery.fancybox.min.js","modified":0,"renderable":1},{"_id":"node_modules/hexo-theme-landscape/source/css/images/banner.jpg","path":"css/images/banner.jpg","modified":0,"renderable":1}],"Cache":[{"_id":"source/images/箱线图.png","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1763494757085},{"_id":"source/images/Z_table.png","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1763494757070},{"_id":"source/_posts/2025-10-13.md","hash":"896149355268a36c7b65c5dcce7eb7372c53f1a0","modified":1763494757124},{"_id":"source/_posts/2025-10-15.md","hash":"2a529b15b585a1650d167755efe1b818cd156d5e","modified":1763494757122},{"_id":"source/_posts/2025-10-17.md","hash":"fda57669e98ae909c0f5fa8ccdeb2c121d321d17","modified":1763494757120},{"_id":"source/_posts/2025-10-28.md","hash":"7ecf243fe2c7d61e280bd510d3410f4c5a73ff72","modified":1763494757115},{"_id":"source/_posts/2025-11-11.md","hash":"8fac0f9ac64ff93f551c4c1667bc3f03b938158f","modified":1763494757107},{"_id":"source/_posts/2025-11-18.md","hash":"d9d2cebc23cdf781f66ca7ab50d364c847f6eb8e","modified":1763494757104},{"_id":"source/_posts/2025-10-20.md","hash":"221eb2d15cc9d00911d180a2e67aa112e7783479","modified":1763494757117},{"_id":"source/_posts/2025-10-31.md","hash":"8fbce7d171ea167fd3e32cbb147a40542d0130e0","modified":1763494757108},{"_id":"source/_posts/2025-10-30.md","hash":"762983a4ce4040ff6935b667a5f70f6626f533f1","modified":1763494757110},{"_id":"source/_posts/2025-11-2.md","hash":"c586e20eb1ca0b5c82234baeb7337ca8723b0ee4","modified":1763494757151},{"_id":"source/_posts/2025-11-5.md","hash":"89da2d9fee9ffbb398f8620c1c2b7f8df4de23e7","modified":1763494757147},{"_id":"source/_posts/2025-10-29.md","hash":"c2741220c1a09b6a09899c4dd5d4e8c40ff003dd","modified":1763494757112},{"_id":"source/_posts/2025-11-3.md","hash":"62d6224d05ff1ca190d1ab0d35da7142cff6071e","modified":1763494757149},{"_id":"source/_posts/2025-11-6.md","hash":"c0888411d133ac90983e8ce714e11bdb58b1524c","modified":1763494757145},{"_id":"source/_posts/2025-9-10.md","hash":"d753c8fec007b7537cd10e7899b31baeb890e263","modified":1763494757141},{"_id":"source/_posts/2025-11-7.md","hash":"9eb4ed3ff30e9a16ee116b85fa24690500924a50","modified":1763494757143},{"_id":"source/_posts/2025-9-15.md","hash":"13bf29835382a953a45f286155fc25969e19d2ad","modified":1763494757137},{"_id":"source/_posts/2025-9-22.md","hash":"d3561e66b2ec8282512a9a640c241e8013082264","modified":1763494757132},{"_id":"source/_posts/2025-9-16.md","hash":"382f31411e06affeb6e034a1a848a93ed2ee92ac","modified":1763494757135},{"_id":"source/_posts/2025-9-11.md","hash":"2480017e6b5399ffd1d5ddd1b88dc99a2a458f69","modified":1763494757139},{"_id":"source/_posts/2025-9-24.md","hash":"657ea9d88ab30f7f198d5cf22325fe97f9a3a5a4","modified":1763494757126},{"_id":"source/_posts/Game-On.md","hash":"b974f08790b6364a0a8fa9fa0b50542554fb73d6","modified":1763494757152},{"_id":"source/_posts/2025-9-23.md","hash":"aa31c996bce1b1bd68f3fee79a124476521cac2c","modified":1763494757130},{"_id":"source/_posts/hello-world.md","hash":"acad91ace80b80295b11a9b7ad4c29a2dcfdd8fb","modified":1763494757099},{"_id":"source/_posts/img.png","hash":"80532c9114af5660c58e075527b845b16932c07c","modified":1763494757157},{"_id":"source/_posts/img_1.png","hash":"80532c9114af5660c58e075527b845b16932c07c","modified":1763494757156},{"_id":"source/_posts/img_2.png","hash":"7aca48ac529c6e7ac70c00ca1de00cfc7f0ccdda","modified":1763494757154},{"_id":"node_modules/hexo-theme-landscape/LICENSE","hash":"c480fce396b23997ee23cc535518ffaaf7f458f8","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/README.md","hash":"6497b70356271fd6f9f1dc862353be844c457a53","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/index.ejs","hash":"57281fc3812c877ec2d8e89ec87ede57b9789d4c","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/archive.ejs","hash":"97160b8111dd0283f8231408bcab4c87d31c1646","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/category.ejs","hash":"97160b8111dd0283f8231408bcab4c87d31c1646","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/_config.yml","hash":"a93d7b3990e45bc7247eecf01888f71674887a63","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/layout.ejs","hash":"0d1765036e4874500e68256fedb7470e96eeb6ee","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/package.json","hash":"06889bee30e4c39479467021da434d3a6a0990fc","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/scripts/fancybox.js","hash":"c857d7a5e4a5d71c743a009c5932bf84229db428","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/tag.ejs","hash":"97160b8111dd0283f8231408bcab4c87d31c1646","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/default.yml","hash":"ea5e6aee4cb14510793ac4593a3bddffe23e530c","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/en-GB.yml","hash":"ea5e6aee4cb14510793ac4593a3bddffe23e530c","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/de.yml","hash":"3ebf0775abbee928c8d7bda943c191d166ded0d3","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/fr-FR.yml","hash":"8d09dbdab00a30a2870b56f7c0a7ca7deafa7b88","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/en-US.yml","hash":"ea5e6aee4cb14510793ac4593a3bddffe23e530c","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/es.yml","hash":"76edb1171b86532ef12cfd15f5f2c1ac3949f061","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/de-DE.yml","hash":"d29d1c4256b7ed9df42f511c2ff0a23ad5fd6c1f","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/en.yml","hash":"3083f319b352d21d80fc5e20113ddf27889c9d11","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/it-IT.yml","hash":"2cb6dc2fab9bd2dbe1c8bb869a9e8bf85a564fdd","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/fr.yml","hash":"415e1c580ced8e4ce20b3b0aeedc3610341c76fb","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/ja-JP.yml","hash":"08481267e0c112e1f6855620f2837ec4c4a98bbd","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/hu.yml","hash":"284d557130bf54a74e7dcef9d42096130e4d9550","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/ko.yml","hash":"881d6a0a101706e0452af81c580218e0bfddd9cf","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/it.yml","hash":"89b7d91306b2c1a0f3ac023b657bf974f798a1e8","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/hu-HU.yml","hash":"712d18664898fa21ba38d4973e90ef41a324ea25","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/es-ES.yml","hash":"7008a8fc91f18d2a735864817b8ebda30c7a2c66","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/mn-MN.yml","hash":"b9e5f3e7c0c2f779cf2cfded6db847b5941637ca","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/ja.yml","hash":"a73e1b9c80fd6e930e2628b393bfe3fb716a21a9","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/mn.yml","hash":"2e7523951072a9403ead3840ad823edd1084c116","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/nl-NL.yml","hash":"5ebbc30021f05d99938f96dfff280392df7f91f0","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/pt-PT.yml","hash":"0f852b6b228e6ea59aa3540574bb89b233f2a098","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/pt.yml","hash":"57d07b75d434fbfc33b0ddb543021cb5f53318a8","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/ru-RU.yml","hash":"360d11a28bb768afb1dd15f63fa7fd3a8cc547ee","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/ko-KR.yml","hash":"19209ad8f9d4057e8df808937f950eb265e1db69","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/tr.yml","hash":"a1cdbfa17682d7a971de8ab8588bf57c74224b5b","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/zh-CN.yml","hash":"1efd95774f401c80193eac6ee3f1794bfe93dc5a","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/th.yml","hash":"84a55b00aa01f03982be294e43c33a20e6d32862","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/zh-TW.yml","hash":"53ce3000c5f767759c7d2c4efcaa9049788599c3","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/after-footer.ejs","hash":"1b89d0caba03a66a43d9c290a5e94fa438a89210","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/archive.ejs","hash":"0039146b8ccbdf9b9f8bee58fc6c238f0e9921fc","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/languages/th-TH.yml","hash":"ebfdba9bc4842c829473c1e6e4544344f182724d","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/article.ejs","hash":"e9d4678e14be5e3cd5e34d783e5af6d6626092f5","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/google-analytics.ejs","hash":"2ea7442ea1e1a8ab4e41e26c563f58413b59a3d0","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/archive-post.ejs","hash":"c7a71425a946d05414c069ec91811b5c09a92c47","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/mobile-nav.ejs","hash":"e952a532dfc583930a666b9d4479c32d4a84b44e","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/head.ejs","hash":"0e94f5722d4c44d3cc91be2f4fd30b9ab503b868","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/footer.ejs","hash":"3656eb692254346671abc03cb3ba1459829e0dce","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/gauges-analytics.ejs","hash":"21a1e2a3907d1a3dad1cd0ab855fe6735f233c74","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_widget/archive.ejs","hash":"beb4a86fcc82a9bdda9289b59db5a1988918bec3","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_widget/category.ejs","hash":"dd1e5af3c6af3f5d6c85dfd5ca1766faed6a0b05","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/header.ejs","hash":"6a5033d189554c9a6d42e2ef7952ae5c9742648e","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_widget/tag.ejs","hash":"2de380865df9ab5f577f7d3bcadf44261eb5faae","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/sidebar.ejs","hash":"930da35cc2d447a92e5ee8f835735e6fd2232469","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_widget/recent_posts.ejs","hash":"60c4b012dcc656438ff59997e60367e5a21ab746","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/css/_variables.styl","hash":"ca28281423ae57d76b6c1eb91cd845fd4e518bd6","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_widget/tagcloud.ejs","hash":"b4a2079101643f63993dcdb32925c9b071763b46","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/css/style.styl","hash":"e55a1d92954ed20f6887f92dc727bb995a010a43","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/css/_extend.styl","hash":"222fbe6d222531d61c1ef0f868c90f747b1c2ced","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/js/script.js","hash":"49773efcb2221bbdf2d86f3f5c5ff2d841b528cc","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/post/gallery.ejs","hash":"3d9d81a3c693ff2378ef06ddb6810254e509de5b","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/fancybox/jquery.fancybox.min.css","hash":"1be9b79be02a1cfc5d96c4a5e0feb8f472babd95","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/post/category.ejs","hash":"c6bcd0e04271ffca81da25bcff5adf3d46f02fc0","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/post/nav.ejs","hash":"16a904de7bceccbb36b4267565f2215704db2880","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/highlight.styl","hash":"9cc3b2927d814f2f6e8e188f9d3657b94f4c6ef3","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/post/date.ejs","hash":"f1458584b679545830b75bef2526e2f3eb931045","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/post/tag.ejs","hash":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/article.styl","hash":"f608400a08cf137ab15ec1f44bac551950afe879","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/archive.styl","hash":"db15f5677dc68f1730e82190bab69c24611ca292","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/comment.styl","hash":"79d280d8d203abb3bd933ca9b8e38c78ec684987","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/layout/_partial/post/title.ejs","hash":"4d7e62574ddf46de9b41605fe3140d77b5ddb26d","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/header.styl","hash":"268d2989acb06e2ddd06cc36a6918c6cd865476b","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/mobile.styl","hash":"a399cf9e1e1cec3e4269066e2948d7ae5854d745","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/footer.styl","hash":"e35a060b8512031048919709a8e7b1ec0e40bc1b","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/sidebar-bottom.styl","hash":"8fd4f30d319542babfd31f087ddbac550f000a8a","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/sidebar.styl","hash":"404ec059dc674a48b9ab89cd83f258dec4dcb24d","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/css/_util/grid.styl","hash":"0bf55ee5d09f193e249083602ac5fcdb1e571aed","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/css/_util/mixin.styl","hash":"44f32767d9fd3c1c08a60d91f181ee53c8f0dbb3","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/css/_partial/sidebar-aside.styl","hash":"890349df5145abf46ce7712010c89237900b3713","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/js/jquery-3.6.4.min.js","hash":"eda46747c71d38a880bee44f9a439c3858bb8f99","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/fancybox/jquery.fancybox.min.js","hash":"6181412e73966696d08e1e5b1243a572d0f22ba6","modified":1763494982067},{"_id":"node_modules/hexo-theme-landscape/source/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1763494982067},{"_id":"public/2025/11/20/hello-world/index.html","hash":"9bc26349bbcc6facdfe8151c73bde3548a76e1ab","modified":1763590430242},{"_id":"public/2025/11/18/2025-11-18/index.html","hash":"1cfd64ed2dcecc5e09a722d10a6987f421d714d1","modified":1763590430242},{"_id":"public/2025/11/11/2025-11-11/index.html","hash":"c6fadf39a96fdba0214353ceab05801347961867","modified":1763590430242},{"_id":"public/2025/11/07/2025-11-7/index.html","hash":"2b3118495d38ce69a3d90f50e27cb7c61e09a87e","modified":1763590430242},{"_id":"public/2025/11/06/2025-11-6/index.html","hash":"0b7286430aed772cdd6ce44f6c1fe70bb68739be","modified":1763590430242},{"_id":"public/2025/11/03/2025-11-3/index.html","hash":"5cf04d3739136a81fe6f049f49693165a5b18624","modified":1763590430242},{"_id":"public/2025/11/05/2025-11-5/index.html","hash":"664a54fac8b3cce3f6e138ca6edb4e105a39b3eb","modified":1763590430242},{"_id":"public/2025/11/02/2025-11-2/index.html","hash":"6a58a3a806dc39c839737eeaed6e32cee1325858","modified":1763590430242},{"_id":"public/2025/10/31/2025-10-31/index.html","hash":"3b3c8be678bf2c329d7514694a2fa8846b97330a","modified":1763590430242},{"_id":"public/2025/10/30/2025-10-30/index.html","hash":"2a7779aa19d3b98152fd87ae28fd2d798d24b58e","modified":1763590430242},{"_id":"public/2025/10/29/2025-10-29/index.html","hash":"cfd3acaa664fd9ae7bd35ee53583716183ff6ebe","modified":1763590430242},{"_id":"public/2025/10/28/2025-10-28/index.html","hash":"69f27d8b73fbdea3e23ade5f6e89e2a9a5115472","modified":1763590430242},{"_id":"public/2025/10/20/2025-10-20/index.html","hash":"de020a081ca569c3bcf6b78d18c04cf051dc31f6","modified":1763590430242},{"_id":"public/2025/10/17/2025-10-17/index.html","hash":"e7cd8f9e4f358100c9f77758ecb21436f5647fac","modified":1763590430242},{"_id":"public/2025/10/15/2025-10-15/index.html","hash":"43d87eb7b949e8e9af02e9bf30497483697c2db8","modified":1763590430242},{"_id":"public/2025/10/13/2025-10-13/index.html","hash":"339ae2c0191ed18c59b0ccd66ed2070072d45dea","modified":1763590430242},{"_id":"public/2025/09/24/2025-9-24/index.html","hash":"1a97ad6c305fae1544932c78cf2cca793b68b940","modified":1763590430242},{"_id":"public/2025/09/23/2025-9-23/index.html","hash":"c7932499788272ca4f00c8e5ce24982d0ac01f63","modified":1763590430242},{"_id":"public/2025/09/22/2025-9-22/index.html","hash":"7fcce925a3d12a76900be9804f948a56415549d9","modified":1763590430242},{"_id":"public/2025/09/16/2025-9-16/index.html","hash":"fb0c9e93b159d87cfa5e6c49877bdd05fa558ab1","modified":1763590430242},{"_id":"public/2025/09/15/2025-9-15/index.html","hash":"eea8ba4c1538b05cf86ecd479ad1994e0d0a2d75","modified":1763590430242},{"_id":"public/2025/09/11/2025-9-11/index.html","hash":"279527769de80fcb1d9d991a400a458e5d6c3c7a","modified":1763590430242},{"_id":"public/2025/09/10/2025-9-10/index.html","hash":"5199e63c2c1c699b7386581231725a1f681941ef","modified":1763590430242},{"_id":"public/2025/09/10/Game-On/index.html","hash":"58026d61a1eb334d0d55bdd8f212ce1647e17931","modified":1763590430242},{"_id":"public/archives/index.html","hash":"9f98a0233d95f24c0c5a0c76bd468c0c1334950f","modified":1763590430242},{"_id":"public/archives/page/2/index.html","hash":"b10c7eb025c50c337bdba5ffaea9865b01143bf9","modified":1763590430242},{"_id":"public/archives/2025/index.html","hash":"40fcd04200bbe451f0d9ca6e5371e7cf69759c19","modified":1763590430242},{"_id":"public/archives/page/3/index.html","hash":"6d94f0ce916fdcef37bf4cb23c0306ab406a15e7","modified":1763590430242},{"_id":"public/archives/2025/page/2/index.html","hash":"2161f82bef9b2ad7301b3edd5bf4d95ac2c71f48","modified":1763590430242},{"_id":"public/archives/2025/page/3/index.html","hash":"92fbe8fd92b5f6f13aab50a55681e04f0950c97c","modified":1763590430242},{"_id":"public/archives/2025/09/index.html","hash":"fc704f1e140089437d753a87c98b6364bfa863bf","modified":1763590430242},{"_id":"public/index.html","hash":"108626311f3e5ee65d3ed6ecf5c5b5026569e770","modified":1763590430242},{"_id":"public/archives/2025/10/index.html","hash":"fd59054594745669328206942f9992675b9920b6","modified":1763590430242},{"_id":"public/archives/2025/11/index.html","hash":"2f70548496893e742c6f8897500fdfc133d44cfe","modified":1763590430242},{"_id":"public/page/2/index.html","hash":"1605ad28787652f196d666d6f0a19694497d867b","modified":1763590430242},{"_id":"public/page/3/index.html","hash":"5e45227b92d2c149278820be460d75c222cf4695","modified":1763590430242},{"_id":"public/images/箱线图.png","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1763590430242},{"_id":"public/images/Z_table.png","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1763590430242},{"_id":"public/css/style.css","hash":"ecc329be740a220cc188ff49b02da4847cb7ee5e","modified":1763590430242},{"_id":"public/fancybox/jquery.fancybox.min.css","hash":"1be9b79be02a1cfc5d96c4a5e0feb8f472babd95","modified":1763590430242},{"_id":"public/js/script.js","hash":"49773efcb2221bbdf2d86f3f5c5ff2d841b528cc","modified":1763590430242},{"_id":"public/fancybox/jquery.fancybox.min.js","hash":"6181412e73966696d08e1e5b1243a572d0f22ba6","modified":1763590430242},{"_id":"public/js/jquery-3.6.4.min.js","hash":"eda46747c71d38a880bee44f9a439c3858bb8f99","modified":1763590430242},{"_id":"public/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1763590430242}],"Category":[],"Data":[],"Page":[],"Post":[{"title":"2025.10.17","date":"2025-10-17T00:47:31.000Z","_content":"# Overview\n1. 今日学习笔记\n2. 句子摘录\n3. 昨天和今天的总结\n\n\n## 学习笔记\n### 概率\n1. 随机变量（Random Variables）\n   1. Definition：设样本空间为 Ω，随机变量 X 是定义在 Ω 上、取值于实数集ℝ的函数，即X: Ω→R，X(ω) 表示对样本点 ω 的赋值\n   2. Example：掷骰子（Ω={1,2,3,4,5,6}），X(1-3)=1（赢1元），X(4-6)=-1（输1元），刻画玩家收益\n   3. 概率表示：事件 “X 取 x 值” 即 {ω∈Ω | X(ω)=x}，概率简化记为P(X=x)，且所有可能取值概率和为 1（∑P (X=x)=1）\n2. 离散型随机变量及其分布（Discrete Random Variables and Distributions）\n   1. Definition：取值为有限个或可列个，且每个取值有其概率，不可能的取值的概率为0.\n   2. 概率质量函数（probability mass function (pmf)）：f(x)满足：\n      1. f(x)≥0\n      2. ∑f (x)=1（所有可能 x 求和）\n   3. 分布函数（distribution function）：F(x)=P(X≤x)=∑(x_j≤x) f(x_j)，其具有性质：\n      1. lim(x→-∞)F(x)=0\n      2. lim(x→+∞)F(x)=1\n      3. 非递减\n      4. 0≤F(x)≤1\n   4. 离散型随机变量的平均数或期望（mean or expectation or expected value）：μ = E[X] = ∑_j x_j f(x_j), j = 1,2,...,n（f是X的pmf，x_j是X的可能取值）\n      1. 进一步推导出：E[g(X)] = ∑_j g(x_j) f(x_j), j = 1,2,...,n\n   5. 离散型随机变量的方差（variance）：σ^2 = Var(X) = E[(X - E(X))^2] = ∑_j (x_j - E(X))^2 f(j_x)\n      1. 方差提供𝑋围绕其均值E𝑋的离散程度的度量，其总是非负的\n      2. 标准差（standard deviation）：σ = √Var(X)\n   6. 均值和方差的性质：\n      1. 设𝑋为随机变量，我们考虑𝑋的线性函数：𝑌 = 𝑎𝑋 + b，a,b ∈ R 其具有性质：\n         1. E(Y) = aE(X) + b\n         2. Var(Y) = a^2Var(X)\n      2. 可以用以下公式表示随机变量𝑋的方差:` Var(X) = E(X^2) - E(X)^2`\n   7. 伯努利分布（Bernoulli Distribution）：\n      1. Definition：随机变量X只能取值1或0，其概率分别为 p ∈ (0,1)，q(:= 1-p)\n      2. 可能取值：1,2\n      3. pmf：P(X=1) = p，P(X=0) = 1-p\n      4. E (X)：p\n      5. Var (X)：p(1-p)\n   8. 二项分布（Binomial Distribution）：𝑋 ∼ Bin(n,p)，n∈ℕ, p∈(0,1))\n      1. Definition：n次独立试验中成功次数的离散概率分布，每个试验的成功概率为𝑝\n      2. 可能取值：0,1,…,n\n      3. pmf：P(X=k) = C(n,k) p^k (1-p)^(n-k)\t （`C(n,k) = n! / k! (n-k)!`）\n      4. E (X)：np\n      5. Var (X)：np(1-p)\n   9. 泊松分布（Poisson Distribution）：𝑋 ∼ Poi(λ)，λ>0\n      1. Definition：泊松分布是一种离散概率分布，用于计算在固定时间或空间间隔内，以**已知平均发生率**且独立于上次事件发生时间的事件发生次数的概率。\n      2. 可能取值：0,1,2,…\n      3. pmf：P(X=k) = e^(-λ) λ^k / k!\n      4. E (X)：λ\n      5. Var (X)：λ\n      6. 注意：问题中给出的速率可能不是所需区间内的𝜆值！我们需要对其进行放大或缩小，以获得正确的𝜆值。（如给了一周的速率为𝜆，要计算两周的间隔则速率为2𝜆）\n   10. 几何分布（Geometric Distribution）：𝑋 ∼ Geo(p)，p∈(0,1)\n       1. Definition：经过X次试验才得到成功的结果\n       2. 可能取值：1,2,3,…（不能为0）\n       3. pmf：P(X=k) = p (1-p)^(k-1)\n       4. E (X)：1/p\n       5. Var (X)：(1-p)/p²\n3. 连续型随机变量及其分布（Continuous Random Variables and Distributions）\n    1. Definition：取值能充满某个区间（或多个区间），且其取任何单个特定值的概率均为 0 的随机变量\n    2. 概率密度函数（probability density function（pdf））：f(x)满足：\n       1. f(x)≥0\n       2. ∫(-∞到+∞) f(x) dx = 1\n    3. 分布函数（Distribution Function）：F(x) = P(X≤x) = ∫(-∞到 x) f(t) dt，具有性质：\n       1. lim(x→-∞)F(x)=0\n       2. lim(x→+∞)F(x)=1\n       3. 𝐹可微（因此连续），是非递减函数\n       4. 0 ≤ 𝐹(x)≤ 1\n       5.  f(x) = F’(x)\n    4. 连续随机变量的均值(Mean of Continuous Random Variable)：μ = E[x] = ∫(-∞到+∞) xf(x) dx ，（f(x)是pdf）\n       1. 进一步推导出：E[g(X)] = ∫(-∞到+∞) g(x)f(x) dx\n    5. 连续随机变量的方差(Variance of Continuous Random Variable)：σ^2 = Var(X) = E[(X - E(X))^2] = ∫(-∞到+∞) (x - E(X))^2 f(x) dx\n    6. 均值和方差的性质：\n       1. 设𝑋为随机变量，我们考虑𝑋的线性函数：𝑌 = 𝑎𝑋 + b，a,b ∈ R 其具有性质：\n          1. E(Y) = aE(X) + b\n          2. Var(Y) = a^2Var(X)\n       2. 我们可以用以下公式表示随机变量𝑋的方差：` Var(X) = E(X^2) - E(X)^2`\n    7. 均匀分布(Uniform Distribution)：X ~ U(a,b)， a<b\n       1. pdf：f(x) = 1/(b-a)（a<x<b），否则 0\n       2. E(X)：(a+b)/2\n       3. Var(X)：(b-a)²/12\n    8. 指数分布(Exponential Distribution)：X ~ Exp(λ)，λ>0\n       1. pdf：f(x) = λe^(-λx)（x≥0），否则 0\n       2. E(X)：1/λ\n       3. Var(X)：1/λ²\n       4. 注意：指数分布常被用作描述特定事件发生前时间长度的分布（eg：从现在开始到发生地震的时间长度）\n    9. 正态分布(Normal Distribution)：X ~ N(μ,σ²)，μ∈R， σ>0\n       1. pdf：f(x)=1/(√(2π)σ)e^(-(x-μ)²/(2σ²))\n       2. E(X)：μ\n       3. Var(X)：σ²\n       4. **正态分布关键特性：**\n          1. 标准化：若 X~N (μ,σ²)，则Z=(X-μ)/σ~N(0,1)（标准正态分布），通过标准正态表查概率\n          2. 3σ 原则：P(μ-σ<X<μ+σ)≈68.27%，P(μ-2σ<X<μ+2σ)≈95.45%，P(μ-3σ<X<μ+3σ)≈99.73%\n       5. 解题步骤：\n          1. `将X转换成Z的范围`\n          2. 用上限减去下限\n          3. 查找对应值带入计算\n![Z table](/images/Z_table.png)\n\n4. 二维分布（2D Distributions）\n   1. 二维离散分布（Discrete 2D Distributions）\n      1. 联合 pmf：f (x_i,y_j)=P (X=x_i,Y=y_j)，满足∑∑f (x_i,y_j)=1\n      2. 边际 pmf：f_X (x_i)=∑(j) f (x_i,y_j)（对 Y 求和），f_Y (y_j)=∑(i) f (x_i,y_j)（对 X 求和）\n      3. 分布函数：F(x,y) = ∑(x_i<=x)∑(y_i<=y) f(x_i,y_j)\n      4. ∑i∑j f(x_i,y_j) = 1\n      5. X的边际分布：f(x) = ∑j f(x,y_j)\n      6. Y的边际分布：f(y) = ∑i f(x_i,y)\n      7. 如果X和Y相互独立：f(x_i|y_j) = f(x_i) or f(x_i,y_j) = f(x_i)f(y_j)\n      8. 期望值：E(g(X,Y)) = ∑i∑j g(x_i,y_j) f(x_i,y_j) \n   2. 二维连续分布（Continuous 2D Distributions）\n      1. 联合 pdf：f (x,y)≥0，∫(-∞到 +∞)∫(-∞到 +∞) f (x,y)dxdy = 1\n      2. 边际 pdf：f_X (x)=∫(-∞到 +∞) f (x,y) dy，f_Y (y)=∫(-∞到 +∞) f (x,y) dx\n      3. 分布函数：F(x,y) = ∫(Y<=y)∫(X<=x) f(X,Y)dXdY\n      4. X的边际分布：f(x) = ∫(-∞到 +∞) f(x,y)dy\n      5. Y的边际分布：f(y) = ∫(-∞到 +∞) f(x,y)dx\n      6. 如果X和Y相互独立：f(x|y) = f(x) or f(x,y) = f(x)f(y)\n      7. 期望值：E(g(X,Y)) = ∫(-∞到 +∞)∫(-∞到 +∞) g(x,y)f(x,y)dxdy\n      8. P(a<=X<=b,c<=Y<=d) = ∫(c到d)∫(a到b) f(x,y)dxdy\n      9. 条件概率描述 “在Y满足某条件时，X发生的概率”，分三类情况：\n         1. P(X<=x|Y<=y) = P(X<=x|Y<=y) / P(Y<=y) = F(x,y) / F(y)\n         2. P(X<=x|Y=y) = ∫(X<=x) f(x|y)dx = ∫(X<=x) f(x,y)/f(y) dx\n         3. P(X<=x|Y>=y) = P(X<=x|Y>=y) / P(Y>=y) = ∫(Y>=y)∫(X<=x) f(x,y) dxdy / ∫(Y>=y) f(y) dy\n5. 数字特征与相关性\n   1. 均值的运算性质\n      1. 求和定理(Sum of Means)：对任意随机变量 X₁,X₂,…,Xₙ（离散/连续、独立/依赖），E(X₁+X₂+…+Xₙ) = E(X₁)+E(X₂)+…+E(Xₙ)\n      2. 乘积定理(Product of Means)：**仅当X₁,X₂,…,Xₙ独立时（每个随机变量的取值都不会对其他随机变量的取值概率产生影响）（离散、连续都适用）**，E(X₁X₂…Xₙ)=E(X₁)E(X₂)…E(Xₙ)\n   2. 独立性与不相关性\n      1. 独立性(independent)：X与Y独立 -> f(x,y) = f(x)f(y)（离散pmf / 连续pdf）\n      2. 不相关性(uncorrelated)：X与Y不相关 -> E(XY) = E(X)E(Y) -> Cov(X,Y) = 0 -> ρ(X,Y) = 0\n      3. 关系：独立→不相关，但不相关≠独立\n   3. 协方差与相关系数\n      1. 协方差(Covariance)：Cov(X,Y) = E[(X-μ_X)(Y-μ_Y)] = E(XY) - E(X)E(Y)，反映X与Y“同增同减” 趋势（Cov>0：正相关，Cov<0：负相关）\n      2. 相关系数(Correlation)：ρ(X,Y)=Cov (X,Y)/(σ_Xσ_Y)，ρ∈[-1,1]，是无量纲的线性关联度量\n         1. ρ=1：完全正线性相关\n         2. ρ=-1：完全负线性相关\n         3. ρ=0：无线性相关\n   4. 双变量正态分布\n      1. 定义：X与Y联合正态 -> 对任意 a,b∈R，aX+bY 正态分布\n      2. 关键性质：若 X 与 Y 联合正态且不相关（ρ=0），则X与Y独立（区别于一般随机变量）\n\n\n## 摘录\n1. 我们一步一步走下去，踏踏实实地去走，永不抗拒生命交给我们的重负，才是一个勇者。到了蓦然回首的那一瞬间，生命必然给我们公平的答案和又一次乍喜的心情，那时的山和水，又恢复成最初单纯的样子，而人生走过的是多么美好的一个秋天。 -- 三毛\n\n\n## 昨日总结\n昨天参加了本学期第一次飞盘活动，感觉是开学以来参与感最强的一次活动了，既能够充分运动，也可以认识很多朋友（争取吧）\n\n## 今日总结\n1. 今天完成了概率课程的提交作业，整体写下来还是比较容易的，就是中途发现还是有些地方想得过于复杂了\n2. 读书一章\n3. 复习完全部单词\n4. 本周第二次网球活动\n","source":"_posts/2025-10-17.md","raw":"---\ntitle: 2025.10.17\ndate: 2025-10-17 08:47:31\ntags:\n---\n# Overview\n1. 今日学习笔记\n2. 句子摘录\n3. 昨天和今天的总结\n\n\n## 学习笔记\n### 概率\n1. 随机变量（Random Variables）\n   1. Definition：设样本空间为 Ω，随机变量 X 是定义在 Ω 上、取值于实数集ℝ的函数，即X: Ω→R，X(ω) 表示对样本点 ω 的赋值\n   2. Example：掷骰子（Ω={1,2,3,4,5,6}），X(1-3)=1（赢1元），X(4-6)=-1（输1元），刻画玩家收益\n   3. 概率表示：事件 “X 取 x 值” 即 {ω∈Ω | X(ω)=x}，概率简化记为P(X=x)，且所有可能取值概率和为 1（∑P (X=x)=1）\n2. 离散型随机变量及其分布（Discrete Random Variables and Distributions）\n   1. Definition：取值为有限个或可列个，且每个取值有其概率，不可能的取值的概率为0.\n   2. 概率质量函数（probability mass function (pmf)）：f(x)满足：\n      1. f(x)≥0\n      2. ∑f (x)=1（所有可能 x 求和）\n   3. 分布函数（distribution function）：F(x)=P(X≤x)=∑(x_j≤x) f(x_j)，其具有性质：\n      1. lim(x→-∞)F(x)=0\n      2. lim(x→+∞)F(x)=1\n      3. 非递减\n      4. 0≤F(x)≤1\n   4. 离散型随机变量的平均数或期望（mean or expectation or expected value）：μ = E[X] = ∑_j x_j f(x_j), j = 1,2,...,n（f是X的pmf，x_j是X的可能取值）\n      1. 进一步推导出：E[g(X)] = ∑_j g(x_j) f(x_j), j = 1,2,...,n\n   5. 离散型随机变量的方差（variance）：σ^2 = Var(X) = E[(X - E(X))^2] = ∑_j (x_j - E(X))^2 f(j_x)\n      1. 方差提供𝑋围绕其均值E𝑋的离散程度的度量，其总是非负的\n      2. 标准差（standard deviation）：σ = √Var(X)\n   6. 均值和方差的性质：\n      1. 设𝑋为随机变量，我们考虑𝑋的线性函数：𝑌 = 𝑎𝑋 + b，a,b ∈ R 其具有性质：\n         1. E(Y) = aE(X) + b\n         2. Var(Y) = a^2Var(X)\n      2. 可以用以下公式表示随机变量𝑋的方差:` Var(X) = E(X^2) - E(X)^2`\n   7. 伯努利分布（Bernoulli Distribution）：\n      1. Definition：随机变量X只能取值1或0，其概率分别为 p ∈ (0,1)，q(:= 1-p)\n      2. 可能取值：1,2\n      3. pmf：P(X=1) = p，P(X=0) = 1-p\n      4. E (X)：p\n      5. Var (X)：p(1-p)\n   8. 二项分布（Binomial Distribution）：𝑋 ∼ Bin(n,p)，n∈ℕ, p∈(0,1))\n      1. Definition：n次独立试验中成功次数的离散概率分布，每个试验的成功概率为𝑝\n      2. 可能取值：0,1,…,n\n      3. pmf：P(X=k) = C(n,k) p^k (1-p)^(n-k)\t （`C(n,k) = n! / k! (n-k)!`）\n      4. E (X)：np\n      5. Var (X)：np(1-p)\n   9. 泊松分布（Poisson Distribution）：𝑋 ∼ Poi(λ)，λ>0\n      1. Definition：泊松分布是一种离散概率分布，用于计算在固定时间或空间间隔内，以**已知平均发生率**且独立于上次事件发生时间的事件发生次数的概率。\n      2. 可能取值：0,1,2,…\n      3. pmf：P(X=k) = e^(-λ) λ^k / k!\n      4. E (X)：λ\n      5. Var (X)：λ\n      6. 注意：问题中给出的速率可能不是所需区间内的𝜆值！我们需要对其进行放大或缩小，以获得正确的𝜆值。（如给了一周的速率为𝜆，要计算两周的间隔则速率为2𝜆）\n   10. 几何分布（Geometric Distribution）：𝑋 ∼ Geo(p)，p∈(0,1)\n       1. Definition：经过X次试验才得到成功的结果\n       2. 可能取值：1,2,3,…（不能为0）\n       3. pmf：P(X=k) = p (1-p)^(k-1)\n       4. E (X)：1/p\n       5. Var (X)：(1-p)/p²\n3. 连续型随机变量及其分布（Continuous Random Variables and Distributions）\n    1. Definition：取值能充满某个区间（或多个区间），且其取任何单个特定值的概率均为 0 的随机变量\n    2. 概率密度函数（probability density function（pdf））：f(x)满足：\n       1. f(x)≥0\n       2. ∫(-∞到+∞) f(x) dx = 1\n    3. 分布函数（Distribution Function）：F(x) = P(X≤x) = ∫(-∞到 x) f(t) dt，具有性质：\n       1. lim(x→-∞)F(x)=0\n       2. lim(x→+∞)F(x)=1\n       3. 𝐹可微（因此连续），是非递减函数\n       4. 0 ≤ 𝐹(x)≤ 1\n       5.  f(x) = F’(x)\n    4. 连续随机变量的均值(Mean of Continuous Random Variable)：μ = E[x] = ∫(-∞到+∞) xf(x) dx ，（f(x)是pdf）\n       1. 进一步推导出：E[g(X)] = ∫(-∞到+∞) g(x)f(x) dx\n    5. 连续随机变量的方差(Variance of Continuous Random Variable)：σ^2 = Var(X) = E[(X - E(X))^2] = ∫(-∞到+∞) (x - E(X))^2 f(x) dx\n    6. 均值和方差的性质：\n       1. 设𝑋为随机变量，我们考虑𝑋的线性函数：𝑌 = 𝑎𝑋 + b，a,b ∈ R 其具有性质：\n          1. E(Y) = aE(X) + b\n          2. Var(Y) = a^2Var(X)\n       2. 我们可以用以下公式表示随机变量𝑋的方差：` Var(X) = E(X^2) - E(X)^2`\n    7. 均匀分布(Uniform Distribution)：X ~ U(a,b)， a<b\n       1. pdf：f(x) = 1/(b-a)（a<x<b），否则 0\n       2. E(X)：(a+b)/2\n       3. Var(X)：(b-a)²/12\n    8. 指数分布(Exponential Distribution)：X ~ Exp(λ)，λ>0\n       1. pdf：f(x) = λe^(-λx)（x≥0），否则 0\n       2. E(X)：1/λ\n       3. Var(X)：1/λ²\n       4. 注意：指数分布常被用作描述特定事件发生前时间长度的分布（eg：从现在开始到发生地震的时间长度）\n    9. 正态分布(Normal Distribution)：X ~ N(μ,σ²)，μ∈R， σ>0\n       1. pdf：f(x)=1/(√(2π)σ)e^(-(x-μ)²/(2σ²))\n       2. E(X)：μ\n       3. Var(X)：σ²\n       4. **正态分布关键特性：**\n          1. 标准化：若 X~N (μ,σ²)，则Z=(X-μ)/σ~N(0,1)（标准正态分布），通过标准正态表查概率\n          2. 3σ 原则：P(μ-σ<X<μ+σ)≈68.27%，P(μ-2σ<X<μ+2σ)≈95.45%，P(μ-3σ<X<μ+3σ)≈99.73%\n       5. 解题步骤：\n          1. `将X转换成Z的范围`\n          2. 用上限减去下限\n          3. 查找对应值带入计算\n![Z table](/images/Z_table.png)\n\n4. 二维分布（2D Distributions）\n   1. 二维离散分布（Discrete 2D Distributions）\n      1. 联合 pmf：f (x_i,y_j)=P (X=x_i,Y=y_j)，满足∑∑f (x_i,y_j)=1\n      2. 边际 pmf：f_X (x_i)=∑(j) f (x_i,y_j)（对 Y 求和），f_Y (y_j)=∑(i) f (x_i,y_j)（对 X 求和）\n      3. 分布函数：F(x,y) = ∑(x_i<=x)∑(y_i<=y) f(x_i,y_j)\n      4. ∑i∑j f(x_i,y_j) = 1\n      5. X的边际分布：f(x) = ∑j f(x,y_j)\n      6. Y的边际分布：f(y) = ∑i f(x_i,y)\n      7. 如果X和Y相互独立：f(x_i|y_j) = f(x_i) or f(x_i,y_j) = f(x_i)f(y_j)\n      8. 期望值：E(g(X,Y)) = ∑i∑j g(x_i,y_j) f(x_i,y_j) \n   2. 二维连续分布（Continuous 2D Distributions）\n      1. 联合 pdf：f (x,y)≥0，∫(-∞到 +∞)∫(-∞到 +∞) f (x,y)dxdy = 1\n      2. 边际 pdf：f_X (x)=∫(-∞到 +∞) f (x,y) dy，f_Y (y)=∫(-∞到 +∞) f (x,y) dx\n      3. 分布函数：F(x,y) = ∫(Y<=y)∫(X<=x) f(X,Y)dXdY\n      4. X的边际分布：f(x) = ∫(-∞到 +∞) f(x,y)dy\n      5. Y的边际分布：f(y) = ∫(-∞到 +∞) f(x,y)dx\n      6. 如果X和Y相互独立：f(x|y) = f(x) or f(x,y) = f(x)f(y)\n      7. 期望值：E(g(X,Y)) = ∫(-∞到 +∞)∫(-∞到 +∞) g(x,y)f(x,y)dxdy\n      8. P(a<=X<=b,c<=Y<=d) = ∫(c到d)∫(a到b) f(x,y)dxdy\n      9. 条件概率描述 “在Y满足某条件时，X发生的概率”，分三类情况：\n         1. P(X<=x|Y<=y) = P(X<=x|Y<=y) / P(Y<=y) = F(x,y) / F(y)\n         2. P(X<=x|Y=y) = ∫(X<=x) f(x|y)dx = ∫(X<=x) f(x,y)/f(y) dx\n         3. P(X<=x|Y>=y) = P(X<=x|Y>=y) / P(Y>=y) = ∫(Y>=y)∫(X<=x) f(x,y) dxdy / ∫(Y>=y) f(y) dy\n5. 数字特征与相关性\n   1. 均值的运算性质\n      1. 求和定理(Sum of Means)：对任意随机变量 X₁,X₂,…,Xₙ（离散/连续、独立/依赖），E(X₁+X₂+…+Xₙ) = E(X₁)+E(X₂)+…+E(Xₙ)\n      2. 乘积定理(Product of Means)：**仅当X₁,X₂,…,Xₙ独立时（每个随机变量的取值都不会对其他随机变量的取值概率产生影响）（离散、连续都适用）**，E(X₁X₂…Xₙ)=E(X₁)E(X₂)…E(Xₙ)\n   2. 独立性与不相关性\n      1. 独立性(independent)：X与Y独立 -> f(x,y) = f(x)f(y)（离散pmf / 连续pdf）\n      2. 不相关性(uncorrelated)：X与Y不相关 -> E(XY) = E(X)E(Y) -> Cov(X,Y) = 0 -> ρ(X,Y) = 0\n      3. 关系：独立→不相关，但不相关≠独立\n   3. 协方差与相关系数\n      1. 协方差(Covariance)：Cov(X,Y) = E[(X-μ_X)(Y-μ_Y)] = E(XY) - E(X)E(Y)，反映X与Y“同增同减” 趋势（Cov>0：正相关，Cov<0：负相关）\n      2. 相关系数(Correlation)：ρ(X,Y)=Cov (X,Y)/(σ_Xσ_Y)，ρ∈[-1,1]，是无量纲的线性关联度量\n         1. ρ=1：完全正线性相关\n         2. ρ=-1：完全负线性相关\n         3. ρ=0：无线性相关\n   4. 双变量正态分布\n      1. 定义：X与Y联合正态 -> 对任意 a,b∈R，aX+bY 正态分布\n      2. 关键性质：若 X 与 Y 联合正态且不相关（ρ=0），则X与Y独立（区别于一般随机变量）\n\n\n## 摘录\n1. 我们一步一步走下去，踏踏实实地去走，永不抗拒生命交给我们的重负，才是一个勇者。到了蓦然回首的那一瞬间，生命必然给我们公平的答案和又一次乍喜的心情，那时的山和水，又恢复成最初单纯的样子，而人生走过的是多么美好的一个秋天。 -- 三毛\n\n\n## 昨日总结\n昨天参加了本学期第一次飞盘活动，感觉是开学以来参与感最强的一次活动了，既能够充分运动，也可以认识很多朋友（争取吧）\n\n## 今日总结\n1. 今天完成了概率课程的提交作业，整体写下来还是比较容易的，就是中途发现还是有些地方想得过于复杂了\n2. 读书一章\n3. 复习完全部单词\n4. 本周第二次网球活动\n","slug":"2025-10-17","published":1,"updated":"2025-11-18T19:39:17.120Z","comments":1,"layout":"post","photos":[],"_id":"cuid1NcM8XsVlgow0GgMUnkBa","content":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>今日学习笔记</li>\n<li>句子摘录</li>\n<li>昨天和今天的总结</li>\n</ol>\n<h2 id=\"学习笔记\"><a href=\"#学习笔记\" class=\"headerlink\" title=\"学习笔记\"></a>学习笔记</h2><h3 id=\"概率\"><a href=\"#概率\" class=\"headerlink\" title=\"概率\"></a>概率</h3><ol>\n<li>随机变量（Random Variables）<ol>\n<li>Definition：设样本空间为 Ω，随机变量 X 是定义在 Ω 上、取值于实数集ℝ的函数，即X: Ω→R，X(ω) 表示对样本点 ω 的赋值</li>\n<li>Example：掷骰子（Ω&#x3D;{1,2,3,4,5,6}），X(1-3)&#x3D;1（赢1元），X(4-6)&#x3D;-1（输1元），刻画玩家收益</li>\n<li>概率表示：事件 “X 取 x 值” 即 {ω∈Ω | X(ω)&#x3D;x}，概率简化记为P(X&#x3D;x)，且所有可能取值概率和为 1（∑P (X&#x3D;x)&#x3D;1）</li>\n</ol>\n</li>\n<li>离散型随机变量及其分布（Discrete Random Variables and Distributions）<ol>\n<li>Definition：取值为有限个或可列个，且每个取值有其概率，不可能的取值的概率为0.</li>\n<li>概率质量函数（probability mass function (pmf)）：f(x)满足：<ol>\n<li>f(x)≥0</li>\n<li>∑f (x)&#x3D;1（所有可能 x 求和）</li>\n</ol>\n</li>\n<li>分布函数（distribution function）：F(x)&#x3D;P(X≤x)&#x3D;∑(x_j≤x) f(x_j)，其具有性质：<ol>\n<li>lim(x→-∞)F(x)&#x3D;0</li>\n<li>lim(x→+∞)F(x)&#x3D;1</li>\n<li>非递减</li>\n<li>0≤F(x)≤1</li>\n</ol>\n</li>\n<li>离散型随机变量的平均数或期望（mean or expectation or expected value）：μ &#x3D; E[X] &#x3D; ∑_j x_j f(x_j), j &#x3D; 1,2,…,n（f是X的pmf，x_j是X的可能取值）<ol>\n<li>进一步推导出：E[g(X)] &#x3D; ∑_j g(x_j) f(x_j), j &#x3D; 1,2,…,n</li>\n</ol>\n</li>\n<li>离散型随机变量的方差（variance）：σ^2 &#x3D; Var(X) &#x3D; E[(X - E(X))^2] &#x3D; ∑_j (x_j - E(X))^2 f(j_x)<ol>\n<li>方差提供𝑋围绕其均值E𝑋的离散程度的度量，其总是非负的</li>\n<li>标准差（standard deviation）：σ &#x3D; √Var(X)</li>\n</ol>\n</li>\n<li>均值和方差的性质：<ol>\n<li>设𝑋为随机变量，我们考虑𝑋的线性函数：𝑌 &#x3D; 𝑎𝑋 + b，a,b ∈ R 其具有性质：<ol>\n<li>E(Y) &#x3D; aE(X) + b</li>\n<li>Var(Y) &#x3D; a^2Var(X)</li>\n</ol>\n</li>\n<li>可以用以下公式表示随机变量𝑋的方差:<code> Var(X) = E(X^2) - E(X)^2</code></li>\n</ol>\n</li>\n<li>伯努利分布（Bernoulli Distribution）：<ol>\n<li>Definition：随机变量X只能取值1或0，其概率分别为 p ∈ (0,1)，q(:&#x3D; 1-p)</li>\n<li>可能取值：1,2</li>\n<li>pmf：P(X&#x3D;1) &#x3D; p，P(X&#x3D;0) &#x3D; 1-p</li>\n<li>E (X)：p</li>\n<li>Var (X)：p(1-p)</li>\n</ol>\n</li>\n<li>二项分布（Binomial Distribution）：𝑋 ∼ Bin(n,p)，n∈ℕ, p∈(0,1))<ol>\n<li>Definition：n次独立试验中成功次数的离散概率分布，每个试验的成功概率为𝑝</li>\n<li>可能取值：0,1,…,n</li>\n<li>pmf：P(X&#x3D;k) &#x3D; C(n,k) p^k (1-p)^(n-k)     （<code>C(n,k) = n! / k! (n-k)!</code>）</li>\n<li>E (X)：np</li>\n<li>Var (X)：np(1-p)</li>\n</ol>\n</li>\n<li>泊松分布（Poisson Distribution）：𝑋 ∼ Poi(λ)，λ&gt;0<ol>\n<li>Definition：泊松分布是一种离散概率分布，用于计算在固定时间或空间间隔内，以<strong>已知平均发生率</strong>且独立于上次事件发生时间的事件发生次数的概率。</li>\n<li>可能取值：0,1,2,…</li>\n<li>pmf：P(X&#x3D;k) &#x3D; e^(-λ) λ^k &#x2F; k!</li>\n<li>E (X)：λ</li>\n<li>Var (X)：λ</li>\n<li>注意：问题中给出的速率可能不是所需区间内的𝜆值！我们需要对其进行放大或缩小，以获得正确的𝜆值。（如给了一周的速率为𝜆，要计算两周的间隔则速率为2𝜆）</li>\n</ol>\n</li>\n<li>几何分布（Geometric Distribution）：𝑋 ∼ Geo(p)，p∈(0,1)<ol>\n<li>Definition：经过X次试验才得到成功的结果</li>\n<li>可能取值：1,2,3,…（不能为0）</li>\n<li>pmf：P(X&#x3D;k) &#x3D; p (1-p)^(k-1)</li>\n<li>E (X)：1&#x2F;p</li>\n<li>Var (X)：(1-p)&#x2F;p²</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>连续型随机变量及其分布（Continuous Random Variables and Distributions）<ol>\n<li>Definition：取值能充满某个区间（或多个区间），且其取任何单个特定值的概率均为 0 的随机变量</li>\n<li>概率密度函数（probability density function（pdf））：f(x)满足：<ol>\n<li>f(x)≥0</li>\n<li>∫(-∞到+∞) f(x) dx &#x3D; 1</li>\n</ol>\n</li>\n<li>分布函数（Distribution Function）：F(x) &#x3D; P(X≤x) &#x3D; ∫(-∞到 x) f(t) dt，具有性质：<ol>\n<li>lim(x→-∞)F(x)&#x3D;0</li>\n<li>lim(x→+∞)F(x)&#x3D;1</li>\n<li>𝐹可微（因此连续），是非递减函数</li>\n<li>0 ≤ 𝐹(x)≤ 1</li>\n<li>f(x) &#x3D; F’(x)</li>\n</ol>\n</li>\n<li>连续随机变量的均值(Mean of Continuous Random Variable)：μ &#x3D; E[x] &#x3D; ∫(-∞到+∞) xf(x) dx ，（f(x)是pdf）<ol>\n<li>进一步推导出：E[g(X)] &#x3D; ∫(-∞到+∞) g(x)f(x) dx</li>\n</ol>\n</li>\n<li>连续随机变量的方差(Variance of Continuous Random Variable)：σ^2 &#x3D; Var(X) &#x3D; E[(X - E(X))^2] &#x3D; ∫(-∞到+∞) (x - E(X))^2 f(x) dx</li>\n<li>均值和方差的性质：<ol>\n<li>设𝑋为随机变量，我们考虑𝑋的线性函数：𝑌 &#x3D; 𝑎𝑋 + b，a,b ∈ R 其具有性质：<ol>\n<li>E(Y) &#x3D; aE(X) + b</li>\n<li>Var(Y) &#x3D; a^2Var(X)</li>\n</ol>\n</li>\n<li>我们可以用以下公式表示随机变量𝑋的方差：<code> Var(X) = E(X^2) - E(X)^2</code></li>\n</ol>\n</li>\n<li>均匀分布(Uniform Distribution)：X ~ U(a,b)， a&lt;b<ol>\n<li>pdf：f(x) &#x3D; 1&#x2F;(b-a)（a&lt;x&lt;b），否则 0</li>\n<li>E(X)：(a+b)&#x2F;2</li>\n<li>Var(X)：(b-a)²&#x2F;12</li>\n</ol>\n</li>\n<li>指数分布(Exponential Distribution)：X ~ Exp(λ)，λ&gt;0<ol>\n<li>pdf：f(x) &#x3D; λe^(-λx)（x≥0），否则 0</li>\n<li>E(X)：1&#x2F;λ</li>\n<li>Var(X)：1&#x2F;λ²</li>\n<li>注意：指数分布常被用作描述特定事件发生前时间长度的分布（eg：从现在开始到发生地震的时间长度）</li>\n</ol>\n</li>\n<li>正态分布(Normal Distribution)：X ~ N(μ,σ²)，μ∈R， σ&gt;0<ol>\n<li>pdf：f(x)&#x3D;1&#x2F;(√(2π)σ)e^(-(x-μ)²&#x2F;(2σ²))</li>\n<li>E(X)：μ</li>\n<li>Var(X)：σ²</li>\n<li><strong>正态分布关键特性：</strong><ol>\n<li>标准化：若 X<del>N (μ,σ²)，则Z&#x3D;(X-μ)&#x2F;σ</del>N(0,1)（标准正态分布），通过标准正态表查概率</li>\n<li>3σ 原则：P(μ-σ&lt;X&lt;μ+σ)≈68.27%，P(μ-2σ&lt;X&lt;μ+2σ)≈95.45%，P(μ-3σ&lt;X&lt;μ+3σ)≈99.73%</li>\n</ol>\n</li>\n<li>解题步骤：<ol>\n<li><code>将X转换成Z的范围</code></li>\n<li>用上限减去下限</li>\n<li>查找对应值带入计算</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<p><img src=\"/images/Z_table.png\" alt=\"Z table\"></p>\n<ol start=\"4\">\n<li>二维分布（2D Distributions）<ol>\n<li>二维离散分布（Discrete 2D Distributions）<ol>\n<li>联合 pmf：f (x_i,y_j)&#x3D;P (X&#x3D;x_i,Y&#x3D;y_j)，满足∑∑f (x_i,y_j)&#x3D;1</li>\n<li>边际 pmf：f_X (x_i)&#x3D;∑(j) f (x_i,y_j)（对 Y 求和），f_Y (y_j)&#x3D;∑(i) f (x_i,y_j)（对 X 求和）</li>\n<li>分布函数：F(x,y) &#x3D; ∑(x_i&lt;&#x3D;x)∑(y_i&lt;&#x3D;y) f(x_i,y_j)</li>\n<li>∑i∑j f(x_i,y_j) &#x3D; 1</li>\n<li>X的边际分布：f(x) &#x3D; ∑j f(x,y_j)</li>\n<li>Y的边际分布：f(y) &#x3D; ∑i f(x_i,y)</li>\n<li>如果X和Y相互独立：f(x_i|y_j) &#x3D; f(x_i) or f(x_i,y_j) &#x3D; f(x_i)f(y_j)</li>\n<li>期望值：E(g(X,Y)) &#x3D; ∑i∑j g(x_i,y_j) f(x_i,y_j)</li>\n</ol>\n</li>\n<li>二维连续分布（Continuous 2D Distributions）<ol>\n<li>联合 pdf：f (x,y)≥0，∫(-∞到 +∞)∫(-∞到 +∞) f (x,y)dxdy &#x3D; 1</li>\n<li>边际 pdf：f_X (x)&#x3D;∫(-∞到 +∞) f (x,y) dy，f_Y (y)&#x3D;∫(-∞到 +∞) f (x,y) dx</li>\n<li>分布函数：F(x,y) &#x3D; ∫(Y&lt;&#x3D;y)∫(X&lt;&#x3D;x) f(X,Y)dXdY</li>\n<li>X的边际分布：f(x) &#x3D; ∫(-∞到 +∞) f(x,y)dy</li>\n<li>Y的边际分布：f(y) &#x3D; ∫(-∞到 +∞) f(x,y)dx</li>\n<li>如果X和Y相互独立：f(x|y) &#x3D; f(x) or f(x,y) &#x3D; f(x)f(y)</li>\n<li>期望值：E(g(X,Y)) &#x3D; ∫(-∞到 +∞)∫(-∞到 +∞) g(x,y)f(x,y)dxdy</li>\n<li>P(a&lt;&#x3D;X&lt;&#x3D;b,c&lt;&#x3D;Y&lt;&#x3D;d) &#x3D; ∫(c到d)∫(a到b) f(x,y)dxdy</li>\n<li>条件概率描述 “在Y满足某条件时，X发生的概率”，分三类情况：<ol>\n<li>P(X&lt;&#x3D;x|Y&lt;&#x3D;y) &#x3D; P(X&lt;&#x3D;x|Y&lt;&#x3D;y) &#x2F; P(Y&lt;&#x3D;y) &#x3D; F(x,y) &#x2F; F(y)</li>\n<li>P(X&lt;&#x3D;x|Y&#x3D;y) &#x3D; ∫(X&lt;&#x3D;x) f(x|y)dx &#x3D; ∫(X&lt;&#x3D;x) f(x,y)&#x2F;f(y) dx</li>\n<li>P(X&lt;&#x3D;x|Y&gt;&#x3D;y) &#x3D; P(X&lt;&#x3D;x|Y&gt;&#x3D;y) &#x2F; P(Y&gt;&#x3D;y) &#x3D; ∫(Y&gt;&#x3D;y)∫(X&lt;&#x3D;x) f(x,y) dxdy &#x2F; ∫(Y&gt;&#x3D;y) f(y) dy</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>数字特征与相关性<ol>\n<li>均值的运算性质<ol>\n<li>求和定理(Sum of Means)：对任意随机变量 X₁,X₂,…,Xₙ（离散&#x2F;连续、独立&#x2F;依赖），E(X₁+X₂+…+Xₙ) &#x3D; E(X₁)+E(X₂)+…+E(Xₙ)</li>\n<li>乘积定理(Product of Means)：<strong>仅当X₁,X₂,…,Xₙ独立时（每个随机变量的取值都不会对其他随机变量的取值概率产生影响）（离散、连续都适用）</strong>，E(X₁X₂…Xₙ)&#x3D;E(X₁)E(X₂)…E(Xₙ)</li>\n</ol>\n</li>\n<li>独立性与不相关性<ol>\n<li>独立性(independent)：X与Y独立 -&gt; f(x,y) &#x3D; f(x)f(y)（离散pmf &#x2F; 连续pdf）</li>\n<li>不相关性(uncorrelated)：X与Y不相关 -&gt; E(XY) &#x3D; E(X)E(Y) -&gt; Cov(X,Y) &#x3D; 0 -&gt; ρ(X,Y) &#x3D; 0</li>\n<li>关系：独立→不相关，但不相关≠独立</li>\n</ol>\n</li>\n<li>协方差与相关系数<ol>\n<li>协方差(Covariance)：Cov(X,Y) &#x3D; E[(X-μ_X)(Y-μ_Y)] &#x3D; E(XY) - E(X)E(Y)，反映X与Y“同增同减” 趋势（Cov&gt;0：正相关，Cov&lt;0：负相关）</li>\n<li>相关系数(Correlation)：ρ(X,Y)&#x3D;Cov (X,Y)&#x2F;(σ_Xσ_Y)，ρ∈[-1,1]，是无量纲的线性关联度量<ol>\n<li>ρ&#x3D;1：完全正线性相关</li>\n<li>ρ&#x3D;-1：完全负线性相关</li>\n<li>ρ&#x3D;0：无线性相关</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>双变量正态分布<ol>\n<li>定义：X与Y联合正态 -&gt; 对任意 a,b∈R，aX+bY 正态分布</li>\n<li>关键性质：若 X 与 Y 联合正态且不相关（ρ&#x3D;0），则X与Y独立（区别于一般随机变量）</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"摘录\"><a href=\"#摘录\" class=\"headerlink\" title=\"摘录\"></a>摘录</h2><ol>\n<li>我们一步一步走下去，踏踏实实地去走，永不抗拒生命交给我们的重负，才是一个勇者。到了蓦然回首的那一瞬间，生命必然给我们公平的答案和又一次乍喜的心情，那时的山和水，又恢复成最初单纯的样子，而人生走过的是多么美好的一个秋天。 – 三毛</li>\n</ol>\n<h2 id=\"昨日总结\"><a href=\"#昨日总结\" class=\"headerlink\" title=\"昨日总结\"></a>昨日总结</h2><p>昨天参加了本学期第一次飞盘活动，感觉是开学以来参与感最强的一次活动了，既能够充分运动，也可以认识很多朋友（争取吧）</p>\n<h2 id=\"今日总结\"><a href=\"#今日总结\" class=\"headerlink\" title=\"今日总结\"></a>今日总结</h2><ol>\n<li>今天完成了概率课程的提交作业，整体写下来还是比较容易的，就是中途发现还是有些地方想得过于复杂了</li>\n<li>读书一章</li>\n<li>复习完全部单词</li>\n<li>本周第二次网球活动</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>今日学习笔记</li>\n<li>句子摘录</li>\n<li>昨天和今天的总结</li>\n</ol>\n<h2 id=\"学习笔记\"><a href=\"#学习笔记\" class=\"headerlink\" title=\"学习笔记\"></a>学习笔记</h2><h3 id=\"概率\"><a href=\"#概率\" class=\"headerlink\" title=\"概率\"></a>概率</h3><ol>\n<li>随机变量（Random Variables）<ol>\n<li>Definition：设样本空间为 Ω，随机变量 X 是定义在 Ω 上、取值于实数集ℝ的函数，即X: Ω→R，X(ω) 表示对样本点 ω 的赋值</li>\n<li>Example：掷骰子（Ω&#x3D;{1,2,3,4,5,6}），X(1-3)&#x3D;1（赢1元），X(4-6)&#x3D;-1（输1元），刻画玩家收益</li>\n<li>概率表示：事件 “X 取 x 值” 即 {ω∈Ω | X(ω)&#x3D;x}，概率简化记为P(X&#x3D;x)，且所有可能取值概率和为 1（∑P (X&#x3D;x)&#x3D;1）</li>\n</ol>\n</li>\n<li>离散型随机变量及其分布（Discrete Random Variables and Distributions）<ol>\n<li>Definition：取值为有限个或可列个，且每个取值有其概率，不可能的取值的概率为0.</li>\n<li>概率质量函数（probability mass function (pmf)）：f(x)满足：<ol>\n<li>f(x)≥0</li>\n<li>∑f (x)&#x3D;1（所有可能 x 求和）</li>\n</ol>\n</li>\n<li>分布函数（distribution function）：F(x)&#x3D;P(X≤x)&#x3D;∑(x_j≤x) f(x_j)，其具有性质：<ol>\n<li>lim(x→-∞)F(x)&#x3D;0</li>\n<li>lim(x→+∞)F(x)&#x3D;1</li>\n<li>非递减</li>\n<li>0≤F(x)≤1</li>\n</ol>\n</li>\n<li>离散型随机变量的平均数或期望（mean or expectation or expected value）：μ &#x3D; E[X] &#x3D; ∑_j x_j f(x_j), j &#x3D; 1,2,…,n（f是X的pmf，x_j是X的可能取值）<ol>\n<li>进一步推导出：E[g(X)] &#x3D; ∑_j g(x_j) f(x_j), j &#x3D; 1,2,…,n</li>\n</ol>\n</li>\n<li>离散型随机变量的方差（variance）：σ^2 &#x3D; Var(X) &#x3D; E[(X - E(X))^2] &#x3D; ∑_j (x_j - E(X))^2 f(j_x)<ol>\n<li>方差提供𝑋围绕其均值E𝑋的离散程度的度量，其总是非负的</li>\n<li>标准差（standard deviation）：σ &#x3D; √Var(X)</li>\n</ol>\n</li>\n<li>均值和方差的性质：<ol>\n<li>设𝑋为随机变量，我们考虑𝑋的线性函数：𝑌 &#x3D; 𝑎𝑋 + b，a,b ∈ R 其具有性质：<ol>\n<li>E(Y) &#x3D; aE(X) + b</li>\n<li>Var(Y) &#x3D; a^2Var(X)</li>\n</ol>\n</li>\n<li>可以用以下公式表示随机变量𝑋的方差:<code> Var(X) = E(X^2) - E(X)^2</code></li>\n</ol>\n</li>\n<li>伯努利分布（Bernoulli Distribution）：<ol>\n<li>Definition：随机变量X只能取值1或0，其概率分别为 p ∈ (0,1)，q(:&#x3D; 1-p)</li>\n<li>可能取值：1,2</li>\n<li>pmf：P(X&#x3D;1) &#x3D; p，P(X&#x3D;0) &#x3D; 1-p</li>\n<li>E (X)：p</li>\n<li>Var (X)：p(1-p)</li>\n</ol>\n</li>\n<li>二项分布（Binomial Distribution）：𝑋 ∼ Bin(n,p)，n∈ℕ, p∈(0,1))<ol>\n<li>Definition：n次独立试验中成功次数的离散概率分布，每个试验的成功概率为𝑝</li>\n<li>可能取值：0,1,…,n</li>\n<li>pmf：P(X&#x3D;k) &#x3D; C(n,k) p^k (1-p)^(n-k)     （<code>C(n,k) = n! / k! (n-k)!</code>）</li>\n<li>E (X)：np</li>\n<li>Var (X)：np(1-p)</li>\n</ol>\n</li>\n<li>泊松分布（Poisson Distribution）：𝑋 ∼ Poi(λ)，λ&gt;0<ol>\n<li>Definition：泊松分布是一种离散概率分布，用于计算在固定时间或空间间隔内，以<strong>已知平均发生率</strong>且独立于上次事件发生时间的事件发生次数的概率。</li>\n<li>可能取值：0,1,2,…</li>\n<li>pmf：P(X&#x3D;k) &#x3D; e^(-λ) λ^k &#x2F; k!</li>\n<li>E (X)：λ</li>\n<li>Var (X)：λ</li>\n<li>注意：问题中给出的速率可能不是所需区间内的𝜆值！我们需要对其进行放大或缩小，以获得正确的𝜆值。（如给了一周的速率为𝜆，要计算两周的间隔则速率为2𝜆）</li>\n</ol>\n</li>\n<li>几何分布（Geometric Distribution）：𝑋 ∼ Geo(p)，p∈(0,1)<ol>\n<li>Definition：经过X次试验才得到成功的结果</li>\n<li>可能取值：1,2,3,…（不能为0）</li>\n<li>pmf：P(X&#x3D;k) &#x3D; p (1-p)^(k-1)</li>\n<li>E (X)：1&#x2F;p</li>\n<li>Var (X)：(1-p)&#x2F;p²</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>连续型随机变量及其分布（Continuous Random Variables and Distributions）<ol>\n<li>Definition：取值能充满某个区间（或多个区间），且其取任何单个特定值的概率均为 0 的随机变量</li>\n<li>概率密度函数（probability density function（pdf））：f(x)满足：<ol>\n<li>f(x)≥0</li>\n<li>∫(-∞到+∞) f(x) dx &#x3D; 1</li>\n</ol>\n</li>\n<li>分布函数（Distribution Function）：F(x) &#x3D; P(X≤x) &#x3D; ∫(-∞到 x) f(t) dt，具有性质：<ol>\n<li>lim(x→-∞)F(x)&#x3D;0</li>\n<li>lim(x→+∞)F(x)&#x3D;1</li>\n<li>𝐹可微（因此连续），是非递减函数</li>\n<li>0 ≤ 𝐹(x)≤ 1</li>\n<li>f(x) &#x3D; F’(x)</li>\n</ol>\n</li>\n<li>连续随机变量的均值(Mean of Continuous Random Variable)：μ &#x3D; E[x] &#x3D; ∫(-∞到+∞) xf(x) dx ，（f(x)是pdf）<ol>\n<li>进一步推导出：E[g(X)] &#x3D; ∫(-∞到+∞) g(x)f(x) dx</li>\n</ol>\n</li>\n<li>连续随机变量的方差(Variance of Continuous Random Variable)：σ^2 &#x3D; Var(X) &#x3D; E[(X - E(X))^2] &#x3D; ∫(-∞到+∞) (x - E(X))^2 f(x) dx</li>\n<li>均值和方差的性质：<ol>\n<li>设𝑋为随机变量，我们考虑𝑋的线性函数：𝑌 &#x3D; 𝑎𝑋 + b，a,b ∈ R 其具有性质：<ol>\n<li>E(Y) &#x3D; aE(X) + b</li>\n<li>Var(Y) &#x3D; a^2Var(X)</li>\n</ol>\n</li>\n<li>我们可以用以下公式表示随机变量𝑋的方差：<code> Var(X) = E(X^2) - E(X)^2</code></li>\n</ol>\n</li>\n<li>均匀分布(Uniform Distribution)：X ~ U(a,b)， a&lt;b<ol>\n<li>pdf：f(x) &#x3D; 1&#x2F;(b-a)（a&lt;x&lt;b），否则 0</li>\n<li>E(X)：(a+b)&#x2F;2</li>\n<li>Var(X)：(b-a)²&#x2F;12</li>\n</ol>\n</li>\n<li>指数分布(Exponential Distribution)：X ~ Exp(λ)，λ&gt;0<ol>\n<li>pdf：f(x) &#x3D; λe^(-λx)（x≥0），否则 0</li>\n<li>E(X)：1&#x2F;λ</li>\n<li>Var(X)：1&#x2F;λ²</li>\n<li>注意：指数分布常被用作描述特定事件发生前时间长度的分布（eg：从现在开始到发生地震的时间长度）</li>\n</ol>\n</li>\n<li>正态分布(Normal Distribution)：X ~ N(μ,σ²)，μ∈R， σ&gt;0<ol>\n<li>pdf：f(x)&#x3D;1&#x2F;(√(2π)σ)e^(-(x-μ)²&#x2F;(2σ²))</li>\n<li>E(X)：μ</li>\n<li>Var(X)：σ²</li>\n<li><strong>正态分布关键特性：</strong><ol>\n<li>标准化：若 X<del>N (μ,σ²)，则Z&#x3D;(X-μ)&#x2F;σ</del>N(0,1)（标准正态分布），通过标准正态表查概率</li>\n<li>3σ 原则：P(μ-σ&lt;X&lt;μ+σ)≈68.27%，P(μ-2σ&lt;X&lt;μ+2σ)≈95.45%，P(μ-3σ&lt;X&lt;μ+3σ)≈99.73%</li>\n</ol>\n</li>\n<li>解题步骤：<ol>\n<li><code>将X转换成Z的范围</code></li>\n<li>用上限减去下限</li>\n<li>查找对应值带入计算</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<p><img src=\"/images/Z_table.png\" alt=\"Z table\"></p>\n<ol start=\"4\">\n<li>二维分布（2D Distributions）<ol>\n<li>二维离散分布（Discrete 2D Distributions）<ol>\n<li>联合 pmf：f (x_i,y_j)&#x3D;P (X&#x3D;x_i,Y&#x3D;y_j)，满足∑∑f (x_i,y_j)&#x3D;1</li>\n<li>边际 pmf：f_X (x_i)&#x3D;∑(j) f (x_i,y_j)（对 Y 求和），f_Y (y_j)&#x3D;∑(i) f (x_i,y_j)（对 X 求和）</li>\n<li>分布函数：F(x,y) &#x3D; ∑(x_i&lt;&#x3D;x)∑(y_i&lt;&#x3D;y) f(x_i,y_j)</li>\n<li>∑i∑j f(x_i,y_j) &#x3D; 1</li>\n<li>X的边际分布：f(x) &#x3D; ∑j f(x,y_j)</li>\n<li>Y的边际分布：f(y) &#x3D; ∑i f(x_i,y)</li>\n<li>如果X和Y相互独立：f(x_i|y_j) &#x3D; f(x_i) or f(x_i,y_j) &#x3D; f(x_i)f(y_j)</li>\n<li>期望值：E(g(X,Y)) &#x3D; ∑i∑j g(x_i,y_j) f(x_i,y_j)</li>\n</ol>\n</li>\n<li>二维连续分布（Continuous 2D Distributions）<ol>\n<li>联合 pdf：f (x,y)≥0，∫(-∞到 +∞)∫(-∞到 +∞) f (x,y)dxdy &#x3D; 1</li>\n<li>边际 pdf：f_X (x)&#x3D;∫(-∞到 +∞) f (x,y) dy，f_Y (y)&#x3D;∫(-∞到 +∞) f (x,y) dx</li>\n<li>分布函数：F(x,y) &#x3D; ∫(Y&lt;&#x3D;y)∫(X&lt;&#x3D;x) f(X,Y)dXdY</li>\n<li>X的边际分布：f(x) &#x3D; ∫(-∞到 +∞) f(x,y)dy</li>\n<li>Y的边际分布：f(y) &#x3D; ∫(-∞到 +∞) f(x,y)dx</li>\n<li>如果X和Y相互独立：f(x|y) &#x3D; f(x) or f(x,y) &#x3D; f(x)f(y)</li>\n<li>期望值：E(g(X,Y)) &#x3D; ∫(-∞到 +∞)∫(-∞到 +∞) g(x,y)f(x,y)dxdy</li>\n<li>P(a&lt;&#x3D;X&lt;&#x3D;b,c&lt;&#x3D;Y&lt;&#x3D;d) &#x3D; ∫(c到d)∫(a到b) f(x,y)dxdy</li>\n<li>条件概率描述 “在Y满足某条件时，X发生的概率”，分三类情况：<ol>\n<li>P(X&lt;&#x3D;x|Y&lt;&#x3D;y) &#x3D; P(X&lt;&#x3D;x|Y&lt;&#x3D;y) &#x2F; P(Y&lt;&#x3D;y) &#x3D; F(x,y) &#x2F; F(y)</li>\n<li>P(X&lt;&#x3D;x|Y&#x3D;y) &#x3D; ∫(X&lt;&#x3D;x) f(x|y)dx &#x3D; ∫(X&lt;&#x3D;x) f(x,y)&#x2F;f(y) dx</li>\n<li>P(X&lt;&#x3D;x|Y&gt;&#x3D;y) &#x3D; P(X&lt;&#x3D;x|Y&gt;&#x3D;y) &#x2F; P(Y&gt;&#x3D;y) &#x3D; ∫(Y&gt;&#x3D;y)∫(X&lt;&#x3D;x) f(x,y) dxdy &#x2F; ∫(Y&gt;&#x3D;y) f(y) dy</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>数字特征与相关性<ol>\n<li>均值的运算性质<ol>\n<li>求和定理(Sum of Means)：对任意随机变量 X₁,X₂,…,Xₙ（离散&#x2F;连续、独立&#x2F;依赖），E(X₁+X₂+…+Xₙ) &#x3D; E(X₁)+E(X₂)+…+E(Xₙ)</li>\n<li>乘积定理(Product of Means)：<strong>仅当X₁,X₂,…,Xₙ独立时（每个随机变量的取值都不会对其他随机变量的取值概率产生影响）（离散、连续都适用）</strong>，E(X₁X₂…Xₙ)&#x3D;E(X₁)E(X₂)…E(Xₙ)</li>\n</ol>\n</li>\n<li>独立性与不相关性<ol>\n<li>独立性(independent)：X与Y独立 -&gt; f(x,y) &#x3D; f(x)f(y)（离散pmf &#x2F; 连续pdf）</li>\n<li>不相关性(uncorrelated)：X与Y不相关 -&gt; E(XY) &#x3D; E(X)E(Y) -&gt; Cov(X,Y) &#x3D; 0 -&gt; ρ(X,Y) &#x3D; 0</li>\n<li>关系：独立→不相关，但不相关≠独立</li>\n</ol>\n</li>\n<li>协方差与相关系数<ol>\n<li>协方差(Covariance)：Cov(X,Y) &#x3D; E[(X-μ_X)(Y-μ_Y)] &#x3D; E(XY) - E(X)E(Y)，反映X与Y“同增同减” 趋势（Cov&gt;0：正相关，Cov&lt;0：负相关）</li>\n<li>相关系数(Correlation)：ρ(X,Y)&#x3D;Cov (X,Y)&#x2F;(σ_Xσ_Y)，ρ∈[-1,1]，是无量纲的线性关联度量<ol>\n<li>ρ&#x3D;1：完全正线性相关</li>\n<li>ρ&#x3D;-1：完全负线性相关</li>\n<li>ρ&#x3D;0：无线性相关</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>双变量正态分布<ol>\n<li>定义：X与Y联合正态 -&gt; 对任意 a,b∈R，aX+bY 正态分布</li>\n<li>关键性质：若 X 与 Y 联合正态且不相关（ρ&#x3D;0），则X与Y独立（区别于一般随机变量）</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"摘录\"><a href=\"#摘录\" class=\"headerlink\" title=\"摘录\"></a>摘录</h2><ol>\n<li>我们一步一步走下去，踏踏实实地去走，永不抗拒生命交给我们的重负，才是一个勇者。到了蓦然回首的那一瞬间，生命必然给我们公平的答案和又一次乍喜的心情，那时的山和水，又恢复成最初单纯的样子，而人生走过的是多么美好的一个秋天。 – 三毛</li>\n</ol>\n<h2 id=\"昨日总结\"><a href=\"#昨日总结\" class=\"headerlink\" title=\"昨日总结\"></a>昨日总结</h2><p>昨天参加了本学期第一次飞盘活动，感觉是开学以来参与感最强的一次活动了，既能够充分运动，也可以认识很多朋友（争取吧）</p>\n<h2 id=\"今日总结\"><a href=\"#今日总结\" class=\"headerlink\" title=\"今日总结\"></a>今日总结</h2><ol>\n<li>今天完成了概率课程的提交作业，整体写下来还是比较容易的，就是中途发现还是有些地方想得过于复杂了</li>\n<li>读书一章</li>\n<li>复习完全部单词</li>\n<li>本周第二次网球活动</li>\n</ol>\n"},{"title":"2025.10.13","date":"2025-10-13T02:25:54.000Z","_content":"# Overview\n1. 十一回顾\n2. 思考与摘录\n3. 今日学习笔记\n4. 迎新晚会感受\n\n## 十一回顾\n1. Day1：\n   1. 上午到达杭州，在办理入住前在大厅里学习了一会儿\n   2. 在办理完入住放好东西后去逛了杭州图书馆\n   3. 之后去了天目里逛了一圈并在茑屋书店呆了一会儿\n   4. 逛了五柳巷历史街区\n   5. 前往胜利河美食街吃完饭并买了防晒防虫喷雾\n2. Day2：\n   1. 早起坐车前往九溪烟树，走了九溪十八涧\n   2. 中午前到达龙井村，被一家热情人家拉进去喝了一会儿龙井茶，聊天的过程中了解了龙井茶主要是采摘的春茶，且根据采摘的时间不同品质也有所区分，可分为明前茶、雨前茶和雨后茶，且采摘完的茶还要炒三遍需要花费一个多小时\n   3. 在吃过午饭和买了点龙井茶后开始顺着十里锒铛开始爬茶山，一路直至云栖竹径出山\n   4. 晚上前往参加Anson Seabra的live house\n3. Day3：\n   1. 凌晨4点起床骑车前往西湖，到了后沿着北山街一路骑行欣赏夜景\n   2. 于5点在神舟基地景点坐等日出\n   3. 看完日出后骑行到西湖东南角开始环湖步行\n   4. 用了不到3小时换西湖一圈\n   5. 晚上前往城市阳台观看灯光秀\n4. Day4：\n   1. 早起前往灵隐寺，并把整个景区逛完\n   2. 骑车前往茅家埠，并徒步沿着湖边的小道把西湖西面逛完\n   3. 乘坐了水上公交7号线\n   4. 去了钟书阁\n5. Day5：\n   1. 参加了西湖边的国庆音乐喷泉\n   2. 买了伴手礼\n6. Day6：\n   1. 去到了拱宸桥，逛了博物馆，并沿着河道一路观赏\n   2. 乘坐了水上公交1号线\n   3. 去了顾雪岩旧居，并一路穿过街巷直至西湖边\n7. Day7:\n   1. 一整天在杭州宋城景区游玩\n8. Day8:\n   1. 逛了良渚古城遗址公园\n   2. 去了玉鸟集文艺街区\n9. Day9：\n    1. 逛了西溪湿地\n10. Day10：\n    1. 去了临安的青山湖，绕湖骑行一圈并参观了水上森林\n    2. 下午再次去到茑屋书店用一下午的时间看完了《通往夏天的隧道，再见的出口》一书\n\n由于最后一天晚上吃了一家过辣的饭导致接下来几天只能躺在宿舍\n\n\n## 思考与摘录\n\n思考：在旅行最后一下午我决心一直待在书店里看完一本书，最终总算在关店前看完了我此生最快速看完的一本书，我其实原本对看书就不是特别上心，虽然时常在脑海里闪过要多看书的念头，也常常去书店寻找自己感兴趣的书，但读着读着最后总会不了了之，所以这次我下定决心当天不看完不走，第一次快速完整的看完一本书真的很开心，而且其实之前就看过了这本书翻拍的电影，但这次读过原著后我深深体会到电影还是没办法很好展现书中的细节和打动人的地方的，所以经此转折我将对读书更进一步，我发现最近我读书的速度和耐心明显提升了，我终会将看书变成由衷热爱的事情  \n其次在旅行的其中一天我看到了一个让我收获很多的视频，视频采访了某个行业大佬，使我决定要将生活中的自己记录下来，我打算尝试拍点视频，而且也会在此后的博客文章中加入更多平日里的所思所想，这既是对自己的激励，也希望对日后读到这些内容的人们有所帮助\n\n文案摘录：\n1. 心灯不借他人火，自照乾坤步步明，人生如逆旅，你我皆行人，唯有不断悦己、阅己、越己，才能活出生命的真正意义\n2. 所有不尊重你的人，赌的都是你没有前途，他们赌你会忍，赌你会忘，赌你就算记得也没有本事反抗。所以你一定要记住你来时路的苦楚，待到来年春暖花开时，愿你安睡时山河入梦，醒来时满目春风，愿你快乐事有始有终，愿你未来路坦荡从容\n3. 大仁不仁\n\n\n## 学习笔记\n### 数据科学（统计）\n机器学习 -- 让计算机无需显式编程即可获得学习能力的研究领域  \n1. 与传统编程的区别：\n   1. 传统编程：数据 + 预设程序（函数） --通过程序中的函数进行计算--> 基于计算得到结果  \n   2. 机器学习：数据 + 期望输出  --通过曲线拟合（如线性回归）等方式推导程序--> 能预测新数据的程序（模型）  \n2. 机器学习的两种学习方式：\n   1. 记忆（memorization）：仅积累个体事实，限制于“观察事实的时间”和“储存事实的记忆空间”，无法应对未见过的情况\n   2. 泛化（generalization）：从已有的事实推导新事实，本质是一种预测活动，核心假设是“过去可以预测未来”，限制于“推导过程的准确性”，**是机器学习的核心**\n3. 机器学习的基本步骤：\n   1. 观察训练数据：获取用于学习的样本集合\n   2. 推断数据生成过程：通过算法（如线性回归拟合多项式曲线）分析训练数据，提炼数据背后的规律\n   3. 预测测试数据：利用推断出的规律，对未见过的样本（测试数据）进行预测\n4. 机器学习的核心范式：监督学习与无监督学习\n   1. 监督学习（supervised）：\n      1. 核心输入：包含 “特征 / 标签对” 的数据集，标签明确指示样本的类别\n      2. 核心目标：找到能预测标签的规则，为未见过的输入（仅特征）分配正确标签。\n      3. 关键任务：分类（classification）\n         1. 目标：在特征空间中找到分隔不同标签组的 “分类面”（如 2D 空间中的直线、高维空间中的平面）\n         2. 约束：需控制分类面复杂度，避免过拟合（若分类面过于复杂，会精准匹配训练数据但无法适应测试数据）\n         3. 权衡：当标签组存在重叠时，需平衡 “假阳性”（将负类误判为正类）与 “假阴性”（将正类误判为负类）\n      4. 案例：足球队员位置分类\n   2. 无监督学习（unsupervised）\n      1. 核心输入：仅包含特征向量的数据集，无任何标签信息\n      2. 核心目标：将数据自动分组为 “自然簇”（具有相似特征的样本集合），或为不同簇创建标签\n      3. 关键任务：聚类（clustering）\n         1. 聚类步骤：\n            1. 随机选择 k 个样本作为 “原型”（初始簇中心）\n            2. 计算剩余样本与各原型的距离，将样本归入距离最近的簇（最小化簇内样本距离，即优化目标函数）\n            3. 计算每个簇的中值样本，将其作为新原型\n            4. 重复步骤 2-3，直至原型不再变化\n         2. 关键指标：相似度（通过距离度量衡量，距离越小相似度越高）\n      4. 案例：足球队员身高体重聚类\n5. 机器学习方法的关键要素\n   1. 训练数据与评估方法\n      1. 数据划分：需将数据集随机分为 “训练集”（用于学习模型）与 “测试集”（用于评估模型泛化能力），避免用训练数据直接评估（易高估性能）\n      2. 评估逻辑：通过模型在测试集上的预测结果，判断模型是否能适应未见过的数据\n   2. 特征表示与特征工程\n      1. 核心观点：“所有模型都是错的，但有些是有用的”，特征的质量决定模型的有用性\n      2. 特征工程目标：构建 “高信噪比（SNR）” 的特征向量 —— 最大化 “有用输入”占比，最小化 “无关输入”占比，避免过拟合\n      3. 案例：爬行动物分类特征优化\n   3. 距离度量（Distance Metric）\n      1. 常用度量：闵可夫斯基度量\n         1. 当 p=1 时：曼哈顿距离，计算各维度差值的绝对值之和，适用于维度不可比的场景\n         2. 当 p=2 时：欧氏距离，计算各维度差值的平方和的平方根，是最常用的度量方式。\n      2. 案例：动物距离计算对比\n      3. 关键注意事项：需统一特征维度的权重，避免某一维度（如整数型腿数）对距离计算产生过度影响\n   4. 目标函数与约束\n      1. 目标函数：定义模型的优化方向（如聚类中 “最小化簇内样本距离”，分类中 “最大化分类面与样本的距离”）\n      2. 约束条件：限制模型复杂度（如聚类中指定簇数 k，分类中限制分类面为直线而非复杂曲线），避免过拟合\n   5. 优化方法：用于求解目标函数的算法，如聚类中 “更新簇中值为新原型”、分类中 “寻找最优分类面” 的梯度下降算法等\n6. **本节知识的重点问题**\n   1. 监督学习与无监督学习的核心差异是什么？在实际应用中如何选择这两种范式？\n      1. 二者的核心差异体现在数据要求与核心目标上：\n         1. 数据要求：监督学习需 “特征 / 标签对”，无监督学习仅需无标签特征向量\n         2. 核心目标：监督学习目标是构建分类器，为新输入预测标签；无监督学习目标是将数据聚类为自然簇，挖掘隐含分组\n      2. 实际应用选择依据：\n         1. 若有明确的标签数据，且需预测新样本标签，选择监督学习\n         2. 若无标签数据，仅需探索数据内在结构，或为后续监督学习生成初始标签，选择无监督学习\n   2. 特征工程在机器学习中扮演什么角色？如何通过特征工程提升模型性能？\n      1. 特征工程的核心角色是构建高信噪比（SNR）的特征向量，即筛选 “有用输入”、剔除 “无关输入”，直接决定模型能否从数据中学习到有效规律\n      2. 提升模型性能的方式：\n         1. 保留有用特征：选择与目标强相关的特征\n         2. 剔除无关特征：移除与目标无关的特征\n         3. 优化特征格式：统一特征维度权重（如将整数型 “腿数” 转为二进制，避免距离计算偏差）\n   3. 什么是过拟合？为什么会出现过拟合？如何通过模型设计或评估方式避免过拟合？\n      1. 过拟合定义：模型在训练数据上表现极佳，但在测试数据上表现差，即模型过度学习训练数据的噪声，而非普遍规律，无法泛化到新数据\n      2. 过拟合原因：\n         1. 模型复杂度过高\n         2. 特征质量差\n         3. 仅用训练数据评估模型\n      3. 避免方式：\n         1. 控制模型复杂度：如分类时选择简单分类面（直线 / 平面），聚类时限制簇数 k（而非 k 等于样本数）\n         2. 优化特征工程：剔除无关特征，提升信噪比\n         3. 合理划分数据与评估：将数据分为训练集与测试集，仅通过测试集性能判断模型好坏（如复杂模型训练准确率高但测试准确率低，需放弃）\n         4. 权衡假阳性与假阴性：避免为追求训练准确率而构建过度复杂的模型\n\n    \n## 迎新晚会总结\n今天的表演还算是成功吧，和上一次相比明显放松多了，而且这次的听众也挺多，再接再厉吧。","source":"_posts/2025-10-13.md","raw":"---\ntitle: 2025.10.13\ndate: 2025-10-13 10:25:54\ntags:\n---\n# Overview\n1. 十一回顾\n2. 思考与摘录\n3. 今日学习笔记\n4. 迎新晚会感受\n\n## 十一回顾\n1. Day1：\n   1. 上午到达杭州，在办理入住前在大厅里学习了一会儿\n   2. 在办理完入住放好东西后去逛了杭州图书馆\n   3. 之后去了天目里逛了一圈并在茑屋书店呆了一会儿\n   4. 逛了五柳巷历史街区\n   5. 前往胜利河美食街吃完饭并买了防晒防虫喷雾\n2. Day2：\n   1. 早起坐车前往九溪烟树，走了九溪十八涧\n   2. 中午前到达龙井村，被一家热情人家拉进去喝了一会儿龙井茶，聊天的过程中了解了龙井茶主要是采摘的春茶，且根据采摘的时间不同品质也有所区分，可分为明前茶、雨前茶和雨后茶，且采摘完的茶还要炒三遍需要花费一个多小时\n   3. 在吃过午饭和买了点龙井茶后开始顺着十里锒铛开始爬茶山，一路直至云栖竹径出山\n   4. 晚上前往参加Anson Seabra的live house\n3. Day3：\n   1. 凌晨4点起床骑车前往西湖，到了后沿着北山街一路骑行欣赏夜景\n   2. 于5点在神舟基地景点坐等日出\n   3. 看完日出后骑行到西湖东南角开始环湖步行\n   4. 用了不到3小时换西湖一圈\n   5. 晚上前往城市阳台观看灯光秀\n4. Day4：\n   1. 早起前往灵隐寺，并把整个景区逛完\n   2. 骑车前往茅家埠，并徒步沿着湖边的小道把西湖西面逛完\n   3. 乘坐了水上公交7号线\n   4. 去了钟书阁\n5. Day5：\n   1. 参加了西湖边的国庆音乐喷泉\n   2. 买了伴手礼\n6. Day6：\n   1. 去到了拱宸桥，逛了博物馆，并沿着河道一路观赏\n   2. 乘坐了水上公交1号线\n   3. 去了顾雪岩旧居，并一路穿过街巷直至西湖边\n7. Day7:\n   1. 一整天在杭州宋城景区游玩\n8. Day8:\n   1. 逛了良渚古城遗址公园\n   2. 去了玉鸟集文艺街区\n9. Day9：\n    1. 逛了西溪湿地\n10. Day10：\n    1. 去了临安的青山湖，绕湖骑行一圈并参观了水上森林\n    2. 下午再次去到茑屋书店用一下午的时间看完了《通往夏天的隧道，再见的出口》一书\n\n由于最后一天晚上吃了一家过辣的饭导致接下来几天只能躺在宿舍\n\n\n## 思考与摘录\n\n思考：在旅行最后一下午我决心一直待在书店里看完一本书，最终总算在关店前看完了我此生最快速看完的一本书，我其实原本对看书就不是特别上心，虽然时常在脑海里闪过要多看书的念头，也常常去书店寻找自己感兴趣的书，但读着读着最后总会不了了之，所以这次我下定决心当天不看完不走，第一次快速完整的看完一本书真的很开心，而且其实之前就看过了这本书翻拍的电影，但这次读过原著后我深深体会到电影还是没办法很好展现书中的细节和打动人的地方的，所以经此转折我将对读书更进一步，我发现最近我读书的速度和耐心明显提升了，我终会将看书变成由衷热爱的事情  \n其次在旅行的其中一天我看到了一个让我收获很多的视频，视频采访了某个行业大佬，使我决定要将生活中的自己记录下来，我打算尝试拍点视频，而且也会在此后的博客文章中加入更多平日里的所思所想，这既是对自己的激励，也希望对日后读到这些内容的人们有所帮助\n\n文案摘录：\n1. 心灯不借他人火，自照乾坤步步明，人生如逆旅，你我皆行人，唯有不断悦己、阅己、越己，才能活出生命的真正意义\n2. 所有不尊重你的人，赌的都是你没有前途，他们赌你会忍，赌你会忘，赌你就算记得也没有本事反抗。所以你一定要记住你来时路的苦楚，待到来年春暖花开时，愿你安睡时山河入梦，醒来时满目春风，愿你快乐事有始有终，愿你未来路坦荡从容\n3. 大仁不仁\n\n\n## 学习笔记\n### 数据科学（统计）\n机器学习 -- 让计算机无需显式编程即可获得学习能力的研究领域  \n1. 与传统编程的区别：\n   1. 传统编程：数据 + 预设程序（函数） --通过程序中的函数进行计算--> 基于计算得到结果  \n   2. 机器学习：数据 + 期望输出  --通过曲线拟合（如线性回归）等方式推导程序--> 能预测新数据的程序（模型）  \n2. 机器学习的两种学习方式：\n   1. 记忆（memorization）：仅积累个体事实，限制于“观察事实的时间”和“储存事实的记忆空间”，无法应对未见过的情况\n   2. 泛化（generalization）：从已有的事实推导新事实，本质是一种预测活动，核心假设是“过去可以预测未来”，限制于“推导过程的准确性”，**是机器学习的核心**\n3. 机器学习的基本步骤：\n   1. 观察训练数据：获取用于学习的样本集合\n   2. 推断数据生成过程：通过算法（如线性回归拟合多项式曲线）分析训练数据，提炼数据背后的规律\n   3. 预测测试数据：利用推断出的规律，对未见过的样本（测试数据）进行预测\n4. 机器学习的核心范式：监督学习与无监督学习\n   1. 监督学习（supervised）：\n      1. 核心输入：包含 “特征 / 标签对” 的数据集，标签明确指示样本的类别\n      2. 核心目标：找到能预测标签的规则，为未见过的输入（仅特征）分配正确标签。\n      3. 关键任务：分类（classification）\n         1. 目标：在特征空间中找到分隔不同标签组的 “分类面”（如 2D 空间中的直线、高维空间中的平面）\n         2. 约束：需控制分类面复杂度，避免过拟合（若分类面过于复杂，会精准匹配训练数据但无法适应测试数据）\n         3. 权衡：当标签组存在重叠时，需平衡 “假阳性”（将负类误判为正类）与 “假阴性”（将正类误判为负类）\n      4. 案例：足球队员位置分类\n   2. 无监督学习（unsupervised）\n      1. 核心输入：仅包含特征向量的数据集，无任何标签信息\n      2. 核心目标：将数据自动分组为 “自然簇”（具有相似特征的样本集合），或为不同簇创建标签\n      3. 关键任务：聚类（clustering）\n         1. 聚类步骤：\n            1. 随机选择 k 个样本作为 “原型”（初始簇中心）\n            2. 计算剩余样本与各原型的距离，将样本归入距离最近的簇（最小化簇内样本距离，即优化目标函数）\n            3. 计算每个簇的中值样本，将其作为新原型\n            4. 重复步骤 2-3，直至原型不再变化\n         2. 关键指标：相似度（通过距离度量衡量，距离越小相似度越高）\n      4. 案例：足球队员身高体重聚类\n5. 机器学习方法的关键要素\n   1. 训练数据与评估方法\n      1. 数据划分：需将数据集随机分为 “训练集”（用于学习模型）与 “测试集”（用于评估模型泛化能力），避免用训练数据直接评估（易高估性能）\n      2. 评估逻辑：通过模型在测试集上的预测结果，判断模型是否能适应未见过的数据\n   2. 特征表示与特征工程\n      1. 核心观点：“所有模型都是错的，但有些是有用的”，特征的质量决定模型的有用性\n      2. 特征工程目标：构建 “高信噪比（SNR）” 的特征向量 —— 最大化 “有用输入”占比，最小化 “无关输入”占比，避免过拟合\n      3. 案例：爬行动物分类特征优化\n   3. 距离度量（Distance Metric）\n      1. 常用度量：闵可夫斯基度量\n         1. 当 p=1 时：曼哈顿距离，计算各维度差值的绝对值之和，适用于维度不可比的场景\n         2. 当 p=2 时：欧氏距离，计算各维度差值的平方和的平方根，是最常用的度量方式。\n      2. 案例：动物距离计算对比\n      3. 关键注意事项：需统一特征维度的权重，避免某一维度（如整数型腿数）对距离计算产生过度影响\n   4. 目标函数与约束\n      1. 目标函数：定义模型的优化方向（如聚类中 “最小化簇内样本距离”，分类中 “最大化分类面与样本的距离”）\n      2. 约束条件：限制模型复杂度（如聚类中指定簇数 k，分类中限制分类面为直线而非复杂曲线），避免过拟合\n   5. 优化方法：用于求解目标函数的算法，如聚类中 “更新簇中值为新原型”、分类中 “寻找最优分类面” 的梯度下降算法等\n6. **本节知识的重点问题**\n   1. 监督学习与无监督学习的核心差异是什么？在实际应用中如何选择这两种范式？\n      1. 二者的核心差异体现在数据要求与核心目标上：\n         1. 数据要求：监督学习需 “特征 / 标签对”，无监督学习仅需无标签特征向量\n         2. 核心目标：监督学习目标是构建分类器，为新输入预测标签；无监督学习目标是将数据聚类为自然簇，挖掘隐含分组\n      2. 实际应用选择依据：\n         1. 若有明确的标签数据，且需预测新样本标签，选择监督学习\n         2. 若无标签数据，仅需探索数据内在结构，或为后续监督学习生成初始标签，选择无监督学习\n   2. 特征工程在机器学习中扮演什么角色？如何通过特征工程提升模型性能？\n      1. 特征工程的核心角色是构建高信噪比（SNR）的特征向量，即筛选 “有用输入”、剔除 “无关输入”，直接决定模型能否从数据中学习到有效规律\n      2. 提升模型性能的方式：\n         1. 保留有用特征：选择与目标强相关的特征\n         2. 剔除无关特征：移除与目标无关的特征\n         3. 优化特征格式：统一特征维度权重（如将整数型 “腿数” 转为二进制，避免距离计算偏差）\n   3. 什么是过拟合？为什么会出现过拟合？如何通过模型设计或评估方式避免过拟合？\n      1. 过拟合定义：模型在训练数据上表现极佳，但在测试数据上表现差，即模型过度学习训练数据的噪声，而非普遍规律，无法泛化到新数据\n      2. 过拟合原因：\n         1. 模型复杂度过高\n         2. 特征质量差\n         3. 仅用训练数据评估模型\n      3. 避免方式：\n         1. 控制模型复杂度：如分类时选择简单分类面（直线 / 平面），聚类时限制簇数 k（而非 k 等于样本数）\n         2. 优化特征工程：剔除无关特征，提升信噪比\n         3. 合理划分数据与评估：将数据分为训练集与测试集，仅通过测试集性能判断模型好坏（如复杂模型训练准确率高但测试准确率低，需放弃）\n         4. 权衡假阳性与假阴性：避免为追求训练准确率而构建过度复杂的模型\n\n    \n## 迎新晚会总结\n今天的表演还算是成功吧，和上一次相比明显放松多了，而且这次的听众也挺多，再接再厉吧。","slug":"2025-10-13","published":1,"updated":"2025-11-18T19:39:17.124Z","comments":1,"layout":"post","photos":[],"_id":"cuidmSpRlc2cIK-m3uQ9_eWJv","content":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>十一回顾</li>\n<li>思考与摘录</li>\n<li>今日学习笔记</li>\n<li>迎新晚会感受</li>\n</ol>\n<h2 id=\"十一回顾\"><a href=\"#十一回顾\" class=\"headerlink\" title=\"十一回顾\"></a>十一回顾</h2><ol>\n<li>Day1：<ol>\n<li>上午到达杭州，在办理入住前在大厅里学习了一会儿</li>\n<li>在办理完入住放好东西后去逛了杭州图书馆</li>\n<li>之后去了天目里逛了一圈并在茑屋书店呆了一会儿</li>\n<li>逛了五柳巷历史街区</li>\n<li>前往胜利河美食街吃完饭并买了防晒防虫喷雾</li>\n</ol>\n</li>\n<li>Day2：<ol>\n<li>早起坐车前往九溪烟树，走了九溪十八涧</li>\n<li>中午前到达龙井村，被一家热情人家拉进去喝了一会儿龙井茶，聊天的过程中了解了龙井茶主要是采摘的春茶，且根据采摘的时间不同品质也有所区分，可分为明前茶、雨前茶和雨后茶，且采摘完的茶还要炒三遍需要花费一个多小时</li>\n<li>在吃过午饭和买了点龙井茶后开始顺着十里锒铛开始爬茶山，一路直至云栖竹径出山</li>\n<li>晚上前往参加Anson Seabra的live house</li>\n</ol>\n</li>\n<li>Day3：<ol>\n<li>凌晨4点起床骑车前往西湖，到了后沿着北山街一路骑行欣赏夜景</li>\n<li>于5点在神舟基地景点坐等日出</li>\n<li>看完日出后骑行到西湖东南角开始环湖步行</li>\n<li>用了不到3小时换西湖一圈</li>\n<li>晚上前往城市阳台观看灯光秀</li>\n</ol>\n</li>\n<li>Day4：<ol>\n<li>早起前往灵隐寺，并把整个景区逛完</li>\n<li>骑车前往茅家埠，并徒步沿着湖边的小道把西湖西面逛完</li>\n<li>乘坐了水上公交7号线</li>\n<li>去了钟书阁</li>\n</ol>\n</li>\n<li>Day5：<ol>\n<li>参加了西湖边的国庆音乐喷泉</li>\n<li>买了伴手礼</li>\n</ol>\n</li>\n<li>Day6：<ol>\n<li>去到了拱宸桥，逛了博物馆，并沿着河道一路观赏</li>\n<li>乘坐了水上公交1号线</li>\n<li>去了顾雪岩旧居，并一路穿过街巷直至西湖边</li>\n</ol>\n</li>\n<li>Day7:<ol>\n<li>一整天在杭州宋城景区游玩</li>\n</ol>\n</li>\n<li>Day8:<ol>\n<li>逛了良渚古城遗址公园</li>\n<li>去了玉鸟集文艺街区</li>\n</ol>\n</li>\n<li>Day9：<ol>\n<li>逛了西溪湿地</li>\n</ol>\n</li>\n<li>Day10：<ol>\n<li>去了临安的青山湖，绕湖骑行一圈并参观了水上森林</li>\n<li>下午再次去到茑屋书店用一下午的时间看完了《通往夏天的隧道，再见的出口》一书</li>\n</ol>\n</li>\n</ol>\n<p>由于最后一天晚上吃了一家过辣的饭导致接下来几天只能躺在宿舍</p>\n<h2 id=\"思考与摘录\"><a href=\"#思考与摘录\" class=\"headerlink\" title=\"思考与摘录\"></a>思考与摘录</h2><p>思考：在旅行最后一下午我决心一直待在书店里看完一本书，最终总算在关店前看完了我此生最快速看完的一本书，我其实原本对看书就不是特别上心，虽然时常在脑海里闪过要多看书的念头，也常常去书店寻找自己感兴趣的书，但读着读着最后总会不了了之，所以这次我下定决心当天不看完不走，第一次快速完整的看完一本书真的很开心，而且其实之前就看过了这本书翻拍的电影，但这次读过原著后我深深体会到电影还是没办法很好展现书中的细节和打动人的地方的，所以经此转折我将对读书更进一步，我发现最近我读书的速度和耐心明显提升了，我终会将看书变成由衷热爱的事情<br>其次在旅行的其中一天我看到了一个让我收获很多的视频，视频采访了某个行业大佬，使我决定要将生活中的自己记录下来，我打算尝试拍点视频，而且也会在此后的博客文章中加入更多平日里的所思所想，这既是对自己的激励，也希望对日后读到这些内容的人们有所帮助</p>\n<p>文案摘录：</p>\n<ol>\n<li>心灯不借他人火，自照乾坤步步明，人生如逆旅，你我皆行人，唯有不断悦己、阅己、越己，才能活出生命的真正意义</li>\n<li>所有不尊重你的人，赌的都是你没有前途，他们赌你会忍，赌你会忘，赌你就算记得也没有本事反抗。所以你一定要记住你来时路的苦楚，待到来年春暖花开时，愿你安睡时山河入梦，醒来时满目春风，愿你快乐事有始有终，愿你未来路坦荡从容</li>\n<li>大仁不仁</li>\n</ol>\n<h2 id=\"学习笔记\"><a href=\"#学习笔记\" class=\"headerlink\" title=\"学习笔记\"></a>学习笔记</h2><h3 id=\"数据科学（统计）\"><a href=\"#数据科学（统计）\" class=\"headerlink\" title=\"数据科学（统计）\"></a>数据科学（统计）</h3><p>机器学习 – 让计算机无需显式编程即可获得学习能力的研究领域  </p>\n<ol>\n<li>与传统编程的区别：<ol>\n<li>传统编程：数据 + 预设程序（函数） –通过程序中的函数进行计算–&gt; 基于计算得到结果  </li>\n<li>机器学习：数据 + 期望输出  –通过曲线拟合（如线性回归）等方式推导程序–&gt; 能预测新数据的程序（模型）</li>\n</ol>\n</li>\n<li>机器学习的两种学习方式：<ol>\n<li>记忆（memorization）：仅积累个体事实，限制于“观察事实的时间”和“储存事实的记忆空间”，无法应对未见过的情况</li>\n<li>泛化（generalization）：从已有的事实推导新事实，本质是一种预测活动，核心假设是“过去可以预测未来”，限制于“推导过程的准确性”，<strong>是机器学习的核心</strong></li>\n</ol>\n</li>\n<li>机器学习的基本步骤：<ol>\n<li>观察训练数据：获取用于学习的样本集合</li>\n<li>推断数据生成过程：通过算法（如线性回归拟合多项式曲线）分析训练数据，提炼数据背后的规律</li>\n<li>预测测试数据：利用推断出的规律，对未见过的样本（测试数据）进行预测</li>\n</ol>\n</li>\n<li>机器学习的核心范式：监督学习与无监督学习<ol>\n<li>监督学习（supervised）：<ol>\n<li>核心输入：包含 “特征 &#x2F; 标签对” 的数据集，标签明确指示样本的类别</li>\n<li>核心目标：找到能预测标签的规则，为未见过的输入（仅特征）分配正确标签。</li>\n<li>关键任务：分类（classification）<ol>\n<li>目标：在特征空间中找到分隔不同标签组的 “分类面”（如 2D 空间中的直线、高维空间中的平面）</li>\n<li>约束：需控制分类面复杂度，避免过拟合（若分类面过于复杂，会精准匹配训练数据但无法适应测试数据）</li>\n<li>权衡：当标签组存在重叠时，需平衡 “假阳性”（将负类误判为正类）与 “假阴性”（将正类误判为负类）</li>\n</ol>\n</li>\n<li>案例：足球队员位置分类</li>\n</ol>\n</li>\n<li>无监督学习（unsupervised）<ol>\n<li>核心输入：仅包含特征向量的数据集，无任何标签信息</li>\n<li>核心目标：将数据自动分组为 “自然簇”（具有相似特征的样本集合），或为不同簇创建标签</li>\n<li>关键任务：聚类（clustering）<ol>\n<li>聚类步骤：<ol>\n<li>随机选择 k 个样本作为 “原型”（初始簇中心）</li>\n<li>计算剩余样本与各原型的距离，将样本归入距离最近的簇（最小化簇内样本距离，即优化目标函数）</li>\n<li>计算每个簇的中值样本，将其作为新原型</li>\n<li>重复步骤 2-3，直至原型不再变化</li>\n</ol>\n</li>\n<li>关键指标：相似度（通过距离度量衡量，距离越小相似度越高）</li>\n</ol>\n</li>\n<li>案例：足球队员身高体重聚类</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>机器学习方法的关键要素<ol>\n<li>训练数据与评估方法<ol>\n<li>数据划分：需将数据集随机分为 “训练集”（用于学习模型）与 “测试集”（用于评估模型泛化能力），避免用训练数据直接评估（易高估性能）</li>\n<li>评估逻辑：通过模型在测试集上的预测结果，判断模型是否能适应未见过的数据</li>\n</ol>\n</li>\n<li>特征表示与特征工程<ol>\n<li>核心观点：“所有模型都是错的，但有些是有用的”，特征的质量决定模型的有用性</li>\n<li>特征工程目标：构建 “高信噪比（SNR）” 的特征向量 —— 最大化 “有用输入”占比，最小化 “无关输入”占比，避免过拟合</li>\n<li>案例：爬行动物分类特征优化</li>\n</ol>\n</li>\n<li>距离度量（Distance Metric）<ol>\n<li>常用度量：闵可夫斯基度量<ol>\n<li>当 p&#x3D;1 时：曼哈顿距离，计算各维度差值的绝对值之和，适用于维度不可比的场景</li>\n<li>当 p&#x3D;2 时：欧氏距离，计算各维度差值的平方和的平方根，是最常用的度量方式。</li>\n</ol>\n</li>\n<li>案例：动物距离计算对比</li>\n<li>关键注意事项：需统一特征维度的权重，避免某一维度（如整数型腿数）对距离计算产生过度影响</li>\n</ol>\n</li>\n<li>目标函数与约束<ol>\n<li>目标函数：定义模型的优化方向（如聚类中 “最小化簇内样本距离”，分类中 “最大化分类面与样本的距离”）</li>\n<li>约束条件：限制模型复杂度（如聚类中指定簇数 k，分类中限制分类面为直线而非复杂曲线），避免过拟合</li>\n</ol>\n</li>\n<li>优化方法：用于求解目标函数的算法，如聚类中 “更新簇中值为新原型”、分类中 “寻找最优分类面” 的梯度下降算法等</li>\n</ol>\n</li>\n<li><strong>本节知识的重点问题</strong><ol>\n<li>监督学习与无监督学习的核心差异是什么？在实际应用中如何选择这两种范式？<ol>\n<li>二者的核心差异体现在数据要求与核心目标上：<ol>\n<li>数据要求：监督学习需 “特征 &#x2F; 标签对”，无监督学习仅需无标签特征向量</li>\n<li>核心目标：监督学习目标是构建分类器，为新输入预测标签；无监督学习目标是将数据聚类为自然簇，挖掘隐含分组</li>\n</ol>\n</li>\n<li>实际应用选择依据：<ol>\n<li>若有明确的标签数据，且需预测新样本标签，选择监督学习</li>\n<li>若无标签数据，仅需探索数据内在结构，或为后续监督学习生成初始标签，选择无监督学习</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>特征工程在机器学习中扮演什么角色？如何通过特征工程提升模型性能？<ol>\n<li>特征工程的核心角色是构建高信噪比（SNR）的特征向量，即筛选 “有用输入”、剔除 “无关输入”，直接决定模型能否从数据中学习到有效规律</li>\n<li>提升模型性能的方式：<ol>\n<li>保留有用特征：选择与目标强相关的特征</li>\n<li>剔除无关特征：移除与目标无关的特征</li>\n<li>优化特征格式：统一特征维度权重（如将整数型 “腿数” 转为二进制，避免距离计算偏差）</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>什么是过拟合？为什么会出现过拟合？如何通过模型设计或评估方式避免过拟合？<ol>\n<li>过拟合定义：模型在训练数据上表现极佳，但在测试数据上表现差，即模型过度学习训练数据的噪声，而非普遍规律，无法泛化到新数据</li>\n<li>过拟合原因：<ol>\n<li>模型复杂度过高</li>\n<li>特征质量差</li>\n<li>仅用训练数据评估模型</li>\n</ol>\n</li>\n<li>避免方式：<ol>\n<li>控制模型复杂度：如分类时选择简单分类面（直线 &#x2F; 平面），聚类时限制簇数 k（而非 k 等于样本数）</li>\n<li>优化特征工程：剔除无关特征，提升信噪比</li>\n<li>合理划分数据与评估：将数据分为训练集与测试集，仅通过测试集性能判断模型好坏（如复杂模型训练准确率高但测试准确率低，需放弃）</li>\n<li>权衡假阳性与假阴性：避免为追求训练准确率而构建过度复杂的模型</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"迎新晚会总结\"><a href=\"#迎新晚会总结\" class=\"headerlink\" title=\"迎新晚会总结\"></a>迎新晚会总结</h2><p>今天的表演还算是成功吧，和上一次相比明显放松多了，而且这次的听众也挺多，再接再厉吧。</p>\n","excerpt":"","more":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>十一回顾</li>\n<li>思考与摘录</li>\n<li>今日学习笔记</li>\n<li>迎新晚会感受</li>\n</ol>\n<h2 id=\"十一回顾\"><a href=\"#十一回顾\" class=\"headerlink\" title=\"十一回顾\"></a>十一回顾</h2><ol>\n<li>Day1：<ol>\n<li>上午到达杭州，在办理入住前在大厅里学习了一会儿</li>\n<li>在办理完入住放好东西后去逛了杭州图书馆</li>\n<li>之后去了天目里逛了一圈并在茑屋书店呆了一会儿</li>\n<li>逛了五柳巷历史街区</li>\n<li>前往胜利河美食街吃完饭并买了防晒防虫喷雾</li>\n</ol>\n</li>\n<li>Day2：<ol>\n<li>早起坐车前往九溪烟树，走了九溪十八涧</li>\n<li>中午前到达龙井村，被一家热情人家拉进去喝了一会儿龙井茶，聊天的过程中了解了龙井茶主要是采摘的春茶，且根据采摘的时间不同品质也有所区分，可分为明前茶、雨前茶和雨后茶，且采摘完的茶还要炒三遍需要花费一个多小时</li>\n<li>在吃过午饭和买了点龙井茶后开始顺着十里锒铛开始爬茶山，一路直至云栖竹径出山</li>\n<li>晚上前往参加Anson Seabra的live house</li>\n</ol>\n</li>\n<li>Day3：<ol>\n<li>凌晨4点起床骑车前往西湖，到了后沿着北山街一路骑行欣赏夜景</li>\n<li>于5点在神舟基地景点坐等日出</li>\n<li>看完日出后骑行到西湖东南角开始环湖步行</li>\n<li>用了不到3小时换西湖一圈</li>\n<li>晚上前往城市阳台观看灯光秀</li>\n</ol>\n</li>\n<li>Day4：<ol>\n<li>早起前往灵隐寺，并把整个景区逛完</li>\n<li>骑车前往茅家埠，并徒步沿着湖边的小道把西湖西面逛完</li>\n<li>乘坐了水上公交7号线</li>\n<li>去了钟书阁</li>\n</ol>\n</li>\n<li>Day5：<ol>\n<li>参加了西湖边的国庆音乐喷泉</li>\n<li>买了伴手礼</li>\n</ol>\n</li>\n<li>Day6：<ol>\n<li>去到了拱宸桥，逛了博物馆，并沿着河道一路观赏</li>\n<li>乘坐了水上公交1号线</li>\n<li>去了顾雪岩旧居，并一路穿过街巷直至西湖边</li>\n</ol>\n</li>\n<li>Day7:<ol>\n<li>一整天在杭州宋城景区游玩</li>\n</ol>\n</li>\n<li>Day8:<ol>\n<li>逛了良渚古城遗址公园</li>\n<li>去了玉鸟集文艺街区</li>\n</ol>\n</li>\n<li>Day9：<ol>\n<li>逛了西溪湿地</li>\n</ol>\n</li>\n<li>Day10：<ol>\n<li>去了临安的青山湖，绕湖骑行一圈并参观了水上森林</li>\n<li>下午再次去到茑屋书店用一下午的时间看完了《通往夏天的隧道，再见的出口》一书</li>\n</ol>\n</li>\n</ol>\n<p>由于最后一天晚上吃了一家过辣的饭导致接下来几天只能躺在宿舍</p>\n<h2 id=\"思考与摘录\"><a href=\"#思考与摘录\" class=\"headerlink\" title=\"思考与摘录\"></a>思考与摘录</h2><p>思考：在旅行最后一下午我决心一直待在书店里看完一本书，最终总算在关店前看完了我此生最快速看完的一本书，我其实原本对看书就不是特别上心，虽然时常在脑海里闪过要多看书的念头，也常常去书店寻找自己感兴趣的书，但读着读着最后总会不了了之，所以这次我下定决心当天不看完不走，第一次快速完整的看完一本书真的很开心，而且其实之前就看过了这本书翻拍的电影，但这次读过原著后我深深体会到电影还是没办法很好展现书中的细节和打动人的地方的，所以经此转折我将对读书更进一步，我发现最近我读书的速度和耐心明显提升了，我终会将看书变成由衷热爱的事情<br>其次在旅行的其中一天我看到了一个让我收获很多的视频，视频采访了某个行业大佬，使我决定要将生活中的自己记录下来，我打算尝试拍点视频，而且也会在此后的博客文章中加入更多平日里的所思所想，这既是对自己的激励，也希望对日后读到这些内容的人们有所帮助</p>\n<p>文案摘录：</p>\n<ol>\n<li>心灯不借他人火，自照乾坤步步明，人生如逆旅，你我皆行人，唯有不断悦己、阅己、越己，才能活出生命的真正意义</li>\n<li>所有不尊重你的人，赌的都是你没有前途，他们赌你会忍，赌你会忘，赌你就算记得也没有本事反抗。所以你一定要记住你来时路的苦楚，待到来年春暖花开时，愿你安睡时山河入梦，醒来时满目春风，愿你快乐事有始有终，愿你未来路坦荡从容</li>\n<li>大仁不仁</li>\n</ol>\n<h2 id=\"学习笔记\"><a href=\"#学习笔记\" class=\"headerlink\" title=\"学习笔记\"></a>学习笔记</h2><h3 id=\"数据科学（统计）\"><a href=\"#数据科学（统计）\" class=\"headerlink\" title=\"数据科学（统计）\"></a>数据科学（统计）</h3><p>机器学习 – 让计算机无需显式编程即可获得学习能力的研究领域  </p>\n<ol>\n<li>与传统编程的区别：<ol>\n<li>传统编程：数据 + 预设程序（函数） –通过程序中的函数进行计算–&gt; 基于计算得到结果  </li>\n<li>机器学习：数据 + 期望输出  –通过曲线拟合（如线性回归）等方式推导程序–&gt; 能预测新数据的程序（模型）</li>\n</ol>\n</li>\n<li>机器学习的两种学习方式：<ol>\n<li>记忆（memorization）：仅积累个体事实，限制于“观察事实的时间”和“储存事实的记忆空间”，无法应对未见过的情况</li>\n<li>泛化（generalization）：从已有的事实推导新事实，本质是一种预测活动，核心假设是“过去可以预测未来”，限制于“推导过程的准确性”，<strong>是机器学习的核心</strong></li>\n</ol>\n</li>\n<li>机器学习的基本步骤：<ol>\n<li>观察训练数据：获取用于学习的样本集合</li>\n<li>推断数据生成过程：通过算法（如线性回归拟合多项式曲线）分析训练数据，提炼数据背后的规律</li>\n<li>预测测试数据：利用推断出的规律，对未见过的样本（测试数据）进行预测</li>\n</ol>\n</li>\n<li>机器学习的核心范式：监督学习与无监督学习<ol>\n<li>监督学习（supervised）：<ol>\n<li>核心输入：包含 “特征 &#x2F; 标签对” 的数据集，标签明确指示样本的类别</li>\n<li>核心目标：找到能预测标签的规则，为未见过的输入（仅特征）分配正确标签。</li>\n<li>关键任务：分类（classification）<ol>\n<li>目标：在特征空间中找到分隔不同标签组的 “分类面”（如 2D 空间中的直线、高维空间中的平面）</li>\n<li>约束：需控制分类面复杂度，避免过拟合（若分类面过于复杂，会精准匹配训练数据但无法适应测试数据）</li>\n<li>权衡：当标签组存在重叠时，需平衡 “假阳性”（将负类误判为正类）与 “假阴性”（将正类误判为负类）</li>\n</ol>\n</li>\n<li>案例：足球队员位置分类</li>\n</ol>\n</li>\n<li>无监督学习（unsupervised）<ol>\n<li>核心输入：仅包含特征向量的数据集，无任何标签信息</li>\n<li>核心目标：将数据自动分组为 “自然簇”（具有相似特征的样本集合），或为不同簇创建标签</li>\n<li>关键任务：聚类（clustering）<ol>\n<li>聚类步骤：<ol>\n<li>随机选择 k 个样本作为 “原型”（初始簇中心）</li>\n<li>计算剩余样本与各原型的距离，将样本归入距离最近的簇（最小化簇内样本距离，即优化目标函数）</li>\n<li>计算每个簇的中值样本，将其作为新原型</li>\n<li>重复步骤 2-3，直至原型不再变化</li>\n</ol>\n</li>\n<li>关键指标：相似度（通过距离度量衡量，距离越小相似度越高）</li>\n</ol>\n</li>\n<li>案例：足球队员身高体重聚类</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>机器学习方法的关键要素<ol>\n<li>训练数据与评估方法<ol>\n<li>数据划分：需将数据集随机分为 “训练集”（用于学习模型）与 “测试集”（用于评估模型泛化能力），避免用训练数据直接评估（易高估性能）</li>\n<li>评估逻辑：通过模型在测试集上的预测结果，判断模型是否能适应未见过的数据</li>\n</ol>\n</li>\n<li>特征表示与特征工程<ol>\n<li>核心观点：“所有模型都是错的，但有些是有用的”，特征的质量决定模型的有用性</li>\n<li>特征工程目标：构建 “高信噪比（SNR）” 的特征向量 —— 最大化 “有用输入”占比，最小化 “无关输入”占比，避免过拟合</li>\n<li>案例：爬行动物分类特征优化</li>\n</ol>\n</li>\n<li>距离度量（Distance Metric）<ol>\n<li>常用度量：闵可夫斯基度量<ol>\n<li>当 p&#x3D;1 时：曼哈顿距离，计算各维度差值的绝对值之和，适用于维度不可比的场景</li>\n<li>当 p&#x3D;2 时：欧氏距离，计算各维度差值的平方和的平方根，是最常用的度量方式。</li>\n</ol>\n</li>\n<li>案例：动物距离计算对比</li>\n<li>关键注意事项：需统一特征维度的权重，避免某一维度（如整数型腿数）对距离计算产生过度影响</li>\n</ol>\n</li>\n<li>目标函数与约束<ol>\n<li>目标函数：定义模型的优化方向（如聚类中 “最小化簇内样本距离”，分类中 “最大化分类面与样本的距离”）</li>\n<li>约束条件：限制模型复杂度（如聚类中指定簇数 k，分类中限制分类面为直线而非复杂曲线），避免过拟合</li>\n</ol>\n</li>\n<li>优化方法：用于求解目标函数的算法，如聚类中 “更新簇中值为新原型”、分类中 “寻找最优分类面” 的梯度下降算法等</li>\n</ol>\n</li>\n<li><strong>本节知识的重点问题</strong><ol>\n<li>监督学习与无监督学习的核心差异是什么？在实际应用中如何选择这两种范式？<ol>\n<li>二者的核心差异体现在数据要求与核心目标上：<ol>\n<li>数据要求：监督学习需 “特征 &#x2F; 标签对”，无监督学习仅需无标签特征向量</li>\n<li>核心目标：监督学习目标是构建分类器，为新输入预测标签；无监督学习目标是将数据聚类为自然簇，挖掘隐含分组</li>\n</ol>\n</li>\n<li>实际应用选择依据：<ol>\n<li>若有明确的标签数据，且需预测新样本标签，选择监督学习</li>\n<li>若无标签数据，仅需探索数据内在结构，或为后续监督学习生成初始标签，选择无监督学习</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>特征工程在机器学习中扮演什么角色？如何通过特征工程提升模型性能？<ol>\n<li>特征工程的核心角色是构建高信噪比（SNR）的特征向量，即筛选 “有用输入”、剔除 “无关输入”，直接决定模型能否从数据中学习到有效规律</li>\n<li>提升模型性能的方式：<ol>\n<li>保留有用特征：选择与目标强相关的特征</li>\n<li>剔除无关特征：移除与目标无关的特征</li>\n<li>优化特征格式：统一特征维度权重（如将整数型 “腿数” 转为二进制，避免距离计算偏差）</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>什么是过拟合？为什么会出现过拟合？如何通过模型设计或评估方式避免过拟合？<ol>\n<li>过拟合定义：模型在训练数据上表现极佳，但在测试数据上表现差，即模型过度学习训练数据的噪声，而非普遍规律，无法泛化到新数据</li>\n<li>过拟合原因：<ol>\n<li>模型复杂度过高</li>\n<li>特征质量差</li>\n<li>仅用训练数据评估模型</li>\n</ol>\n</li>\n<li>避免方式：<ol>\n<li>控制模型复杂度：如分类时选择简单分类面（直线 &#x2F; 平面），聚类时限制簇数 k（而非 k 等于样本数）</li>\n<li>优化特征工程：剔除无关特征，提升信噪比</li>\n<li>合理划分数据与评估：将数据分为训练集与测试集，仅通过测试集性能判断模型好坏（如复杂模型训练准确率高但测试准确率低，需放弃）</li>\n<li>权衡假阳性与假阴性：避免为追求训练准确率而构建过度复杂的模型</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"迎新晚会总结\"><a href=\"#迎新晚会总结\" class=\"headerlink\" title=\"迎新晚会总结\"></a>迎新晚会总结</h2><p>今天的表演还算是成功吧，和上一次相比明显放松多了，而且这次的听众也挺多，再接再厉吧。</p>\n"},{"title":"2025.10.28","date":"2025-10-28T06:20:01.000Z","_content":"# Overview\n1. 前段时间的总结\n2. 学习笔记\n3. 今日收获\n\n## 前段时间的总结\n从上次博客之后以及一周多了，这期间每天都被牙疼所困扰，从而导致作息被打乱了，且状态明显有所下降。但是不能再继续下去了，从今天开始吃两天药看能不能缓解，实在不行就去医院看看。  \n在这段时间内虽然生活被有点打乱，但是还是完成了不少有意义的事情的：上周的两次飞盘活动明显参与感更好了，虽然第一次的活动由于失误误伤了一个同学，但幸好问题不是特别严重，周末的第二次活动上更是难得和一名同学在练习时交流的非常开心，希望之后能够继续照这样发展。其次上周末按惯例去参加了志愿者活动，虽然因为我的固执导致被咬了一下，但没什么大碍，就是我发现我买的防水服洗过之后还是有很大的味道，没办法只能再多洗几次看看行不行吧。昨天进行了第一次的城市之旅活动，这次的主题是“食”，由于我的两个行程都被婉拒了所以最后就在学校里的一个饭店吃了个晚饭，顺便把之后几期的活动都交给对应的人来安排，虽然活动的人有点少，但是我感觉还是很不错的，尤其和老师交流的挺开心，完全像是和朋友一样特别轻松自在。\n\n## 学习笔记\n\n### 数据科学（统计）\n1. 监督学习（Supervised Learning）基础框架\n   1. 核心流程：数据准备→选择算法→拟合模型→评估模型→更新模型→进行预测 （损失（Loss）：预测结果与真实结果的差异）\n   2. 任务分类：\n      1. 回归：预测与特征向量关联的实数，例如用线性回归对数据拟合曲线\n      2. 分类：预测与特征向量关联的离散标签\n2. KNN（K 近邻）分类算法\n   1. 原理：基于距离矩阵计算样本间相似度，最简单的实现是 “最近邻”—— 预测新样本时，找到训练集中距离最近的样本，直接沿用其标签；扩展为 “K 近邻” 时，取前 K 个最近样本的标签进行投票\n   2. 优点：\n      1. 学习速度快，无显式训练过程\n      2. 无需复杂理论支撑\n      3. 方法与结果易解释\n   3. 缺点：\n      1. 内存密集，预测耗时较长\n      2. 暴力搜索并非最优算法\n      3. 无模型可解释数据生成过程\n3. 分类模型的评估体系\n   1. 仅用 “准确率” 评估存在局限性，需补充以下指标：\n      1. 灵敏度（召回率）：sensitivity = truepositive / truepositive + falsenegative \n      2. 特异性：specificity = truenegative / truenegative + falsepositive\n      3. 阳性预测值：positivepredictivevalue = truepositive / truepositive + falsepositive\n   2. 测试方法：\n      1. 留一法（Leave-one-out）：遍历每个样本，以该样本为测试集、其余为训练集，循环计算指标\n      2. 重复随机抽样：如 80/20 分割数据（20% 为测试集，80% 为训练集），多次重复抽样以降低随机性影响\n      3. K 折交叉验证：首先将数据集均匀划分为 K 个规模相近的子集（即 “K 折”）；随后，循环进行 K 次模型训练与测试 —— 每次训练时，用其中 K-1 个子集作为训练数据拟合模型，剩余 1 个子集作为测试数据评估模型性能；最后，综合 K 次测试的结果（如灵敏度、特异性等），取平均值作为模型的最终性能评估，以此在计算量与损失估计准确率之间达到平衡\n4. 逻辑回归算法详解\n   1. 核心特点：\n      1. 用途：专门预测事件发生的概率，因变量仅取有限值（通常为 0 或 1）\n      2. 特征权重：每个特征对应一个权重，正权重表示特征与结果正相关，负权重表示负相关，权重绝对值反映相关性强度\n      3. 核心函数：逻辑函数（sigmoid 函数），将线性输出映射到 0-1 区间（概率）\n\n## 今日收获\n今天打算开始认真攻克英语口语，我创建了一个word文档用来记录所学的口语知识（固定搭配、语法、连读习惯···）","source":"_posts/2025-10-28.md","raw":"---\ntitle: 2025.10.28\ndate: 2025-10-28 14:20:01\ntags:\n---\n# Overview\n1. 前段时间的总结\n2. 学习笔记\n3. 今日收获\n\n## 前段时间的总结\n从上次博客之后以及一周多了，这期间每天都被牙疼所困扰，从而导致作息被打乱了，且状态明显有所下降。但是不能再继续下去了，从今天开始吃两天药看能不能缓解，实在不行就去医院看看。  \n在这段时间内虽然生活被有点打乱，但是还是完成了不少有意义的事情的：上周的两次飞盘活动明显参与感更好了，虽然第一次的活动由于失误误伤了一个同学，但幸好问题不是特别严重，周末的第二次活动上更是难得和一名同学在练习时交流的非常开心，希望之后能够继续照这样发展。其次上周末按惯例去参加了志愿者活动，虽然因为我的固执导致被咬了一下，但没什么大碍，就是我发现我买的防水服洗过之后还是有很大的味道，没办法只能再多洗几次看看行不行吧。昨天进行了第一次的城市之旅活动，这次的主题是“食”，由于我的两个行程都被婉拒了所以最后就在学校里的一个饭店吃了个晚饭，顺便把之后几期的活动都交给对应的人来安排，虽然活动的人有点少，但是我感觉还是很不错的，尤其和老师交流的挺开心，完全像是和朋友一样特别轻松自在。\n\n## 学习笔记\n\n### 数据科学（统计）\n1. 监督学习（Supervised Learning）基础框架\n   1. 核心流程：数据准备→选择算法→拟合模型→评估模型→更新模型→进行预测 （损失（Loss）：预测结果与真实结果的差异）\n   2. 任务分类：\n      1. 回归：预测与特征向量关联的实数，例如用线性回归对数据拟合曲线\n      2. 分类：预测与特征向量关联的离散标签\n2. KNN（K 近邻）分类算法\n   1. 原理：基于距离矩阵计算样本间相似度，最简单的实现是 “最近邻”—— 预测新样本时，找到训练集中距离最近的样本，直接沿用其标签；扩展为 “K 近邻” 时，取前 K 个最近样本的标签进行投票\n   2. 优点：\n      1. 学习速度快，无显式训练过程\n      2. 无需复杂理论支撑\n      3. 方法与结果易解释\n   3. 缺点：\n      1. 内存密集，预测耗时较长\n      2. 暴力搜索并非最优算法\n      3. 无模型可解释数据生成过程\n3. 分类模型的评估体系\n   1. 仅用 “准确率” 评估存在局限性，需补充以下指标：\n      1. 灵敏度（召回率）：sensitivity = truepositive / truepositive + falsenegative \n      2. 特异性：specificity = truenegative / truenegative + falsepositive\n      3. 阳性预测值：positivepredictivevalue = truepositive / truepositive + falsepositive\n   2. 测试方法：\n      1. 留一法（Leave-one-out）：遍历每个样本，以该样本为测试集、其余为训练集，循环计算指标\n      2. 重复随机抽样：如 80/20 分割数据（20% 为测试集，80% 为训练集），多次重复抽样以降低随机性影响\n      3. K 折交叉验证：首先将数据集均匀划分为 K 个规模相近的子集（即 “K 折”）；随后，循环进行 K 次模型训练与测试 —— 每次训练时，用其中 K-1 个子集作为训练数据拟合模型，剩余 1 个子集作为测试数据评估模型性能；最后，综合 K 次测试的结果（如灵敏度、特异性等），取平均值作为模型的最终性能评估，以此在计算量与损失估计准确率之间达到平衡\n4. 逻辑回归算法详解\n   1. 核心特点：\n      1. 用途：专门预测事件发生的概率，因变量仅取有限值（通常为 0 或 1）\n      2. 特征权重：每个特征对应一个权重，正权重表示特征与结果正相关，负权重表示负相关，权重绝对值反映相关性强度\n      3. 核心函数：逻辑函数（sigmoid 函数），将线性输出映射到 0-1 区间（概率）\n\n## 今日收获\n今天打算开始认真攻克英语口语，我创建了一个word文档用来记录所学的口语知识（固定搭配、语法、连读习惯···）","slug":"2025-10-28","published":1,"updated":"2025-11-18T19:39:17.115Z","comments":1,"layout":"post","photos":[],"_id":"cuidkJhKhcB4FslJuu2OCvOCS","content":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>前段时间的总结</li>\n<li>学习笔记</li>\n<li>今日收获</li>\n</ol>\n<h2 id=\"前段时间的总结\"><a href=\"#前段时间的总结\" class=\"headerlink\" title=\"前段时间的总结\"></a>前段时间的总结</h2><p>从上次博客之后以及一周多了，这期间每天都被牙疼所困扰，从而导致作息被打乱了，且状态明显有所下降。但是不能再继续下去了，从今天开始吃两天药看能不能缓解，实在不行就去医院看看。<br>在这段时间内虽然生活被有点打乱，但是还是完成了不少有意义的事情的：上周的两次飞盘活动明显参与感更好了，虽然第一次的活动由于失误误伤了一个同学，但幸好问题不是特别严重，周末的第二次活动上更是难得和一名同学在练习时交流的非常开心，希望之后能够继续照这样发展。其次上周末按惯例去参加了志愿者活动，虽然因为我的固执导致被咬了一下，但没什么大碍，就是我发现我买的防水服洗过之后还是有很大的味道，没办法只能再多洗几次看看行不行吧。昨天进行了第一次的城市之旅活动，这次的主题是“食”，由于我的两个行程都被婉拒了所以最后就在学校里的一个饭店吃了个晚饭，顺便把之后几期的活动都交给对应的人来安排，虽然活动的人有点少，但是我感觉还是很不错的，尤其和老师交流的挺开心，完全像是和朋友一样特别轻松自在。</p>\n<h2 id=\"学习笔记\"><a href=\"#学习笔记\" class=\"headerlink\" title=\"学习笔记\"></a>学习笔记</h2><h3 id=\"数据科学（统计）\"><a href=\"#数据科学（统计）\" class=\"headerlink\" title=\"数据科学（统计）\"></a>数据科学（统计）</h3><ol>\n<li>监督学习（Supervised Learning）基础框架<ol>\n<li>核心流程：数据准备→选择算法→拟合模型→评估模型→更新模型→进行预测 （损失（Loss）：预测结果与真实结果的差异）</li>\n<li>任务分类：<ol>\n<li>回归：预测与特征向量关联的实数，例如用线性回归对数据拟合曲线</li>\n<li>分类：预测与特征向量关联的离散标签</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>KNN（K 近邻）分类算法<ol>\n<li>原理：基于距离矩阵计算样本间相似度，最简单的实现是 “最近邻”—— 预测新样本时，找到训练集中距离最近的样本，直接沿用其标签；扩展为 “K 近邻” 时，取前 K 个最近样本的标签进行投票</li>\n<li>优点：<ol>\n<li>学习速度快，无显式训练过程</li>\n<li>无需复杂理论支撑</li>\n<li>方法与结果易解释</li>\n</ol>\n</li>\n<li>缺点：<ol>\n<li>内存密集，预测耗时较长</li>\n<li>暴力搜索并非最优算法</li>\n<li>无模型可解释数据生成过程</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>分类模型的评估体系<ol>\n<li>仅用 “准确率” 评估存在局限性，需补充以下指标：<ol>\n<li>灵敏度（召回率）：sensitivity &#x3D; truepositive &#x2F; truepositive + falsenegative </li>\n<li>特异性：specificity &#x3D; truenegative &#x2F; truenegative + falsepositive</li>\n<li>阳性预测值：positivepredictivevalue &#x3D; truepositive &#x2F; truepositive + falsepositive</li>\n</ol>\n</li>\n<li>测试方法：<ol>\n<li>留一法（Leave-one-out）：遍历每个样本，以该样本为测试集、其余为训练集，循环计算指标</li>\n<li>重复随机抽样：如 80&#x2F;20 分割数据（20% 为测试集，80% 为训练集），多次重复抽样以降低随机性影响</li>\n<li>K 折交叉验证：首先将数据集均匀划分为 K 个规模相近的子集（即 “K 折”）；随后，循环进行 K 次模型训练与测试 —— 每次训练时，用其中 K-1 个子集作为训练数据拟合模型，剩余 1 个子集作为测试数据评估模型性能；最后，综合 K 次测试的结果（如灵敏度、特异性等），取平均值作为模型的最终性能评估，以此在计算量与损失估计准确率之间达到平衡</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>逻辑回归算法详解<ol>\n<li>核心特点：<ol>\n<li>用途：专门预测事件发生的概率，因变量仅取有限值（通常为 0 或 1）</li>\n<li>特征权重：每个特征对应一个权重，正权重表示特征与结果正相关，负权重表示负相关，权重绝对值反映相关性强度</li>\n<li>核心函数：逻辑函数（sigmoid 函数），将线性输出映射到 0-1 区间（概率）</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"今日收获\"><a href=\"#今日收获\" class=\"headerlink\" title=\"今日收获\"></a>今日收获</h2><p>今天打算开始认真攻克英语口语，我创建了一个word文档用来记录所学的口语知识（固定搭配、语法、连读习惯···）</p>\n","excerpt":"","more":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>前段时间的总结</li>\n<li>学习笔记</li>\n<li>今日收获</li>\n</ol>\n<h2 id=\"前段时间的总结\"><a href=\"#前段时间的总结\" class=\"headerlink\" title=\"前段时间的总结\"></a>前段时间的总结</h2><p>从上次博客之后以及一周多了，这期间每天都被牙疼所困扰，从而导致作息被打乱了，且状态明显有所下降。但是不能再继续下去了，从今天开始吃两天药看能不能缓解，实在不行就去医院看看。<br>在这段时间内虽然生活被有点打乱，但是还是完成了不少有意义的事情的：上周的两次飞盘活动明显参与感更好了，虽然第一次的活动由于失误误伤了一个同学，但幸好问题不是特别严重，周末的第二次活动上更是难得和一名同学在练习时交流的非常开心，希望之后能够继续照这样发展。其次上周末按惯例去参加了志愿者活动，虽然因为我的固执导致被咬了一下，但没什么大碍，就是我发现我买的防水服洗过之后还是有很大的味道，没办法只能再多洗几次看看行不行吧。昨天进行了第一次的城市之旅活动，这次的主题是“食”，由于我的两个行程都被婉拒了所以最后就在学校里的一个饭店吃了个晚饭，顺便把之后几期的活动都交给对应的人来安排，虽然活动的人有点少，但是我感觉还是很不错的，尤其和老师交流的挺开心，完全像是和朋友一样特别轻松自在。</p>\n<h2 id=\"学习笔记\"><a href=\"#学习笔记\" class=\"headerlink\" title=\"学习笔记\"></a>学习笔记</h2><h3 id=\"数据科学（统计）\"><a href=\"#数据科学（统计）\" class=\"headerlink\" title=\"数据科学（统计）\"></a>数据科学（统计）</h3><ol>\n<li>监督学习（Supervised Learning）基础框架<ol>\n<li>核心流程：数据准备→选择算法→拟合模型→评估模型→更新模型→进行预测 （损失（Loss）：预测结果与真实结果的差异）</li>\n<li>任务分类：<ol>\n<li>回归：预测与特征向量关联的实数，例如用线性回归对数据拟合曲线</li>\n<li>分类：预测与特征向量关联的离散标签</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>KNN（K 近邻）分类算法<ol>\n<li>原理：基于距离矩阵计算样本间相似度，最简单的实现是 “最近邻”—— 预测新样本时，找到训练集中距离最近的样本，直接沿用其标签；扩展为 “K 近邻” 时，取前 K 个最近样本的标签进行投票</li>\n<li>优点：<ol>\n<li>学习速度快，无显式训练过程</li>\n<li>无需复杂理论支撑</li>\n<li>方法与结果易解释</li>\n</ol>\n</li>\n<li>缺点：<ol>\n<li>内存密集，预测耗时较长</li>\n<li>暴力搜索并非最优算法</li>\n<li>无模型可解释数据生成过程</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>分类模型的评估体系<ol>\n<li>仅用 “准确率” 评估存在局限性，需补充以下指标：<ol>\n<li>灵敏度（召回率）：sensitivity &#x3D; truepositive &#x2F; truepositive + falsenegative </li>\n<li>特异性：specificity &#x3D; truenegative &#x2F; truenegative + falsepositive</li>\n<li>阳性预测值：positivepredictivevalue &#x3D; truepositive &#x2F; truepositive + falsepositive</li>\n</ol>\n</li>\n<li>测试方法：<ol>\n<li>留一法（Leave-one-out）：遍历每个样本，以该样本为测试集、其余为训练集，循环计算指标</li>\n<li>重复随机抽样：如 80&#x2F;20 分割数据（20% 为测试集，80% 为训练集），多次重复抽样以降低随机性影响</li>\n<li>K 折交叉验证：首先将数据集均匀划分为 K 个规模相近的子集（即 “K 折”）；随后，循环进行 K 次模型训练与测试 —— 每次训练时，用其中 K-1 个子集作为训练数据拟合模型，剩余 1 个子集作为测试数据评估模型性能；最后，综合 K 次测试的结果（如灵敏度、特异性等），取平均值作为模型的最终性能评估，以此在计算量与损失估计准确率之间达到平衡</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>逻辑回归算法详解<ol>\n<li>核心特点：<ol>\n<li>用途：专门预测事件发生的概率，因变量仅取有限值（通常为 0 或 1）</li>\n<li>特征权重：每个特征对应一个权重，正权重表示特征与结果正相关，负权重表示负相关，权重绝对值反映相关性强度</li>\n<li>核心函数：逻辑函数（sigmoid 函数），将线性输出映射到 0-1 区间（概率）</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"今日收获\"><a href=\"#今日收获\" class=\"headerlink\" title=\"今日收获\"></a>今日收获</h2><p>今天打算开始认真攻克英语口语，我创建了一个word文档用来记录所学的口语知识（固定搭配、语法、连读习惯···）</p>\n"},{"title":"2025.10.15","date":"2025-10-15T10:04:54.000Z","_content":"# Summary\n1. 今天受到之前表演时的一个外国朋友的邀请去到了专业的录音棚里面弹琴，以帮助他们学习如何调试录音设备，预计之后会有更多机会既能帮助他们完成毕设也能够让我体验梦寐以求的专业录音，所以接下来要好好练琴了\n2. 今天和老师汇报了一下近期的情况，还是比较满意吧\n3. 第二次参加本学期的网球社团活动，明显开始适应社团活动的流程了，今天从头到尾一直在打球，比起上一次体验感强多了","source":"_posts/2025-10-15.md","raw":"---\ntitle: 2025.10.15\ndate: 2025-10-15 18:04:54\ntags:\n---\n# Summary\n1. 今天受到之前表演时的一个外国朋友的邀请去到了专业的录音棚里面弹琴，以帮助他们学习如何调试录音设备，预计之后会有更多机会既能帮助他们完成毕设也能够让我体验梦寐以求的专业录音，所以接下来要好好练琴了\n2. 今天和老师汇报了一下近期的情况，还是比较满意吧\n3. 第二次参加本学期的网球社团活动，明显开始适应社团活动的流程了，今天从头到尾一直在打球，比起上一次体验感强多了","slug":"2025-10-15","published":1,"updated":"2025-11-18T19:39:17.122Z","comments":1,"layout":"post","photos":[],"_id":"cuidNopxJh8Ja046b3ct-TubX","content":"<h1 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h1><ol>\n<li>今天受到之前表演时的一个外国朋友的邀请去到了专业的录音棚里面弹琴，以帮助他们学习如何调试录音设备，预计之后会有更多机会既能帮助他们完成毕设也能够让我体验梦寐以求的专业录音，所以接下来要好好练琴了</li>\n<li>今天和老师汇报了一下近期的情况，还是比较满意吧</li>\n<li>第二次参加本学期的网球社团活动，明显开始适应社团活动的流程了，今天从头到尾一直在打球，比起上一次体验感强多了</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h1><ol>\n<li>今天受到之前表演时的一个外国朋友的邀请去到了专业的录音棚里面弹琴，以帮助他们学习如何调试录音设备，预计之后会有更多机会既能帮助他们完成毕设也能够让我体验梦寐以求的专业录音，所以接下来要好好练琴了</li>\n<li>今天和老师汇报了一下近期的情况，还是比较满意吧</li>\n<li>第二次参加本学期的网球社团活动，明显开始适应社团活动的流程了，今天从头到尾一直在打球，比起上一次体验感强多了</li>\n</ol>\n"},{"title":"2025.10.31","date":"2025-10-31T00:58:15.000Z","_content":"# Overview\n1. 博客升级\n2. 今日总结\n3. 摘录\n\n## 博客升级\n\n### 1. 过程记录\n1. 首先在阿里云注册了账号并购买了一个域名\n2. 登录Vercel网站并登录GitHub账号，再导入之前的博客仓库\n3. 在Vercel中添加购买的域名\n4. 去阿里云里修改DNS设置\n   1. 配置根域名（A 记录）\n      1. 主机记录：@\n      2. 记录类型：A\n      3. 记录值：216.198.79.1\n   2. 配置 www 子域名（CNAME 记录）\n      1. 主机记录：www\n      2. 记录类型：CNAME\n      3. 记录值：a866d5a916b7fd31.vercel-dns-017.com\n\n### 2. 总结\n至今为止的博客搭建过程中我用到了以下工具：Node.js、Hexo、GitHub 库、Vercel、域名  \n若把博客比作开一家咖啡厅，则上面的工具可以类比为：  \n1. Node.js -- 咖啡店的电力系统（提供动力）\n   1. Node.js 就是为所有工具提供“动力”的基础运行环境。Hexo 需要它的“电力”才能运转\n2. Hexo -- 全自动咖啡机和标准食谱（生成网站）\n   1. 你提供原材料（Markdown 笔记和文章）\n   2. Hexo（咖啡机）按照固定的食谱（主题和模板），自动、快速地把这些原材料“冲泡”成一整套风格统一、漂亮的网页文件（HTML/CSS/JS）\n   3. 不需要从零开始手写网页\n3. GitHub 库 -- 咖啡馆的总部仓库和设计图纸库（存储代码）\n   1. 备份与版本管理：它安全地存储咖啡馆的所有“设计图纸”（博客的源代码）。如果后面改坏了配方，随时可以找回之前的版本\n   2. 协作与分发：它是代码的“大本营”，Vercel 可以从这里获取最新图纸来施工\n4. Vercel -- 全球顶级的店铺装修和运营团队（部署和加速）\n   1. 自动装修：只需要把图纸（代码）存进 GitHub 仓库，Vercel 团队就会自动领取图纸，帮你把店铺（博客）装修好\n   2. 全球连锁：它在全世界都有分店（服务器），确保无论顾客在哪里，都能从最近的店铺拿到咖啡，速度极快\n   3. 免费服务：免费帮办好营业执照（SSL证书，即 HTTPS 安全锁），让店铺正规、安全\n5. 域名 -- 咖啡馆的品牌名和招牌（品牌入口）\n   1. 没有招牌，顾客只能通过一个非常难记的地址（比如 Vercel 给你的默认网址 xxx.vercel.app）找到你。而“域名”这个酷炫的招牌，让顾客很容易就能记住并找到你的店\n\n工作流程：  \n1. 你在“后厨”（你的电脑），用 Hexo（咖啡机）和 Node.js（电力）写好一篇新文章（制作一杯新咖啡）\n2. 把这份新品的“配方”（代码）交给总部仓库（GitHub）存档\n3. 全球运营团队（Vercel）自动从仓库拿到了新配方\n4. Vercel 立刻指挥它在全球的所有分店，按照新配方进行更新\n5. 分钟后，全世界的顾客都可以通过你醒目的招牌（你的域名）享受到你的新品了\n\n知识点：\n1. IP地址：\n   1. IP 地址就像互联网世界里设备的 “身份证号码 + 门牌号”，是给电脑、手机等联网设备分配的唯一数字标识\n   2. 核心特点：\n      1. 格式是一串点分隔的数字（比如 IPv4 常见的 192.168.1.1），每段数字有范围限制\n      2. 唯一性，同一时间同一网络里，没有两台设备的公开 IP 完全相同\n      3. 作用是让数据在网络中找准 “收发对象”，就像寄快递必须填清楚收件人地址\n2. DNS（域名系统）：\n   1. DNS（域名系统）本质是互联网的 “地址簿”，DNS 负责将易记的域名（比如 www.baidu.com）翻译成计算机能识别的 IP 地址（比如 180.101.49.11），让设备能准确连接目标服务器\n   2. 关键作用：\n      1. 简化访问流程，不用记复杂的数字 IP 地址\n      2. 实现负载均衡，让多个服务器分担访问压力\n      3. 保障网络弹性，某台服务器故障时可切换至备用 IP\n\n### 3. 后续规划\n1. 通过借鉴别的博客来设计一个属于我自己的博客页面，并尝试手敲代码实现个性化\n2. 日后尝试云服务器部署：\n   1. 购买云服务器\n   2. 通过SSH连接到服务器\n   3. 在服务器上安装Node.js、Git等环境\n   4. 克隆你的博客代码到服务器\n   5. 配置Nginx作为Web服务器\n\n## 今日总结\n1. 终于在进入11月前的最后一天学完了Python的所有语法，接下来只剩下爬虫课了\n2. 今天成功完成了对博客的初步升级\n3. 网球活动\n\n## 摘录\n1. 对于盲目的船来说，所有的风向都是逆风\n2. 知识是一个细化铺开的过程，而智慧是一个简化浓缩的过程","source":"_posts/2025-10-31.md","raw":"---\ntitle: 2025.10.31\ndate: 2025-10-31 08:58:15\ntags:\n---\n# Overview\n1. 博客升级\n2. 今日总结\n3. 摘录\n\n## 博客升级\n\n### 1. 过程记录\n1. 首先在阿里云注册了账号并购买了一个域名\n2. 登录Vercel网站并登录GitHub账号，再导入之前的博客仓库\n3. 在Vercel中添加购买的域名\n4. 去阿里云里修改DNS设置\n   1. 配置根域名（A 记录）\n      1. 主机记录：@\n      2. 记录类型：A\n      3. 记录值：216.198.79.1\n   2. 配置 www 子域名（CNAME 记录）\n      1. 主机记录：www\n      2. 记录类型：CNAME\n      3. 记录值：a866d5a916b7fd31.vercel-dns-017.com\n\n### 2. 总结\n至今为止的博客搭建过程中我用到了以下工具：Node.js、Hexo、GitHub 库、Vercel、域名  \n若把博客比作开一家咖啡厅，则上面的工具可以类比为：  \n1. Node.js -- 咖啡店的电力系统（提供动力）\n   1. Node.js 就是为所有工具提供“动力”的基础运行环境。Hexo 需要它的“电力”才能运转\n2. Hexo -- 全自动咖啡机和标准食谱（生成网站）\n   1. 你提供原材料（Markdown 笔记和文章）\n   2. Hexo（咖啡机）按照固定的食谱（主题和模板），自动、快速地把这些原材料“冲泡”成一整套风格统一、漂亮的网页文件（HTML/CSS/JS）\n   3. 不需要从零开始手写网页\n3. GitHub 库 -- 咖啡馆的总部仓库和设计图纸库（存储代码）\n   1. 备份与版本管理：它安全地存储咖啡馆的所有“设计图纸”（博客的源代码）。如果后面改坏了配方，随时可以找回之前的版本\n   2. 协作与分发：它是代码的“大本营”，Vercel 可以从这里获取最新图纸来施工\n4. Vercel -- 全球顶级的店铺装修和运营团队（部署和加速）\n   1. 自动装修：只需要把图纸（代码）存进 GitHub 仓库，Vercel 团队就会自动领取图纸，帮你把店铺（博客）装修好\n   2. 全球连锁：它在全世界都有分店（服务器），确保无论顾客在哪里，都能从最近的店铺拿到咖啡，速度极快\n   3. 免费服务：免费帮办好营业执照（SSL证书，即 HTTPS 安全锁），让店铺正规、安全\n5. 域名 -- 咖啡馆的品牌名和招牌（品牌入口）\n   1. 没有招牌，顾客只能通过一个非常难记的地址（比如 Vercel 给你的默认网址 xxx.vercel.app）找到你。而“域名”这个酷炫的招牌，让顾客很容易就能记住并找到你的店\n\n工作流程：  \n1. 你在“后厨”（你的电脑），用 Hexo（咖啡机）和 Node.js（电力）写好一篇新文章（制作一杯新咖啡）\n2. 把这份新品的“配方”（代码）交给总部仓库（GitHub）存档\n3. 全球运营团队（Vercel）自动从仓库拿到了新配方\n4. Vercel 立刻指挥它在全球的所有分店，按照新配方进行更新\n5. 分钟后，全世界的顾客都可以通过你醒目的招牌（你的域名）享受到你的新品了\n\n知识点：\n1. IP地址：\n   1. IP 地址就像互联网世界里设备的 “身份证号码 + 门牌号”，是给电脑、手机等联网设备分配的唯一数字标识\n   2. 核心特点：\n      1. 格式是一串点分隔的数字（比如 IPv4 常见的 192.168.1.1），每段数字有范围限制\n      2. 唯一性，同一时间同一网络里，没有两台设备的公开 IP 完全相同\n      3. 作用是让数据在网络中找准 “收发对象”，就像寄快递必须填清楚收件人地址\n2. DNS（域名系统）：\n   1. DNS（域名系统）本质是互联网的 “地址簿”，DNS 负责将易记的域名（比如 www.baidu.com）翻译成计算机能识别的 IP 地址（比如 180.101.49.11），让设备能准确连接目标服务器\n   2. 关键作用：\n      1. 简化访问流程，不用记复杂的数字 IP 地址\n      2. 实现负载均衡，让多个服务器分担访问压力\n      3. 保障网络弹性，某台服务器故障时可切换至备用 IP\n\n### 3. 后续规划\n1. 通过借鉴别的博客来设计一个属于我自己的博客页面，并尝试手敲代码实现个性化\n2. 日后尝试云服务器部署：\n   1. 购买云服务器\n   2. 通过SSH连接到服务器\n   3. 在服务器上安装Node.js、Git等环境\n   4. 克隆你的博客代码到服务器\n   5. 配置Nginx作为Web服务器\n\n## 今日总结\n1. 终于在进入11月前的最后一天学完了Python的所有语法，接下来只剩下爬虫课了\n2. 今天成功完成了对博客的初步升级\n3. 网球活动\n\n## 摘录\n1. 对于盲目的船来说，所有的风向都是逆风\n2. 知识是一个细化铺开的过程，而智慧是一个简化浓缩的过程","slug":"2025-10-31","published":1,"updated":"2025-11-18T19:39:17.108Z","comments":1,"layout":"post","photos":[],"_id":"cuidy4s4pX6S_NQlxS_GRQwc4","content":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>博客升级</li>\n<li>今日总结</li>\n<li>摘录</li>\n</ol>\n<h2 id=\"博客升级\"><a href=\"#博客升级\" class=\"headerlink\" title=\"博客升级\"></a>博客升级</h2><h3 id=\"1-过程记录\"><a href=\"#1-过程记录\" class=\"headerlink\" title=\"1. 过程记录\"></a>1. 过程记录</h3><ol>\n<li>首先在阿里云注册了账号并购买了一个域名</li>\n<li>登录Vercel网站并登录GitHub账号，再导入之前的博客仓库</li>\n<li>在Vercel中添加购买的域名</li>\n<li>去阿里云里修改DNS设置<ol>\n<li>配置根域名（A 记录）<ol>\n<li>主机记录：@</li>\n<li>记录类型：A</li>\n<li>记录值：216.198.79.1</li>\n</ol>\n</li>\n<li>配置 www 子域名（CNAME 记录）<ol>\n<li>主机记录：www</li>\n<li>记录类型：CNAME</li>\n<li>记录值：a866d5a916b7fd31.vercel-dns-017.com</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h3 id=\"2-总结\"><a href=\"#2-总结\" class=\"headerlink\" title=\"2. 总结\"></a>2. 总结</h3><p>至今为止的博客搭建过程中我用到了以下工具：Node.js、Hexo、GitHub 库、Vercel、域名<br>若把博客比作开一家咖啡厅，则上面的工具可以类比为：  </p>\n<ol>\n<li>Node.js – 咖啡店的电力系统（提供动力）<ol>\n<li>Node.js 就是为所有工具提供“动力”的基础运行环境。Hexo 需要它的“电力”才能运转</li>\n</ol>\n</li>\n<li>Hexo – 全自动咖啡机和标准食谱（生成网站）<ol>\n<li>你提供原材料（Markdown 笔记和文章）</li>\n<li>Hexo（咖啡机）按照固定的食谱（主题和模板），自动、快速地把这些原材料“冲泡”成一整套风格统一、漂亮的网页文件（HTML&#x2F;CSS&#x2F;JS）</li>\n<li>不需要从零开始手写网页</li>\n</ol>\n</li>\n<li>GitHub 库 – 咖啡馆的总部仓库和设计图纸库（存储代码）<ol>\n<li>备份与版本管理：它安全地存储咖啡馆的所有“设计图纸”（博客的源代码）。如果后面改坏了配方，随时可以找回之前的版本</li>\n<li>协作与分发：它是代码的“大本营”，Vercel 可以从这里获取最新图纸来施工</li>\n</ol>\n</li>\n<li>Vercel – 全球顶级的店铺装修和运营团队（部署和加速）<ol>\n<li>自动装修：只需要把图纸（代码）存进 GitHub 仓库，Vercel 团队就会自动领取图纸，帮你把店铺（博客）装修好</li>\n<li>全球连锁：它在全世界都有分店（服务器），确保无论顾客在哪里，都能从最近的店铺拿到咖啡，速度极快</li>\n<li>免费服务：免费帮办好营业执照（SSL证书，即 HTTPS 安全锁），让店铺正规、安全</li>\n</ol>\n</li>\n<li>域名 – 咖啡馆的品牌名和招牌（品牌入口）<ol>\n<li>没有招牌，顾客只能通过一个非常难记的地址（比如 Vercel 给你的默认网址 xxx.vercel.app）找到你。而“域名”这个酷炫的招牌，让顾客很容易就能记住并找到你的店</li>\n</ol>\n</li>\n</ol>\n<p>工作流程：  </p>\n<ol>\n<li>你在“后厨”（你的电脑），用 Hexo（咖啡机）和 Node.js（电力）写好一篇新文章（制作一杯新咖啡）</li>\n<li>把这份新品的“配方”（代码）交给总部仓库（GitHub）存档</li>\n<li>全球运营团队（Vercel）自动从仓库拿到了新配方</li>\n<li>Vercel 立刻指挥它在全球的所有分店，按照新配方进行更新</li>\n<li>分钟后，全世界的顾客都可以通过你醒目的招牌（你的域名）享受到你的新品了</li>\n</ol>\n<p>知识点：</p>\n<ol>\n<li>IP地址：<ol>\n<li>IP 地址就像互联网世界里设备的 “身份证号码 + 门牌号”，是给电脑、手机等联网设备分配的唯一数字标识</li>\n<li>核心特点：<ol>\n<li>格式是一串点分隔的数字（比如 IPv4 常见的 192.168.1.1），每段数字有范围限制</li>\n<li>唯一性，同一时间同一网络里，没有两台设备的公开 IP 完全相同</li>\n<li>作用是让数据在网络中找准 “收发对象”，就像寄快递必须填清楚收件人地址</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>DNS（域名系统）：<ol>\n<li>DNS（域名系统）本质是互联网的 “地址簿”，DNS 负责将易记的域名（比如 <a href=\"http://www.baidu.com)翻译成计算机能识别的/\">www.baidu.com）翻译成计算机能识别的</a> IP 地址（比如 180.101.49.11），让设备能准确连接目标服务器</li>\n<li>关键作用：<ol>\n<li>简化访问流程，不用记复杂的数字 IP 地址</li>\n<li>实现负载均衡，让多个服务器分担访问压力</li>\n<li>保障网络弹性，某台服务器故障时可切换至备用 IP</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h3 id=\"3-后续规划\"><a href=\"#3-后续规划\" class=\"headerlink\" title=\"3. 后续规划\"></a>3. 后续规划</h3><ol>\n<li>通过借鉴别的博客来设计一个属于我自己的博客页面，并尝试手敲代码实现个性化</li>\n<li>日后尝试云服务器部署：<ol>\n<li>购买云服务器</li>\n<li>通过SSH连接到服务器</li>\n<li>在服务器上安装Node.js、Git等环境</li>\n<li>克隆你的博客代码到服务器</li>\n<li>配置Nginx作为Web服务器</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"今日总结\"><a href=\"#今日总结\" class=\"headerlink\" title=\"今日总结\"></a>今日总结</h2><ol>\n<li>终于在进入11月前的最后一天学完了Python的所有语法，接下来只剩下爬虫课了</li>\n<li>今天成功完成了对博客的初步升级</li>\n<li>网球活动</li>\n</ol>\n<h2 id=\"摘录\"><a href=\"#摘录\" class=\"headerlink\" title=\"摘录\"></a>摘录</h2><ol>\n<li>对于盲目的船来说，所有的风向都是逆风</li>\n<li>知识是一个细化铺开的过程，而智慧是一个简化浓缩的过程</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>博客升级</li>\n<li>今日总结</li>\n<li>摘录</li>\n</ol>\n<h2 id=\"博客升级\"><a href=\"#博客升级\" class=\"headerlink\" title=\"博客升级\"></a>博客升级</h2><h3 id=\"1-过程记录\"><a href=\"#1-过程记录\" class=\"headerlink\" title=\"1. 过程记录\"></a>1. 过程记录</h3><ol>\n<li>首先在阿里云注册了账号并购买了一个域名</li>\n<li>登录Vercel网站并登录GitHub账号，再导入之前的博客仓库</li>\n<li>在Vercel中添加购买的域名</li>\n<li>去阿里云里修改DNS设置<ol>\n<li>配置根域名（A 记录）<ol>\n<li>主机记录：@</li>\n<li>记录类型：A</li>\n<li>记录值：216.198.79.1</li>\n</ol>\n</li>\n<li>配置 www 子域名（CNAME 记录）<ol>\n<li>主机记录：www</li>\n<li>记录类型：CNAME</li>\n<li>记录值：a866d5a916b7fd31.vercel-dns-017.com</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h3 id=\"2-总结\"><a href=\"#2-总结\" class=\"headerlink\" title=\"2. 总结\"></a>2. 总结</h3><p>至今为止的博客搭建过程中我用到了以下工具：Node.js、Hexo、GitHub 库、Vercel、域名<br>若把博客比作开一家咖啡厅，则上面的工具可以类比为：  </p>\n<ol>\n<li>Node.js – 咖啡店的电力系统（提供动力）<ol>\n<li>Node.js 就是为所有工具提供“动力”的基础运行环境。Hexo 需要它的“电力”才能运转</li>\n</ol>\n</li>\n<li>Hexo – 全自动咖啡机和标准食谱（生成网站）<ol>\n<li>你提供原材料（Markdown 笔记和文章）</li>\n<li>Hexo（咖啡机）按照固定的食谱（主题和模板），自动、快速地把这些原材料“冲泡”成一整套风格统一、漂亮的网页文件（HTML&#x2F;CSS&#x2F;JS）</li>\n<li>不需要从零开始手写网页</li>\n</ol>\n</li>\n<li>GitHub 库 – 咖啡馆的总部仓库和设计图纸库（存储代码）<ol>\n<li>备份与版本管理：它安全地存储咖啡馆的所有“设计图纸”（博客的源代码）。如果后面改坏了配方，随时可以找回之前的版本</li>\n<li>协作与分发：它是代码的“大本营”，Vercel 可以从这里获取最新图纸来施工</li>\n</ol>\n</li>\n<li>Vercel – 全球顶级的店铺装修和运营团队（部署和加速）<ol>\n<li>自动装修：只需要把图纸（代码）存进 GitHub 仓库，Vercel 团队就会自动领取图纸，帮你把店铺（博客）装修好</li>\n<li>全球连锁：它在全世界都有分店（服务器），确保无论顾客在哪里，都能从最近的店铺拿到咖啡，速度极快</li>\n<li>免费服务：免费帮办好营业执照（SSL证书，即 HTTPS 安全锁），让店铺正规、安全</li>\n</ol>\n</li>\n<li>域名 – 咖啡馆的品牌名和招牌（品牌入口）<ol>\n<li>没有招牌，顾客只能通过一个非常难记的地址（比如 Vercel 给你的默认网址 xxx.vercel.app）找到你。而“域名”这个酷炫的招牌，让顾客很容易就能记住并找到你的店</li>\n</ol>\n</li>\n</ol>\n<p>工作流程：  </p>\n<ol>\n<li>你在“后厨”（你的电脑），用 Hexo（咖啡机）和 Node.js（电力）写好一篇新文章（制作一杯新咖啡）</li>\n<li>把这份新品的“配方”（代码）交给总部仓库（GitHub）存档</li>\n<li>全球运营团队（Vercel）自动从仓库拿到了新配方</li>\n<li>Vercel 立刻指挥它在全球的所有分店，按照新配方进行更新</li>\n<li>分钟后，全世界的顾客都可以通过你醒目的招牌（你的域名）享受到你的新品了</li>\n</ol>\n<p>知识点：</p>\n<ol>\n<li>IP地址：<ol>\n<li>IP 地址就像互联网世界里设备的 “身份证号码 + 门牌号”，是给电脑、手机等联网设备分配的唯一数字标识</li>\n<li>核心特点：<ol>\n<li>格式是一串点分隔的数字（比如 IPv4 常见的 192.168.1.1），每段数字有范围限制</li>\n<li>唯一性，同一时间同一网络里，没有两台设备的公开 IP 完全相同</li>\n<li>作用是让数据在网络中找准 “收发对象”，就像寄快递必须填清楚收件人地址</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>DNS（域名系统）：<ol>\n<li>DNS（域名系统）本质是互联网的 “地址簿”，DNS 负责将易记的域名（比如 <a href=\"http://www.baidu.com)翻译成计算机能识别的/\">www.baidu.com）翻译成计算机能识别的</a> IP 地址（比如 180.101.49.11），让设备能准确连接目标服务器</li>\n<li>关键作用：<ol>\n<li>简化访问流程，不用记复杂的数字 IP 地址</li>\n<li>实现负载均衡，让多个服务器分担访问压力</li>\n<li>保障网络弹性，某台服务器故障时可切换至备用 IP</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h3 id=\"3-后续规划\"><a href=\"#3-后续规划\" class=\"headerlink\" title=\"3. 后续规划\"></a>3. 后续规划</h3><ol>\n<li>通过借鉴别的博客来设计一个属于我自己的博客页面，并尝试手敲代码实现个性化</li>\n<li>日后尝试云服务器部署：<ol>\n<li>购买云服务器</li>\n<li>通过SSH连接到服务器</li>\n<li>在服务器上安装Node.js、Git等环境</li>\n<li>克隆你的博客代码到服务器</li>\n<li>配置Nginx作为Web服务器</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"今日总结\"><a href=\"#今日总结\" class=\"headerlink\" title=\"今日总结\"></a>今日总结</h2><ol>\n<li>终于在进入11月前的最后一天学完了Python的所有语法，接下来只剩下爬虫课了</li>\n<li>今天成功完成了对博客的初步升级</li>\n<li>网球活动</li>\n</ol>\n<h2 id=\"摘录\"><a href=\"#摘录\" class=\"headerlink\" title=\"摘录\"></a>摘录</h2><ol>\n<li>对于盲目的船来说，所有的风向都是逆风</li>\n<li>知识是一个细化铺开的过程，而智慧是一个简化浓缩的过程</li>\n</ol>\n"},{"title":"2025.10.30","date":"2025-10-30T00:55:03.000Z","_content":"# Summary\n1. 把昨天的笔记补全了\n2. 学习了正则表达式\n3. 每日英语\n4. 定好了下周的骑行路线\n5. 报名了寒假海外交流项目\n6. 查询了如何办理日本签证\n7. 规划了一下之后的学习路线（打算边实践边学习）","source":"_posts/2025-10-30.md","raw":"---\ntitle: 2025.10.30\ndate: 2025-10-30 08:55:03\ntags:\n---\n# Summary\n1. 把昨天的笔记补全了\n2. 学习了正则表达式\n3. 每日英语\n4. 定好了下周的骑行路线\n5. 报名了寒假海外交流项目\n6. 查询了如何办理日本签证\n7. 规划了一下之后的学习路线（打算边实践边学习）","slug":"2025-10-30","published":1,"updated":"2025-11-18T19:39:17.110Z","comments":1,"layout":"post","photos":[],"_id":"cuidldTH4JlLzwvUHZzoY37ac","content":"<h1 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h1><ol>\n<li>把昨天的笔记补全了</li>\n<li>学习了正则表达式</li>\n<li>每日英语</li>\n<li>定好了下周的骑行路线</li>\n<li>报名了寒假海外交流项目</li>\n<li>查询了如何办理日本签证</li>\n<li>规划了一下之后的学习路线（打算边实践边学习）</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h1><ol>\n<li>把昨天的笔记补全了</li>\n<li>学习了正则表达式</li>\n<li>每日英语</li>\n<li>定好了下周的骑行路线</li>\n<li>报名了寒假海外交流项目</li>\n<li>查询了如何办理日本签证</li>\n<li>规划了一下之后的学习路线（打算边实践边学习）</li>\n</ol>\n"},{"title":"2025.10.20","date":"2025-10-20T00:41:01.000Z","_content":"# Overview\n1. 周末总结\n2. 今日学习笔记\n3. 今日总结\n\n## 周末总结\n这周末暂时放松了一下，不过还是弹了琴，新曲子虽然有点难以掌握节奏，但以及整体过了一遍了，感觉再练几次就能弹下来了；原本打算带摩羯出去逛逛，结果起床完了，不过还是决定周末下午出去，结果刚骑到公园走了几步就开始下雨了，无奈之下只能提前回家了，没事以后有的是机会\n\n## 学习笔记\n\n### 数据科学（统计）\n1. 机器学习核心范式\n   1. 机器学习的核心逻辑： “观察训练数据→推断数据生成过程→预测测试数据”\n   2. 监督学习：给定特征 / 标签对，学习预测未知输入标签的规则\n   3. 无监督学习：仅给定特征向量（无标签），将样本分组为 “自然聚类”，聚类是无监督学习的核心任务之一\n2. 聚类（Clustering）的本质：优化问题，目标是找到聚类划分 C 以最小化聚类内差异（dissimilarity (C)），但需满足约束条件：\n   1. 若不设约束，会导致每个样本单独成簇（无意义），因此需添加约束，如 “聚类间最小距离” 或 “指定聚类数量（k）”\n   2. 核心逻辑：“大而差” 的聚类比 “小而差” 的聚类更差，需平衡聚类大小与内部一致性\n3. 层次聚类（Hierarchical Clustering）\n   1. 核心步骤：\n      1. 初始状态：每个样本单独成簇，N 个样本对应 N 个簇\n      2. 迭代合并：找到最相似（距离最近）的一对簇，合并为 1 个簇，簇数减少 1\n      3. 终止条件：所有样本合并为 1 个簇（大小为 N）\n   2. 簇间距离（链接度量）（Linkage Metrics）\n      1. 单链接（Single-linkage）：簇间距离 = 两簇中任意样本的最短距离\n      2. 全链接（Complete-linkage）：簇间距离 = 两簇中任意样本的最长距离  （`注意：比较的是谁的最长距离最小，而不是最大`）\n      3. 平均链接（Average-linkage）：簇间距离 = 两簇中所有样本的平均距离\n   3. 方法特点：\n      1. 优势：可通过树状图选择聚类数量；结果具有确定性；链接准则灵活\n      2. 劣势：速度慢，朴素算法时间复杂度为n^3，仅部分链接准则存在n^2优化算法\n4. K-means 聚类\n   1. 算法流程：\n      1. 随机选k个样本作为初始值\n      2. 将每个样本分配至最近的质心，形成k个簇\n      3. 计算每个簇的新质心（簇内所有样本特征的平均值）\n      4. 质心是否变化？\n      5. 质心变化则返回第二步；质心不变则输出聚类结果\n   2. 时间复杂度：knd （n：样本总数；d：计算单个样本与质心距离的耗时）\n   3. 关键问题与解决办法：\n      1. 问题1：k 值选择不当\t\n      2. 解决办法：\n         1. 利用领域先验知识（如已知 5 种细菌，设 k=5）；\n         2. 测试不同 k 值，评估聚类质量；\n         3. 对部分数据运行层次聚类辅助选 k\n      3. 问题2：依赖初始质心\n      4. 解决办法：尝试多组随机初始质心，计算每组结果的差异，选择差异最小的结果作为最终聚类\n5. 聚类评估方法\n   1. 核心评估指标：总差异（dissimilarity）\n      1. 聚类质量通过 “总差异” 衡量，计算公式为：dissimilarity(clusters) = ∑ c∈clusters variability(c)\n      2. 其中variability(c)（簇内差异）= 簇内所有样本到该簇质心的距离平方和。总差异越小，聚类质量越好（簇内样本越集中）\n   2. 代码实现核心函数\n      1. dissimilarity(clusters)：计算所有簇的总差异\n      2. trykmeans(examples, numClusters, numTrials)：运行 numTrials 次 K-means，返回总差异最小的结果\n      3. printClustering(clustering)：输出各簇样本数与阳性率，辅助业务评估\n6. 关键问题\n   1. 层次聚类与 K-means 聚类在适用场景和性能上有何核心差异？如何根据数据特点选择这两种方法？\n      1. 适用场景：\n         1. 层次聚类适用于**无需提前确定聚类数量的场景**（可通过树状图灵活选 k），或对聚类结果确定性要求高的场景（如小样本数据的精细分组）\n         2. K-means 适用于**已知聚类数量范围**（如通过领域知识确定 k）、追求高效聚类的场景（如大样本数据）\n      2. 性能：\n         1. 层次聚类速度慢（朴素算法n^3），仅小样本适用\n         2. K-means 速度快（单次迭代 knd），可处理大样本，但结果依赖初始质心（需多组测试）\n      3. **选择依据：**\n         1. 选择层次聚类：若数据量小、需灵活选 k；；若需确定簇间关系（如层级结构）\n         2. 选择K-means：若数据量大、已知 k 范围或可通过测试选 k；若需避免局部最优\n   2. 在 K-means 聚类中，特征归一化（如 Z-Scaling）为何对聚类结果影响显著？\n      1. 特征归一化的核心作用是消除特征量纲差异导致的权重失衡，避免数值范围大的特征主导距离计算（K-means 依赖样本与质心的距离）\n      2. 未归一化的问题：患者数据中，“年龄”（如 20-80 岁）与 “ST 段抬高”（0/1 二元变量）数值范围差异极大，未归一化时，“年龄” 对距离的贡献远大于 “ST 段抬高”，导致聚类仅依赖年龄，无法捕捉 ST 段抬高（与心脏病风险直接相关）的特征，因此 k=2 时两簇阳性率接近（33.05% vs 33.33%），无实际意义\n      3. 归一化的作用：Z-Scaling 后，所有特征均值为 0、标准差为 1，各特征对距离的贡献权重一致，聚类可同时考虑心率、既往病史、年龄、ST 段抬高的综合影响，k=2 时出现高风险簇（26 人，阳性率 69.23%）与低风险簇（224 人，阳性率 29.02%），聚类结果符合业务逻辑（高风险患者被有效区分），证明归一化能让 K-means 捕捉关键特征关联，提升聚类实用性\n   3. 在聚类分析中，如何科学选择 K 值（聚类数量）？\n      1. k 值选择方法：\n         1. 利用领域先验知识（如已知 5 种细菌类型，直接设 k=5）\n         2. 测试多组 k 值，通过 “总差异（dissimilarity）” 评估（总差异越小，聚类内一致性越高），同时结合业务指标（如患者聚类的阳性率）\n         3. 对部分数据运行层次聚类，通过树状图的 “距离断点” 辅助确定 k 值范围\n      2. k 值选择与业务目标的关系（以患者数据为例）：\n         1. 若业务目标是`快速区分高 / 低风险患者`：选 k=2，此时高风险簇（26 人，69.23% 阳性率）与低风险簇（224 人，29.02% 阳性率）界限清晰，可快速筛选高风险人群\n         2. 若业务目标是`细分高风险患者（如制定个性化干预方案）`：选 k=4 或 k=6，k=4 时出现两个高风险簇（69.23%、71.05%），k=6 时高风险簇进一步细分（最高 77.78% 阳性率），可针对不同高风险 subgroup 分析特征（如是否有多次既往心脏病发作），制定精准方案\n         3. 若 k 值过大（如 k=10）：可能导致簇样本量过小（如部分簇仅 5-10 人），阳性率波动大（无统计意义），不符合 “稳定分组” 的业务需求，因此 k 值需在 “细分程度” 与 “簇稳定性” 间平衡\n\n## 今日总结\n1. 编程学习（进程）\n2. 看书一章\n3. 参加每周城市之旅活动，今天主要认识了一下小组成员以及了解了之后的安排，加了一个成员的微信，感觉通过介绍会是个不错的伙伴\n4. 把之前没学完的ppt学完了\n5. 英语学习","source":"_posts/2025-10-20.md","raw":"---\ntitle: 2025.10.20\ndate: 2025-10-20 08:41:01\ntags:\n---\n# Overview\n1. 周末总结\n2. 今日学习笔记\n3. 今日总结\n\n## 周末总结\n这周末暂时放松了一下，不过还是弹了琴，新曲子虽然有点难以掌握节奏，但以及整体过了一遍了，感觉再练几次就能弹下来了；原本打算带摩羯出去逛逛，结果起床完了，不过还是决定周末下午出去，结果刚骑到公园走了几步就开始下雨了，无奈之下只能提前回家了，没事以后有的是机会\n\n## 学习笔记\n\n### 数据科学（统计）\n1. 机器学习核心范式\n   1. 机器学习的核心逻辑： “观察训练数据→推断数据生成过程→预测测试数据”\n   2. 监督学习：给定特征 / 标签对，学习预测未知输入标签的规则\n   3. 无监督学习：仅给定特征向量（无标签），将样本分组为 “自然聚类”，聚类是无监督学习的核心任务之一\n2. 聚类（Clustering）的本质：优化问题，目标是找到聚类划分 C 以最小化聚类内差异（dissimilarity (C)），但需满足约束条件：\n   1. 若不设约束，会导致每个样本单独成簇（无意义），因此需添加约束，如 “聚类间最小距离” 或 “指定聚类数量（k）”\n   2. 核心逻辑：“大而差” 的聚类比 “小而差” 的聚类更差，需平衡聚类大小与内部一致性\n3. 层次聚类（Hierarchical Clustering）\n   1. 核心步骤：\n      1. 初始状态：每个样本单独成簇，N 个样本对应 N 个簇\n      2. 迭代合并：找到最相似（距离最近）的一对簇，合并为 1 个簇，簇数减少 1\n      3. 终止条件：所有样本合并为 1 个簇（大小为 N）\n   2. 簇间距离（链接度量）（Linkage Metrics）\n      1. 单链接（Single-linkage）：簇间距离 = 两簇中任意样本的最短距离\n      2. 全链接（Complete-linkage）：簇间距离 = 两簇中任意样本的最长距离  （`注意：比较的是谁的最长距离最小，而不是最大`）\n      3. 平均链接（Average-linkage）：簇间距离 = 两簇中所有样本的平均距离\n   3. 方法特点：\n      1. 优势：可通过树状图选择聚类数量；结果具有确定性；链接准则灵活\n      2. 劣势：速度慢，朴素算法时间复杂度为n^3，仅部分链接准则存在n^2优化算法\n4. K-means 聚类\n   1. 算法流程：\n      1. 随机选k个样本作为初始值\n      2. 将每个样本分配至最近的质心，形成k个簇\n      3. 计算每个簇的新质心（簇内所有样本特征的平均值）\n      4. 质心是否变化？\n      5. 质心变化则返回第二步；质心不变则输出聚类结果\n   2. 时间复杂度：knd （n：样本总数；d：计算单个样本与质心距离的耗时）\n   3. 关键问题与解决办法：\n      1. 问题1：k 值选择不当\t\n      2. 解决办法：\n         1. 利用领域先验知识（如已知 5 种细菌，设 k=5）；\n         2. 测试不同 k 值，评估聚类质量；\n         3. 对部分数据运行层次聚类辅助选 k\n      3. 问题2：依赖初始质心\n      4. 解决办法：尝试多组随机初始质心，计算每组结果的差异，选择差异最小的结果作为最终聚类\n5. 聚类评估方法\n   1. 核心评估指标：总差异（dissimilarity）\n      1. 聚类质量通过 “总差异” 衡量，计算公式为：dissimilarity(clusters) = ∑ c∈clusters variability(c)\n      2. 其中variability(c)（簇内差异）= 簇内所有样本到该簇质心的距离平方和。总差异越小，聚类质量越好（簇内样本越集中）\n   2. 代码实现核心函数\n      1. dissimilarity(clusters)：计算所有簇的总差异\n      2. trykmeans(examples, numClusters, numTrials)：运行 numTrials 次 K-means，返回总差异最小的结果\n      3. printClustering(clustering)：输出各簇样本数与阳性率，辅助业务评估\n6. 关键问题\n   1. 层次聚类与 K-means 聚类在适用场景和性能上有何核心差异？如何根据数据特点选择这两种方法？\n      1. 适用场景：\n         1. 层次聚类适用于**无需提前确定聚类数量的场景**（可通过树状图灵活选 k），或对聚类结果确定性要求高的场景（如小样本数据的精细分组）\n         2. K-means 适用于**已知聚类数量范围**（如通过领域知识确定 k）、追求高效聚类的场景（如大样本数据）\n      2. 性能：\n         1. 层次聚类速度慢（朴素算法n^3），仅小样本适用\n         2. K-means 速度快（单次迭代 knd），可处理大样本，但结果依赖初始质心（需多组测试）\n      3. **选择依据：**\n         1. 选择层次聚类：若数据量小、需灵活选 k；；若需确定簇间关系（如层级结构）\n         2. 选择K-means：若数据量大、已知 k 范围或可通过测试选 k；若需避免局部最优\n   2. 在 K-means 聚类中，特征归一化（如 Z-Scaling）为何对聚类结果影响显著？\n      1. 特征归一化的核心作用是消除特征量纲差异导致的权重失衡，避免数值范围大的特征主导距离计算（K-means 依赖样本与质心的距离）\n      2. 未归一化的问题：患者数据中，“年龄”（如 20-80 岁）与 “ST 段抬高”（0/1 二元变量）数值范围差异极大，未归一化时，“年龄” 对距离的贡献远大于 “ST 段抬高”，导致聚类仅依赖年龄，无法捕捉 ST 段抬高（与心脏病风险直接相关）的特征，因此 k=2 时两簇阳性率接近（33.05% vs 33.33%），无实际意义\n      3. 归一化的作用：Z-Scaling 后，所有特征均值为 0、标准差为 1，各特征对距离的贡献权重一致，聚类可同时考虑心率、既往病史、年龄、ST 段抬高的综合影响，k=2 时出现高风险簇（26 人，阳性率 69.23%）与低风险簇（224 人，阳性率 29.02%），聚类结果符合业务逻辑（高风险患者被有效区分），证明归一化能让 K-means 捕捉关键特征关联，提升聚类实用性\n   3. 在聚类分析中，如何科学选择 K 值（聚类数量）？\n      1. k 值选择方法：\n         1. 利用领域先验知识（如已知 5 种细菌类型，直接设 k=5）\n         2. 测试多组 k 值，通过 “总差异（dissimilarity）” 评估（总差异越小，聚类内一致性越高），同时结合业务指标（如患者聚类的阳性率）\n         3. 对部分数据运行层次聚类，通过树状图的 “距离断点” 辅助确定 k 值范围\n      2. k 值选择与业务目标的关系（以患者数据为例）：\n         1. 若业务目标是`快速区分高 / 低风险患者`：选 k=2，此时高风险簇（26 人，69.23% 阳性率）与低风险簇（224 人，29.02% 阳性率）界限清晰，可快速筛选高风险人群\n         2. 若业务目标是`细分高风险患者（如制定个性化干预方案）`：选 k=4 或 k=6，k=4 时出现两个高风险簇（69.23%、71.05%），k=6 时高风险簇进一步细分（最高 77.78% 阳性率），可针对不同高风险 subgroup 分析特征（如是否有多次既往心脏病发作），制定精准方案\n         3. 若 k 值过大（如 k=10）：可能导致簇样本量过小（如部分簇仅 5-10 人），阳性率波动大（无统计意义），不符合 “稳定分组” 的业务需求，因此 k 值需在 “细分程度” 与 “簇稳定性” 间平衡\n\n## 今日总结\n1. 编程学习（进程）\n2. 看书一章\n3. 参加每周城市之旅活动，今天主要认识了一下小组成员以及了解了之后的安排，加了一个成员的微信，感觉通过介绍会是个不错的伙伴\n4. 把之前没学完的ppt学完了\n5. 英语学习","slug":"2025-10-20","published":1,"updated":"2025-11-18T19:39:17.117Z","comments":1,"layout":"post","photos":[],"_id":"cuidrxPkVwCd2YsB0eS4bw7AZ","content":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>周末总结</li>\n<li>今日学习笔记</li>\n<li>今日总结</li>\n</ol>\n<h2 id=\"周末总结\"><a href=\"#周末总结\" class=\"headerlink\" title=\"周末总结\"></a>周末总结</h2><p>这周末暂时放松了一下，不过还是弹了琴，新曲子虽然有点难以掌握节奏，但以及整体过了一遍了，感觉再练几次就能弹下来了；原本打算带摩羯出去逛逛，结果起床完了，不过还是决定周末下午出去，结果刚骑到公园走了几步就开始下雨了，无奈之下只能提前回家了，没事以后有的是机会</p>\n<h2 id=\"学习笔记\"><a href=\"#学习笔记\" class=\"headerlink\" title=\"学习笔记\"></a>学习笔记</h2><h3 id=\"数据科学（统计）\"><a href=\"#数据科学（统计）\" class=\"headerlink\" title=\"数据科学（统计）\"></a>数据科学（统计）</h3><ol>\n<li>机器学习核心范式<ol>\n<li>机器学习的核心逻辑： “观察训练数据→推断数据生成过程→预测测试数据”</li>\n<li>监督学习：给定特征 &#x2F; 标签对，学习预测未知输入标签的规则</li>\n<li>无监督学习：仅给定特征向量（无标签），将样本分组为 “自然聚类”，聚类是无监督学习的核心任务之一</li>\n</ol>\n</li>\n<li>聚类（Clustering）的本质：优化问题，目标是找到聚类划分 C 以最小化聚类内差异（dissimilarity (C)），但需满足约束条件：<ol>\n<li>若不设约束，会导致每个样本单独成簇（无意义），因此需添加约束，如 “聚类间最小距离” 或 “指定聚类数量（k）”</li>\n<li>核心逻辑：“大而差” 的聚类比 “小而差” 的聚类更差，需平衡聚类大小与内部一致性</li>\n</ol>\n</li>\n<li>层次聚类（Hierarchical Clustering）<ol>\n<li>核心步骤：<ol>\n<li>初始状态：每个样本单独成簇，N 个样本对应 N 个簇</li>\n<li>迭代合并：找到最相似（距离最近）的一对簇，合并为 1 个簇，簇数减少 1</li>\n<li>终止条件：所有样本合并为 1 个簇（大小为 N）</li>\n</ol>\n</li>\n<li>簇间距离（链接度量）（Linkage Metrics）<ol>\n<li>单链接（Single-linkage）：簇间距离 &#x3D; 两簇中任意样本的最短距离</li>\n<li>全链接（Complete-linkage）：簇间距离 &#x3D; 两簇中任意样本的最长距离  （<code>注意：比较的是谁的最长距离最小，而不是最大</code>）</li>\n<li>平均链接（Average-linkage）：簇间距离 &#x3D; 两簇中所有样本的平均距离</li>\n</ol>\n</li>\n<li>方法特点：<ol>\n<li>优势：可通过树状图选择聚类数量；结果具有确定性；链接准则灵活</li>\n<li>劣势：速度慢，朴素算法时间复杂度为n^3，仅部分链接准则存在n^2优化算法</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>K-means 聚类<ol>\n<li>算法流程：<ol>\n<li>随机选k个样本作为初始值</li>\n<li>将每个样本分配至最近的质心，形成k个簇</li>\n<li>计算每个簇的新质心（簇内所有样本特征的平均值）</li>\n<li>质心是否变化？</li>\n<li>质心变化则返回第二步；质心不变则输出聚类结果</li>\n</ol>\n</li>\n<li>时间复杂度：knd （n：样本总数；d：计算单个样本与质心距离的耗时）</li>\n<li>关键问题与解决办法：<ol>\n<li>问题1：k 值选择不当    </li>\n<li>解决办法：<ol>\n<li>利用领域先验知识（如已知 5 种细菌，设 k&#x3D;5）；</li>\n<li>测试不同 k 值，评估聚类质量；</li>\n<li>对部分数据运行层次聚类辅助选 k</li>\n</ol>\n</li>\n<li>问题2：依赖初始质心</li>\n<li>解决办法：尝试多组随机初始质心，计算每组结果的差异，选择差异最小的结果作为最终聚类</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>聚类评估方法<ol>\n<li>核心评估指标：总差异（dissimilarity）<ol>\n<li>聚类质量通过 “总差异” 衡量，计算公式为：dissimilarity(clusters) &#x3D; ∑ c∈clusters variability(c)</li>\n<li>其中variability(c)（簇内差异）&#x3D; 簇内所有样本到该簇质心的距离平方和。总差异越小，聚类质量越好（簇内样本越集中）</li>\n</ol>\n</li>\n<li>代码实现核心函数<ol>\n<li>dissimilarity(clusters)：计算所有簇的总差异</li>\n<li>trykmeans(examples, numClusters, numTrials)：运行 numTrials 次 K-means，返回总差异最小的结果</li>\n<li>printClustering(clustering)：输出各簇样本数与阳性率，辅助业务评估</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>关键问题<ol>\n<li>层次聚类与 K-means 聚类在适用场景和性能上有何核心差异？如何根据数据特点选择这两种方法？<ol>\n<li>适用场景：<ol>\n<li>层次聚类适用于<strong>无需提前确定聚类数量的场景</strong>（可通过树状图灵活选 k），或对聚类结果确定性要求高的场景（如小样本数据的精细分组）</li>\n<li>K-means 适用于<strong>已知聚类数量范围</strong>（如通过领域知识确定 k）、追求高效聚类的场景（如大样本数据）</li>\n</ol>\n</li>\n<li>性能：<ol>\n<li>层次聚类速度慢（朴素算法n^3），仅小样本适用</li>\n<li>K-means 速度快（单次迭代 knd），可处理大样本，但结果依赖初始质心（需多组测试）</li>\n</ol>\n</li>\n<li><strong>选择依据：</strong><ol>\n<li>选择层次聚类：若数据量小、需灵活选 k；；若需确定簇间关系（如层级结构）</li>\n<li>选择K-means：若数据量大、已知 k 范围或可通过测试选 k；若需避免局部最优</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>在 K-means 聚类中，特征归一化（如 Z-Scaling）为何对聚类结果影响显著？<ol>\n<li>特征归一化的核心作用是消除特征量纲差异导致的权重失衡，避免数值范围大的特征主导距离计算（K-means 依赖样本与质心的距离）</li>\n<li>未归一化的问题：患者数据中，“年龄”（如 20-80 岁）与 “ST 段抬高”（0&#x2F;1 二元变量）数值范围差异极大，未归一化时，“年龄” 对距离的贡献远大于 “ST 段抬高”，导致聚类仅依赖年龄，无法捕捉 ST 段抬高（与心脏病风险直接相关）的特征，因此 k&#x3D;2 时两簇阳性率接近（33.05% vs 33.33%），无实际意义</li>\n<li>归一化的作用：Z-Scaling 后，所有特征均值为 0、标准差为 1，各特征对距离的贡献权重一致，聚类可同时考虑心率、既往病史、年龄、ST 段抬高的综合影响，k&#x3D;2 时出现高风险簇（26 人，阳性率 69.23%）与低风险簇（224 人，阳性率 29.02%），聚类结果符合业务逻辑（高风险患者被有效区分），证明归一化能让 K-means 捕捉关键特征关联，提升聚类实用性</li>\n</ol>\n</li>\n<li>在聚类分析中，如何科学选择 K 值（聚类数量）？<ol>\n<li>k 值选择方法：<ol>\n<li>利用领域先验知识（如已知 5 种细菌类型，直接设 k&#x3D;5）</li>\n<li>测试多组 k 值，通过 “总差异（dissimilarity）” 评估（总差异越小，聚类内一致性越高），同时结合业务指标（如患者聚类的阳性率）</li>\n<li>对部分数据运行层次聚类，通过树状图的 “距离断点” 辅助确定 k 值范围</li>\n</ol>\n</li>\n<li>k 值选择与业务目标的关系（以患者数据为例）：<ol>\n<li>若业务目标是<code>快速区分高 / 低风险患者</code>：选 k&#x3D;2，此时高风险簇（26 人，69.23% 阳性率）与低风险簇（224 人，29.02% 阳性率）界限清晰，可快速筛选高风险人群</li>\n<li>若业务目标是<code>细分高风险患者（如制定个性化干预方案）</code>：选 k&#x3D;4 或 k&#x3D;6，k&#x3D;4 时出现两个高风险簇（69.23%、71.05%），k&#x3D;6 时高风险簇进一步细分（最高 77.78% 阳性率），可针对不同高风险 subgroup 分析特征（如是否有多次既往心脏病发作），制定精准方案</li>\n<li>若 k 值过大（如 k&#x3D;10）：可能导致簇样本量过小（如部分簇仅 5-10 人），阳性率波动大（无统计意义），不符合 “稳定分组” 的业务需求，因此 k 值需在 “细分程度” 与 “簇稳定性” 间平衡</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"今日总结\"><a href=\"#今日总结\" class=\"headerlink\" title=\"今日总结\"></a>今日总结</h2><ol>\n<li>编程学习（进程）</li>\n<li>看书一章</li>\n<li>参加每周城市之旅活动，今天主要认识了一下小组成员以及了解了之后的安排，加了一个成员的微信，感觉通过介绍会是个不错的伙伴</li>\n<li>把之前没学完的ppt学完了</li>\n<li>英语学习</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>周末总结</li>\n<li>今日学习笔记</li>\n<li>今日总结</li>\n</ol>\n<h2 id=\"周末总结\"><a href=\"#周末总结\" class=\"headerlink\" title=\"周末总结\"></a>周末总结</h2><p>这周末暂时放松了一下，不过还是弹了琴，新曲子虽然有点难以掌握节奏，但以及整体过了一遍了，感觉再练几次就能弹下来了；原本打算带摩羯出去逛逛，结果起床完了，不过还是决定周末下午出去，结果刚骑到公园走了几步就开始下雨了，无奈之下只能提前回家了，没事以后有的是机会</p>\n<h2 id=\"学习笔记\"><a href=\"#学习笔记\" class=\"headerlink\" title=\"学习笔记\"></a>学习笔记</h2><h3 id=\"数据科学（统计）\"><a href=\"#数据科学（统计）\" class=\"headerlink\" title=\"数据科学（统计）\"></a>数据科学（统计）</h3><ol>\n<li>机器学习核心范式<ol>\n<li>机器学习的核心逻辑： “观察训练数据→推断数据生成过程→预测测试数据”</li>\n<li>监督学习：给定特征 &#x2F; 标签对，学习预测未知输入标签的规则</li>\n<li>无监督学习：仅给定特征向量（无标签），将样本分组为 “自然聚类”，聚类是无监督学习的核心任务之一</li>\n</ol>\n</li>\n<li>聚类（Clustering）的本质：优化问题，目标是找到聚类划分 C 以最小化聚类内差异（dissimilarity (C)），但需满足约束条件：<ol>\n<li>若不设约束，会导致每个样本单独成簇（无意义），因此需添加约束，如 “聚类间最小距离” 或 “指定聚类数量（k）”</li>\n<li>核心逻辑：“大而差” 的聚类比 “小而差” 的聚类更差，需平衡聚类大小与内部一致性</li>\n</ol>\n</li>\n<li>层次聚类（Hierarchical Clustering）<ol>\n<li>核心步骤：<ol>\n<li>初始状态：每个样本单独成簇，N 个样本对应 N 个簇</li>\n<li>迭代合并：找到最相似（距离最近）的一对簇，合并为 1 个簇，簇数减少 1</li>\n<li>终止条件：所有样本合并为 1 个簇（大小为 N）</li>\n</ol>\n</li>\n<li>簇间距离（链接度量）（Linkage Metrics）<ol>\n<li>单链接（Single-linkage）：簇间距离 &#x3D; 两簇中任意样本的最短距离</li>\n<li>全链接（Complete-linkage）：簇间距离 &#x3D; 两簇中任意样本的最长距离  （<code>注意：比较的是谁的最长距离最小，而不是最大</code>）</li>\n<li>平均链接（Average-linkage）：簇间距离 &#x3D; 两簇中所有样本的平均距离</li>\n</ol>\n</li>\n<li>方法特点：<ol>\n<li>优势：可通过树状图选择聚类数量；结果具有确定性；链接准则灵活</li>\n<li>劣势：速度慢，朴素算法时间复杂度为n^3，仅部分链接准则存在n^2优化算法</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>K-means 聚类<ol>\n<li>算法流程：<ol>\n<li>随机选k个样本作为初始值</li>\n<li>将每个样本分配至最近的质心，形成k个簇</li>\n<li>计算每个簇的新质心（簇内所有样本特征的平均值）</li>\n<li>质心是否变化？</li>\n<li>质心变化则返回第二步；质心不变则输出聚类结果</li>\n</ol>\n</li>\n<li>时间复杂度：knd （n：样本总数；d：计算单个样本与质心距离的耗时）</li>\n<li>关键问题与解决办法：<ol>\n<li>问题1：k 值选择不当    </li>\n<li>解决办法：<ol>\n<li>利用领域先验知识（如已知 5 种细菌，设 k&#x3D;5）；</li>\n<li>测试不同 k 值，评估聚类质量；</li>\n<li>对部分数据运行层次聚类辅助选 k</li>\n</ol>\n</li>\n<li>问题2：依赖初始质心</li>\n<li>解决办法：尝试多组随机初始质心，计算每组结果的差异，选择差异最小的结果作为最终聚类</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>聚类评估方法<ol>\n<li>核心评估指标：总差异（dissimilarity）<ol>\n<li>聚类质量通过 “总差异” 衡量，计算公式为：dissimilarity(clusters) &#x3D; ∑ c∈clusters variability(c)</li>\n<li>其中variability(c)（簇内差异）&#x3D; 簇内所有样本到该簇质心的距离平方和。总差异越小，聚类质量越好（簇内样本越集中）</li>\n</ol>\n</li>\n<li>代码实现核心函数<ol>\n<li>dissimilarity(clusters)：计算所有簇的总差异</li>\n<li>trykmeans(examples, numClusters, numTrials)：运行 numTrials 次 K-means，返回总差异最小的结果</li>\n<li>printClustering(clustering)：输出各簇样本数与阳性率，辅助业务评估</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>关键问题<ol>\n<li>层次聚类与 K-means 聚类在适用场景和性能上有何核心差异？如何根据数据特点选择这两种方法？<ol>\n<li>适用场景：<ol>\n<li>层次聚类适用于<strong>无需提前确定聚类数量的场景</strong>（可通过树状图灵活选 k），或对聚类结果确定性要求高的场景（如小样本数据的精细分组）</li>\n<li>K-means 适用于<strong>已知聚类数量范围</strong>（如通过领域知识确定 k）、追求高效聚类的场景（如大样本数据）</li>\n</ol>\n</li>\n<li>性能：<ol>\n<li>层次聚类速度慢（朴素算法n^3），仅小样本适用</li>\n<li>K-means 速度快（单次迭代 knd），可处理大样本，但结果依赖初始质心（需多组测试）</li>\n</ol>\n</li>\n<li><strong>选择依据：</strong><ol>\n<li>选择层次聚类：若数据量小、需灵活选 k；；若需确定簇间关系（如层级结构）</li>\n<li>选择K-means：若数据量大、已知 k 范围或可通过测试选 k；若需避免局部最优</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>在 K-means 聚类中，特征归一化（如 Z-Scaling）为何对聚类结果影响显著？<ol>\n<li>特征归一化的核心作用是消除特征量纲差异导致的权重失衡，避免数值范围大的特征主导距离计算（K-means 依赖样本与质心的距离）</li>\n<li>未归一化的问题：患者数据中，“年龄”（如 20-80 岁）与 “ST 段抬高”（0&#x2F;1 二元变量）数值范围差异极大，未归一化时，“年龄” 对距离的贡献远大于 “ST 段抬高”，导致聚类仅依赖年龄，无法捕捉 ST 段抬高（与心脏病风险直接相关）的特征，因此 k&#x3D;2 时两簇阳性率接近（33.05% vs 33.33%），无实际意义</li>\n<li>归一化的作用：Z-Scaling 后，所有特征均值为 0、标准差为 1，各特征对距离的贡献权重一致，聚类可同时考虑心率、既往病史、年龄、ST 段抬高的综合影响，k&#x3D;2 时出现高风险簇（26 人，阳性率 69.23%）与低风险簇（224 人，阳性率 29.02%），聚类结果符合业务逻辑（高风险患者被有效区分），证明归一化能让 K-means 捕捉关键特征关联，提升聚类实用性</li>\n</ol>\n</li>\n<li>在聚类分析中，如何科学选择 K 值（聚类数量）？<ol>\n<li>k 值选择方法：<ol>\n<li>利用领域先验知识（如已知 5 种细菌类型，直接设 k&#x3D;5）</li>\n<li>测试多组 k 值，通过 “总差异（dissimilarity）” 评估（总差异越小，聚类内一致性越高），同时结合业务指标（如患者聚类的阳性率）</li>\n<li>对部分数据运行层次聚类，通过树状图的 “距离断点” 辅助确定 k 值范围</li>\n</ol>\n</li>\n<li>k 值选择与业务目标的关系（以患者数据为例）：<ol>\n<li>若业务目标是<code>快速区分高 / 低风险患者</code>：选 k&#x3D;2，此时高风险簇（26 人，69.23% 阳性率）与低风险簇（224 人，29.02% 阳性率）界限清晰，可快速筛选高风险人群</li>\n<li>若业务目标是<code>细分高风险患者（如制定个性化干预方案）</code>：选 k&#x3D;4 或 k&#x3D;6，k&#x3D;4 时出现两个高风险簇（69.23%、71.05%），k&#x3D;6 时高风险簇进一步细分（最高 77.78% 阳性率），可针对不同高风险 subgroup 分析特征（如是否有多次既往心脏病发作），制定精准方案</li>\n<li>若 k 值过大（如 k&#x3D;10）：可能导致簇样本量过小（如部分簇仅 5-10 人），阳性率波动大（无统计意义），不符合 “稳定分组” 的业务需求，因此 k 值需在 “细分程度” 与 “簇稳定性” 间平衡</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"今日总结\"><a href=\"#今日总结\" class=\"headerlink\" title=\"今日总结\"></a>今日总结</h2><ol>\n<li>编程学习（进程）</li>\n<li>看书一章</li>\n<li>参加每周城市之旅活动，今天主要认识了一下小组成员以及了解了之后的安排，加了一个成员的微信，感觉通过介绍会是个不错的伙伴</li>\n<li>把之前没学完的ppt学完了</li>\n<li>英语学习</li>\n</ol>\n"},{"title":"2025.11.2","date":"2025-11-02T00:53:45.000Z","_content":"# Overview\n1. 周末总结\n2. 学习笔记\n3. 后续安排\n\n## 周末总结\n1. 骑行探索了一下市区的两个湿地公园，并带摩羯溜了一圈\n2. 在飞盘活动中学习了长传和正手发盘\n3. 训练好了一个英语口语交流AI\n\n## 学习笔记\n\n### 统计\n1. 人工智能（AI）基础\n    1. AI 的定义与核心能力\n       1. 定义：AI 即 “人工（人造）” 与 “智能（思考能力）” 的结合，是计算机科学的一个分支，能模拟人类智能并在机器上实现，用于执行原本需要人类智能的任务\n       2. 核心功能：包括学习、推理、问题解决和快速决策\n   2. AI 的典型应用领域：图像、制造、医疗、互联网、金融、零售、自然语言生成\n2. 神经网络（NN）概述\n   1. 神经网络与 AI 的关系\n      1. 核心地位：当前大多数主流 AI 模型均基于神经网络，神经网络是 AI 模拟人类智能的核心技术\n      2. 结构灵感：神经网络由相互连接的 “神经元” 构成，灵感来源于生物大脑的神经元连接结构\n      3. 基础架构示例：以图像识别鸟类为例，输入层接收图像像素，经隐藏层处理，最终由输出层输出识别结果，各层间通过权重传递信息\n3. 卷积神经网络（CNN）\n   1. CNN 的基础：神经元行为\n      1. 神经元输出公式：单个神经元的输出遵循公式 y = tanh(w₁x₁ + w₂x₂ + b)，其中 w₁、w₂为输入 x₁、x₂的权重，b 为偏置，tanh 为激活函数（输出范围 - 1 至 1）\n   2. 卷积层与 CNN 的核心功能\n      1. 卷积层的作用：通过 “滤波器（Filter）” 对输入图像进行处理，提取图像特征，如垂直条纹、水平边缘、对角线边缘、白色斑点、对角线交叉等\n      2. 特征图（激活值）：卷积层的输出是一组滤波后的图像，称为 “特征图”，也叫该层的 “激活值”，其形式为 3D 数组，第三维度称为 “通道”，可单独可视化（灰度图）或组合可视化（彩色图）\n   3. CNN 的实用技巧与数据处理\n      1. 预训练网络的应用：由于深度学习训练耗时久（无 GPU 时难度大），可利用预训练网络提取特征，再结合传统机器学习方法进行分类\n      2. 特征提取流程：CNN 在学习图像分类的同时提取有用特征 —— 早期层读取输入图像并提取基础特征，全连接层利用这些特征完成分类；其中，第一个全连接层之前的所有层可作为独立的特征提取网络\n      3. 信号数据的图像化：将信号数据（如频谱图）转化为图像形式，输入 CNN 进行特征提取与分类，拓展 CNN 的应用场景\n4. 循环神经网络（RNN）\n   1. RNN 的关键类型\n      1. 长短期记忆网络（LSTM）：解决传统 RNN 的长期依赖问题，能处理序列数据，可用于序列分类（如 “喜欢跳舞” 的文本分类）\n      2. 双向 LSTM：同时从序列的正向和反向进行学习，提升序列分类的准确性，适用于对上下文依赖较强的任务（如文本标点优化：将 “punctuation is important and need” 优化为 “punctuation important, and”）\n   2. RNN 的序列预处理\n      1. 分类序列的数值化：训练 LSTM 需输入数值型序列，若序列为分类类型（如天气序列、DNA 序列（A/G/T）、音符序列、星期序列（周一至周六）），需先将其转化为数值形式才能进行模型训练\n5. 网络训练与大数据的关系\n   1. 网络训练的核心要素\n      1. 训练 checklist：成功的网络训练需具备四大要素 ——训练数据（模型学习的基础）、网络架构（模型的结构设计）、算法选项（训练所用的算法）、损失函数（计算模型输出与真实值的总误差，用于优化模型）\n   2. AI 与大数据的依存关系\n      1. 数据是 AI 的基础：没有大数据，AI 无法进行有效学习；AI 模型的智能程度与接触的数据量正相关 —— 数据越多，模型能学习到的规律越丰富，智能程度越高\n      2. 类比人类学习：AI 模型通过大数据训练，类似人类大脑通过积累大量经验（数据）来学习和提升能力\n\n## 安排及所学\n为了实现成为全栈AI开发者的终极目标，第一步打算实现极简个人网站\nHTML、CSS、JavaScript的理解：  \n若拿盖一座房子做比喻：  \n1. HTML -- 房子的结构和内容\n   1. 它负责定义网页上有什么内容\n   2. 墙壁和房间： 这是标题，那是段落，这边是一个图片，那边是一个按钮\n   3. `纯结构： 它不管这些东西好不好看`。墙壁就是光秃秃的水泥墙，按钮就是个方框，上面写着字\n2. CSS -- 房子的装修和设计\n   1. 它负责定义网页内容看起来是什么样子\n   2. 美化： 把标题的文字变成红色、放大；把段落的文字变成某种字体，调整行距；把图片加个圆角边框；把按钮的背景变成蓝色，让鼠标放上去时会变色\n   3. 布局： 决定导航栏在顶部，侧边栏在左边，主要内容在中间\n3. JavaScript -- 让房子变成智能家居的电路\n   1. 它负责让网页动起来，并能与用户互动\n   2. 交互响应：你点击一个按钮，会弹出一个对话框。你把鼠标移到菜单上，菜单会向下展开\n   3. 动态改变内容：网站可以自动更新最新的新闻头条。社交媒体页面上，你发布一条新状态，页面会立刻显示出来，而不用你手动刷新整个页面\n   4. 进行计算和验证：在购物网站，当你把商品加入购物车时，JavaScript 会立刻计算总价。在填写注册表单时，它会立即检查你的密码是否足够安全，或者邮箱格式是否正确\n   5. `创建复杂的动画和游戏： 网页上那些复杂的幻灯片轮播、有趣的交互动画，以及所有在浏览器里运行的简单游戏（比如贪吃蛇），几乎都是用 JavaScript 实现的`\n\n\n","source":"_posts/2025-11-2.md","raw":"---\ntitle: 2025.11.2\ndate: 2025-11-02 08:53:45\ntags:\n---\n# Overview\n1. 周末总结\n2. 学习笔记\n3. 后续安排\n\n## 周末总结\n1. 骑行探索了一下市区的两个湿地公园，并带摩羯溜了一圈\n2. 在飞盘活动中学习了长传和正手发盘\n3. 训练好了一个英语口语交流AI\n\n## 学习笔记\n\n### 统计\n1. 人工智能（AI）基础\n    1. AI 的定义与核心能力\n       1. 定义：AI 即 “人工（人造）” 与 “智能（思考能力）” 的结合，是计算机科学的一个分支，能模拟人类智能并在机器上实现，用于执行原本需要人类智能的任务\n       2. 核心功能：包括学习、推理、问题解决和快速决策\n   2. AI 的典型应用领域：图像、制造、医疗、互联网、金融、零售、自然语言生成\n2. 神经网络（NN）概述\n   1. 神经网络与 AI 的关系\n      1. 核心地位：当前大多数主流 AI 模型均基于神经网络，神经网络是 AI 模拟人类智能的核心技术\n      2. 结构灵感：神经网络由相互连接的 “神经元” 构成，灵感来源于生物大脑的神经元连接结构\n      3. 基础架构示例：以图像识别鸟类为例，输入层接收图像像素，经隐藏层处理，最终由输出层输出识别结果，各层间通过权重传递信息\n3. 卷积神经网络（CNN）\n   1. CNN 的基础：神经元行为\n      1. 神经元输出公式：单个神经元的输出遵循公式 y = tanh(w₁x₁ + w₂x₂ + b)，其中 w₁、w₂为输入 x₁、x₂的权重，b 为偏置，tanh 为激活函数（输出范围 - 1 至 1）\n   2. 卷积层与 CNN 的核心功能\n      1. 卷积层的作用：通过 “滤波器（Filter）” 对输入图像进行处理，提取图像特征，如垂直条纹、水平边缘、对角线边缘、白色斑点、对角线交叉等\n      2. 特征图（激活值）：卷积层的输出是一组滤波后的图像，称为 “特征图”，也叫该层的 “激活值”，其形式为 3D 数组，第三维度称为 “通道”，可单独可视化（灰度图）或组合可视化（彩色图）\n   3. CNN 的实用技巧与数据处理\n      1. 预训练网络的应用：由于深度学习训练耗时久（无 GPU 时难度大），可利用预训练网络提取特征，再结合传统机器学习方法进行分类\n      2. 特征提取流程：CNN 在学习图像分类的同时提取有用特征 —— 早期层读取输入图像并提取基础特征，全连接层利用这些特征完成分类；其中，第一个全连接层之前的所有层可作为独立的特征提取网络\n      3. 信号数据的图像化：将信号数据（如频谱图）转化为图像形式，输入 CNN 进行特征提取与分类，拓展 CNN 的应用场景\n4. 循环神经网络（RNN）\n   1. RNN 的关键类型\n      1. 长短期记忆网络（LSTM）：解决传统 RNN 的长期依赖问题，能处理序列数据，可用于序列分类（如 “喜欢跳舞” 的文本分类）\n      2. 双向 LSTM：同时从序列的正向和反向进行学习，提升序列分类的准确性，适用于对上下文依赖较强的任务（如文本标点优化：将 “punctuation is important and need” 优化为 “punctuation important, and”）\n   2. RNN 的序列预处理\n      1. 分类序列的数值化：训练 LSTM 需输入数值型序列，若序列为分类类型（如天气序列、DNA 序列（A/G/T）、音符序列、星期序列（周一至周六）），需先将其转化为数值形式才能进行模型训练\n5. 网络训练与大数据的关系\n   1. 网络训练的核心要素\n      1. 训练 checklist：成功的网络训练需具备四大要素 ——训练数据（模型学习的基础）、网络架构（模型的结构设计）、算法选项（训练所用的算法）、损失函数（计算模型输出与真实值的总误差，用于优化模型）\n   2. AI 与大数据的依存关系\n      1. 数据是 AI 的基础：没有大数据，AI 无法进行有效学习；AI 模型的智能程度与接触的数据量正相关 —— 数据越多，模型能学习到的规律越丰富，智能程度越高\n      2. 类比人类学习：AI 模型通过大数据训练，类似人类大脑通过积累大量经验（数据）来学习和提升能力\n\n## 安排及所学\n为了实现成为全栈AI开发者的终极目标，第一步打算实现极简个人网站\nHTML、CSS、JavaScript的理解：  \n若拿盖一座房子做比喻：  \n1. HTML -- 房子的结构和内容\n   1. 它负责定义网页上有什么内容\n   2. 墙壁和房间： 这是标题，那是段落，这边是一个图片，那边是一个按钮\n   3. `纯结构： 它不管这些东西好不好看`。墙壁就是光秃秃的水泥墙，按钮就是个方框，上面写着字\n2. CSS -- 房子的装修和设计\n   1. 它负责定义网页内容看起来是什么样子\n   2. 美化： 把标题的文字变成红色、放大；把段落的文字变成某种字体，调整行距；把图片加个圆角边框；把按钮的背景变成蓝色，让鼠标放上去时会变色\n   3. 布局： 决定导航栏在顶部，侧边栏在左边，主要内容在中间\n3. JavaScript -- 让房子变成智能家居的电路\n   1. 它负责让网页动起来，并能与用户互动\n   2. 交互响应：你点击一个按钮，会弹出一个对话框。你把鼠标移到菜单上，菜单会向下展开\n   3. 动态改变内容：网站可以自动更新最新的新闻头条。社交媒体页面上，你发布一条新状态，页面会立刻显示出来，而不用你手动刷新整个页面\n   4. 进行计算和验证：在购物网站，当你把商品加入购物车时，JavaScript 会立刻计算总价。在填写注册表单时，它会立即检查你的密码是否足够安全，或者邮箱格式是否正确\n   5. `创建复杂的动画和游戏： 网页上那些复杂的幻灯片轮播、有趣的交互动画，以及所有在浏览器里运行的简单游戏（比如贪吃蛇），几乎都是用 JavaScript 实现的`\n\n\n","slug":"2025-11-2","published":1,"updated":"2025-11-18T19:39:17.151Z","comments":1,"layout":"post","photos":[],"_id":"cuidcsPufEP1tlhdQo2-IrhYA","content":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>周末总结</li>\n<li>学习笔记</li>\n<li>后续安排</li>\n</ol>\n<h2 id=\"周末总结\"><a href=\"#周末总结\" class=\"headerlink\" title=\"周末总结\"></a>周末总结</h2><ol>\n<li>骑行探索了一下市区的两个湿地公园，并带摩羯溜了一圈</li>\n<li>在飞盘活动中学习了长传和正手发盘</li>\n<li>训练好了一个英语口语交流AI</li>\n</ol>\n<h2 id=\"学习笔记\"><a href=\"#学习笔记\" class=\"headerlink\" title=\"学习笔记\"></a>学习笔记</h2><h3 id=\"统计\"><a href=\"#统计\" class=\"headerlink\" title=\"统计\"></a>统计</h3><ol>\n<li>人工智能（AI）基础<ol>\n<li>AI 的定义与核心能力<ol>\n<li>定义：AI 即 “人工（人造）” 与 “智能（思考能力）” 的结合，是计算机科学的一个分支，能模拟人类智能并在机器上实现，用于执行原本需要人类智能的任务</li>\n<li>核心功能：包括学习、推理、问题解决和快速决策</li>\n</ol>\n</li>\n<li>AI 的典型应用领域：图像、制造、医疗、互联网、金融、零售、自然语言生成</li>\n</ol>\n</li>\n<li>神经网络（NN）概述<ol>\n<li>神经网络与 AI 的关系<ol>\n<li>核心地位：当前大多数主流 AI 模型均基于神经网络，神经网络是 AI 模拟人类智能的核心技术</li>\n<li>结构灵感：神经网络由相互连接的 “神经元” 构成，灵感来源于生物大脑的神经元连接结构</li>\n<li>基础架构示例：以图像识别鸟类为例，输入层接收图像像素，经隐藏层处理，最终由输出层输出识别结果，各层间通过权重传递信息</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>卷积神经网络（CNN）<ol>\n<li>CNN 的基础：神经元行为<ol>\n<li>神经元输出公式：单个神经元的输出遵循公式 y &#x3D; tanh(w₁x₁ + w₂x₂ + b)，其中 w₁、w₂为输入 x₁、x₂的权重，b 为偏置，tanh 为激活函数（输出范围 - 1 至 1）</li>\n</ol>\n</li>\n<li>卷积层与 CNN 的核心功能<ol>\n<li>卷积层的作用：通过 “滤波器（Filter）” 对输入图像进行处理，提取图像特征，如垂直条纹、水平边缘、对角线边缘、白色斑点、对角线交叉等</li>\n<li>特征图（激活值）：卷积层的输出是一组滤波后的图像，称为 “特征图”，也叫该层的 “激活值”，其形式为 3D 数组，第三维度称为 “通道”，可单独可视化（灰度图）或组合可视化（彩色图）</li>\n</ol>\n</li>\n<li>CNN 的实用技巧与数据处理<ol>\n<li>预训练网络的应用：由于深度学习训练耗时久（无 GPU 时难度大），可利用预训练网络提取特征，再结合传统机器学习方法进行分类</li>\n<li>特征提取流程：CNN 在学习图像分类的同时提取有用特征 —— 早期层读取输入图像并提取基础特征，全连接层利用这些特征完成分类；其中，第一个全连接层之前的所有层可作为独立的特征提取网络</li>\n<li>信号数据的图像化：将信号数据（如频谱图）转化为图像形式，输入 CNN 进行特征提取与分类，拓展 CNN 的应用场景</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>循环神经网络（RNN）<ol>\n<li>RNN 的关键类型<ol>\n<li>长短期记忆网络（LSTM）：解决传统 RNN 的长期依赖问题，能处理序列数据，可用于序列分类（如 “喜欢跳舞” 的文本分类）</li>\n<li>双向 LSTM：同时从序列的正向和反向进行学习，提升序列分类的准确性，适用于对上下文依赖较强的任务（如文本标点优化：将 “punctuation is important and need” 优化为 “punctuation important, and”）</li>\n</ol>\n</li>\n<li>RNN 的序列预处理<ol>\n<li>分类序列的数值化：训练 LSTM 需输入数值型序列，若序列为分类类型（如天气序列、DNA 序列（A&#x2F;G&#x2F;T）、音符序列、星期序列（周一至周六）），需先将其转化为数值形式才能进行模型训练</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>网络训练与大数据的关系<ol>\n<li>网络训练的核心要素<ol>\n<li>训练 checklist：成功的网络训练需具备四大要素 ——训练数据（模型学习的基础）、网络架构（模型的结构设计）、算法选项（训练所用的算法）、损失函数（计算模型输出与真实值的总误差，用于优化模型）</li>\n</ol>\n</li>\n<li>AI 与大数据的依存关系<ol>\n<li>数据是 AI 的基础：没有大数据，AI 无法进行有效学习；AI 模型的智能程度与接触的数据量正相关 —— 数据越多，模型能学习到的规律越丰富，智能程度越高</li>\n<li>类比人类学习：AI 模型通过大数据训练，类似人类大脑通过积累大量经验（数据）来学习和提升能力</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"安排及所学\"><a href=\"#安排及所学\" class=\"headerlink\" title=\"安排及所学\"></a>安排及所学</h2><p>为了实现成为全栈AI开发者的终极目标，第一步打算实现极简个人网站<br>HTML、CSS、JavaScript的理解：<br>若拿盖一座房子做比喻：  </p>\n<ol>\n<li>HTML – 房子的结构和内容<ol>\n<li>它负责定义网页上有什么内容</li>\n<li>墙壁和房间： 这是标题，那是段落，这边是一个图片，那边是一个按钮</li>\n<li><code>纯结构： 它不管这些东西好不好看</code>。墙壁就是光秃秃的水泥墙，按钮就是个方框，上面写着字</li>\n</ol>\n</li>\n<li>CSS – 房子的装修和设计<ol>\n<li>它负责定义网页内容看起来是什么样子</li>\n<li>美化： 把标题的文字变成红色、放大；把段落的文字变成某种字体，调整行距；把图片加个圆角边框；把按钮的背景变成蓝色，让鼠标放上去时会变色</li>\n<li>布局： 决定导航栏在顶部，侧边栏在左边，主要内容在中间</li>\n</ol>\n</li>\n<li>JavaScript – 让房子变成智能家居的电路<ol>\n<li>它负责让网页动起来，并能与用户互动</li>\n<li>交互响应：你点击一个按钮，会弹出一个对话框。你把鼠标移到菜单上，菜单会向下展开</li>\n<li>动态改变内容：网站可以自动更新最新的新闻头条。社交媒体页面上，你发布一条新状态，页面会立刻显示出来，而不用你手动刷新整个页面</li>\n<li>进行计算和验证：在购物网站，当你把商品加入购物车时，JavaScript 会立刻计算总价。在填写注册表单时，它会立即检查你的密码是否足够安全，或者邮箱格式是否正确</li>\n<li><code>创建复杂的动画和游戏： 网页上那些复杂的幻灯片轮播、有趣的交互动画，以及所有在浏览器里运行的简单游戏（比如贪吃蛇），几乎都是用 JavaScript 实现的</code></li>\n</ol>\n</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>周末总结</li>\n<li>学习笔记</li>\n<li>后续安排</li>\n</ol>\n<h2 id=\"周末总结\"><a href=\"#周末总结\" class=\"headerlink\" title=\"周末总结\"></a>周末总结</h2><ol>\n<li>骑行探索了一下市区的两个湿地公园，并带摩羯溜了一圈</li>\n<li>在飞盘活动中学习了长传和正手发盘</li>\n<li>训练好了一个英语口语交流AI</li>\n</ol>\n<h2 id=\"学习笔记\"><a href=\"#学习笔记\" class=\"headerlink\" title=\"学习笔记\"></a>学习笔记</h2><h3 id=\"统计\"><a href=\"#统计\" class=\"headerlink\" title=\"统计\"></a>统计</h3><ol>\n<li>人工智能（AI）基础<ol>\n<li>AI 的定义与核心能力<ol>\n<li>定义：AI 即 “人工（人造）” 与 “智能（思考能力）” 的结合，是计算机科学的一个分支，能模拟人类智能并在机器上实现，用于执行原本需要人类智能的任务</li>\n<li>核心功能：包括学习、推理、问题解决和快速决策</li>\n</ol>\n</li>\n<li>AI 的典型应用领域：图像、制造、医疗、互联网、金融、零售、自然语言生成</li>\n</ol>\n</li>\n<li>神经网络（NN）概述<ol>\n<li>神经网络与 AI 的关系<ol>\n<li>核心地位：当前大多数主流 AI 模型均基于神经网络，神经网络是 AI 模拟人类智能的核心技术</li>\n<li>结构灵感：神经网络由相互连接的 “神经元” 构成，灵感来源于生物大脑的神经元连接结构</li>\n<li>基础架构示例：以图像识别鸟类为例，输入层接收图像像素，经隐藏层处理，最终由输出层输出识别结果，各层间通过权重传递信息</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>卷积神经网络（CNN）<ol>\n<li>CNN 的基础：神经元行为<ol>\n<li>神经元输出公式：单个神经元的输出遵循公式 y &#x3D; tanh(w₁x₁ + w₂x₂ + b)，其中 w₁、w₂为输入 x₁、x₂的权重，b 为偏置，tanh 为激活函数（输出范围 - 1 至 1）</li>\n</ol>\n</li>\n<li>卷积层与 CNN 的核心功能<ol>\n<li>卷积层的作用：通过 “滤波器（Filter）” 对输入图像进行处理，提取图像特征，如垂直条纹、水平边缘、对角线边缘、白色斑点、对角线交叉等</li>\n<li>特征图（激活值）：卷积层的输出是一组滤波后的图像，称为 “特征图”，也叫该层的 “激活值”，其形式为 3D 数组，第三维度称为 “通道”，可单独可视化（灰度图）或组合可视化（彩色图）</li>\n</ol>\n</li>\n<li>CNN 的实用技巧与数据处理<ol>\n<li>预训练网络的应用：由于深度学习训练耗时久（无 GPU 时难度大），可利用预训练网络提取特征，再结合传统机器学习方法进行分类</li>\n<li>特征提取流程：CNN 在学习图像分类的同时提取有用特征 —— 早期层读取输入图像并提取基础特征，全连接层利用这些特征完成分类；其中，第一个全连接层之前的所有层可作为独立的特征提取网络</li>\n<li>信号数据的图像化：将信号数据（如频谱图）转化为图像形式，输入 CNN 进行特征提取与分类，拓展 CNN 的应用场景</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>循环神经网络（RNN）<ol>\n<li>RNN 的关键类型<ol>\n<li>长短期记忆网络（LSTM）：解决传统 RNN 的长期依赖问题，能处理序列数据，可用于序列分类（如 “喜欢跳舞” 的文本分类）</li>\n<li>双向 LSTM：同时从序列的正向和反向进行学习，提升序列分类的准确性，适用于对上下文依赖较强的任务（如文本标点优化：将 “punctuation is important and need” 优化为 “punctuation important, and”）</li>\n</ol>\n</li>\n<li>RNN 的序列预处理<ol>\n<li>分类序列的数值化：训练 LSTM 需输入数值型序列，若序列为分类类型（如天气序列、DNA 序列（A&#x2F;G&#x2F;T）、音符序列、星期序列（周一至周六）），需先将其转化为数值形式才能进行模型训练</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>网络训练与大数据的关系<ol>\n<li>网络训练的核心要素<ol>\n<li>训练 checklist：成功的网络训练需具备四大要素 ——训练数据（模型学习的基础）、网络架构（模型的结构设计）、算法选项（训练所用的算法）、损失函数（计算模型输出与真实值的总误差，用于优化模型）</li>\n</ol>\n</li>\n<li>AI 与大数据的依存关系<ol>\n<li>数据是 AI 的基础：没有大数据，AI 无法进行有效学习；AI 模型的智能程度与接触的数据量正相关 —— 数据越多，模型能学习到的规律越丰富，智能程度越高</li>\n<li>类比人类学习：AI 模型通过大数据训练，类似人类大脑通过积累大量经验（数据）来学习和提升能力</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"安排及所学\"><a href=\"#安排及所学\" class=\"headerlink\" title=\"安排及所学\"></a>安排及所学</h2><p>为了实现成为全栈AI开发者的终极目标，第一步打算实现极简个人网站<br>HTML、CSS、JavaScript的理解：<br>若拿盖一座房子做比喻：  </p>\n<ol>\n<li>HTML – 房子的结构和内容<ol>\n<li>它负责定义网页上有什么内容</li>\n<li>墙壁和房间： 这是标题，那是段落，这边是一个图片，那边是一个按钮</li>\n<li><code>纯结构： 它不管这些东西好不好看</code>。墙壁就是光秃秃的水泥墙，按钮就是个方框，上面写着字</li>\n</ol>\n</li>\n<li>CSS – 房子的装修和设计<ol>\n<li>它负责定义网页内容看起来是什么样子</li>\n<li>美化： 把标题的文字变成红色、放大；把段落的文字变成某种字体，调整行距；把图片加个圆角边框；把按钮的背景变成蓝色，让鼠标放上去时会变色</li>\n<li>布局： 决定导航栏在顶部，侧边栏在左边，主要内容在中间</li>\n</ol>\n</li>\n<li>JavaScript – 让房子变成智能家居的电路<ol>\n<li>它负责让网页动起来，并能与用户互动</li>\n<li>交互响应：你点击一个按钮，会弹出一个对话框。你把鼠标移到菜单上，菜单会向下展开</li>\n<li>动态改变内容：网站可以自动更新最新的新闻头条。社交媒体页面上，你发布一条新状态，页面会立刻显示出来，而不用你手动刷新整个页面</li>\n<li>进行计算和验证：在购物网站，当你把商品加入购物车时，JavaScript 会立刻计算总价。在填写注册表单时，它会立即检查你的密码是否足够安全，或者邮箱格式是否正确</li>\n<li><code>创建复杂的动画和游戏： 网页上那些复杂的幻灯片轮播、有趣的交互动画，以及所有在浏览器里运行的简单游戏（比如贪吃蛇），几乎都是用 JavaScript 实现的</code></li>\n</ol>\n</li>\n</ol>\n"},{"title":"2025.11.11","date":"2025-11-11T01:02:33.000Z","_content":"# Overview\n1. 昨日总结\n2. 学习笔记\n3. 今日总结\n\n## 昨日总结\n昨天从早上集合后前往上海参加本周的城市之旅活动，逛了几处没去过的地方，不过最大的收获是从一个来参加的老师那里得知了一个日后会常驻举办的活动——宠物交流活动，以后每周有一次带摩羯出去和别的宠物交流的机会，希望借此机会让它的胆子变大吧，而且希望可以人生同样有爱的主人吧  \n不过可惜的是昨天因为行程安排不妥导致昨天没能赶上晚上的飞盘训练，之后的活动不能再犯同样的错误了\n## 学习笔记\n\n### 计算机体系结构与操作系统\nMIPS 汇编语言入门\n1. 计算机抽象层级与指令基础\n   1. 抽象层级（从高到低）：应用软件→操作系统→架构（程序员视角，定义指令 / 操作数位置）→微架构（硬件实现细节）→逻辑→数字电路→模拟电路→器件→物理\n   2. 指令分类：\n      1. 机器语言：二进制码（如01101010 10101101），计算机可直接识别\n      2. 汇编语言：机器语言的符号表示（如add \\$s0,\\$s1,\\$s2），需汇编器转换\n2. MIPS 架构概述\n   1. 学习价值：作为 RISC 架构代表，掌握后易迁移到其他架构\n   2. 核心特点：\n      1. 32 位架构：操作 32 位数据，含32 个 32 位通用寄存器（速度远快于内存，减少访问延迟）\n      2. load/store 架构：仅通过lw（加载）/sw（存储）指令访问内存，其他指令操作寄存器\n      3. 固定指令长度：所有指令均为 32 位，简化硬件解码\n3. 基础算术与逻辑操作\n   1. 核心指令格式：多数指令为 “目标寄存器，源寄存器 1，源寄存器 2”（如add \\$d, \\$s, \\$t）\n   2. 算术指令：\n      1. add \\$d, \\$s, \\$t：\\$d = \\$s + \\$t\n      2. sub \\$d, \\$s, \\$t：\\$d = \\$s - \\$t\n      3. addi \\$d, \\$s, imm：\\$d = \\$s + imm （add后面的i意味计算里使用了数字）\n   3. 复杂表达式实现：需拆分多指令，如 C 代码a=b+c-d对应：  \n      add \\$t0, \\$s1, \\$s2  # \\$t0 = b + c（临时寄存器存中间结果）  \n      sub \\$s0, \\$t0, \\$s3  # \\$s0 = \\$t0 - d = b + c - d\n4. 内存访问基础\n   1. 内存需求：寄存器仅 32 个，无法存储大量数据，需依赖内存（容量大但速度慢）\n   2. 寻址模式：\n      1. 字寻址：每个 32 位数据（字）对应唯一字地址\n   3. 字节寻址：MIPS 实际采用字节寻址（每个字节 1 个地址），字地址 = 字节地址 ×4（因 1 字 = 4 字节），示例：字 2 的字节地址为 8（2×4）\n   4. 内存操作指令：\n      1. 加载字：lw \\$d, offset\\(\\$base\\) -> d = 内存\\[base + offset]（示例：读取字节地址4的字到s3，指令lw \\$s3,4\\(\\$0)）\n      2. 存储字：sw \\$s, offset\\(\\$base\\) -> s = 内存\\[base + offset]()（示例：将t4存入字节地址7，指令sw \\$t4,0x7\\(\\$0)）\n      3. 加载字节（lb）/ 存储字节（sb）：操作单个字节数据  \n\n逻辑指令、移位、数组与函数调用\n1. 逻辑指令\n   1. 核心指令（操作寄存器或立即数）：\n      1. and \\$d, \\$s, \\$t：\\$d = \\$s & \\$t （用于位掩码，如保留低 8 位：0xF234012F & 0x000000FF = 0x0000002F）\n      2. or \\$d, \\$s, \\$t：\\$d = \\$s | \\$t  （用于组合位域，如0xF2340000 | 0x000012BC = 0xF23412BC）\n      3. xor \\$d, \\$s, \\$t：\\$d = \\$s ^ \\$t （位异或）\n      4. nor \\$d, \\$s, \\$t：d= \\(s | $t)  （位或非，用于取反：A nor 0 = ~A）\n      5. 立即数逻辑指令：andi、ori、xori（16 位立即数零扩展，无nori）\n2. 移位指令\n   1. 指令类型（移位量可为立即数或寄存器）：\n      1. sll \\$d, \\$s, shamt：逻辑左移 → \\$d = \\$s << shamt（高位补 0，示例：sll \\$t0,\\$t1,5 → t0=t1 左移 5 位）\n      2. srl \\$d, \\$s, shamt：逻辑右移 → \\$d = \\$s >> shamt（低位补 0）\n      3. sra \\$d, \\$s, shamt：算术右移 → \\$d = \\$s >>> shamt（高位补符号位，用于有符号数）\n   2. 应用：左移 1 位等价于 ×2，左移 3 位等价于 ×8（如 C 代码a=2*b对应sll \\$t0,\\$s1,1）\n3. 常量生成与乘除操作\n   1. 32 位常量生成：MIPS 立即数仅 16 位，需组合lui（加载高位立即数）和ori：\n      1. 示例：C 代码int a=0xFEDC8765对应：  \n         lui \\$s0, 0xFEDC  # \\$s0 = 0xFEDC0000（加载高16位）\n         ori \\$s0, $s0, 0x8765  # \\$s0 = 0xFEDC0000 | 0x8765 = 0xFEDC8765\n   2. 乘除操作：依赖专用寄存器hi（高位结果）和lo（低位结果）：\n      1. 乘法：mult \\$s, \\$t → 结果（64 位）存入 {hi, lo}，需mfhi \\$d（读取 hi）、mflo $d（读取 lo）\n      2. 除法：div \\$s, \\$t → 商存入 lo，余数存入 hi，同样通过mfhi/mflo读取\n4. 数组操作\n   1. 数组存储：数组元素连续存储，基地址为首个元素地址（如 5 元素数组 base=0x12348000，元素地址为 base、base+4、base+8 等）\n   2. 单元素操作示例：  \n      C 代码：\n      ```c\n      array[0] *=2; array[1] *=2(base=0x12348000)\n      ```\n      汇编代码：\n      ```asm\n      lui $s0, 0x1234       # $s0 = 0x12340000\n      ori $s0, $s0, 0x8000  # $s0 = 0x12348000(数组基地址)\n      \n      lw $t1, 0($s0)     # $t1 = array[0]\n      sll $t1, $t1, 1    # $t1 = array[0] * 2\n      sw $t1, 0($s0)     # array[0] = $t1\n      \n      lw $t1, 4($s0)     # $t1 = array[1]\n      sll $t1, $t1, 1    # $t1 = array[1] * 2\n      sw $t1, 4($s0)     # array[1] = $t1\n      ```\n   3. for 循环操作数组：  \n      C 代码：\n      ```c\n      for(i=0;i<1000;i++) array[i] *=8\n      ```\n      汇编代码：\n      ```asm\n      # 初始化：$s0=数组基址(0x23B8F000),$s1=i=0,$t2=1000\n      lui $s0, 0x23B8\n      ori $s0, $s0, 0xF000      \n      addi $s1, $0, 0\n      addi $t2, $0, 1000\n      \n      loop:\n      slt $t0, $s1, $t2  # $t0=1(i<1000)，否则0\n      beq $t0, $0, done  # 若i>=1000，跳至done\n      sll $t0, $s1, 2    # $t0 = i*4(字节偏移)\n      add $t0, $t0, $s0  # $t0 = array[i]地址\n      lw $t1, 0($t0)     # $t1 = array[i]\n      sll $t1, $t1, 3    # $t1 = array[i] *8(左移3位)\n      sw $t1, 0($t0)     # array[i] = $t1\n      addi $s1, $s1, 1   # i = i+1\n      j loop             # 跳回loop\n      \n      done:\n      ```\n5. 函数调用机制\n   1. 核心概念：\n      1. 调用者（Caller）：发起调用的函数（如 main）\n      2. 被调用者（Callee）：被调用的函数（如 sum）\n   2. `MIPS 函数调用约定`：\n      1. 传参：前 4 个参数通过a0−a3 传递，超过 4 个需用栈\n      2. 返回值：通过v0−v1 返回\n      3. 跳转与返回：jal（jump and link）指令跳转（同时将返回地址存入$ra），jr $ra（jump register）指令返回\n   3. 简单函数示例：  \n      C 代码：\n      ```c\n      void main(){simple(); a=b+c;} void simple(){return;}\n      ```  \n      汇编代码：\n      ```asm\n      0x00400200 main: jal simple  # 跳至simple,$ra=0x00400204(下一条指令地址)\n      0x00400204      add $s0, $s1, $s2  # a=b+c\n      ...\n      0x00401020 simple: jr $ra  # 跳回$ra(0x00400204)\n      ```\n6. 分支、循环、栈内存与寻址方式\n   1. 条件标志（CPSR 寄存器）：  \n      | 标志位 | 名称 | 含义 |\n      | :---: | :---: | :---: |\n      | N | Negative（负） | 指令结果为负（结果第 31 位为 1） |\n      | Z | Zero（零） | 指令结果为 0 |\n      | C | Carry（进位） | 指令执行产生进位 / 借位 |\n      | V | Overflow（溢出） | 指令执行产生溢出 |\n   2. 分支指令（流程跳转）：用于 “打破顺序执行”，分为条件分支（满足条件才跳）和无条件分支（强制跳），依赖 CPSR 寄存器的标志位（N/Z/C/V）判断条件，核心分支指令如下：\n      | 指令类型 | 指令 | 格式 | 功能 | 示例 |\n      | :---: | :---: | :---: | :---: | :---: |\n      | 条件分支\t| beq | beq $s, $t, label | 若$s == $t，跳 label | beq $s0, $s1, target（s0==s1 跳 target） | \n      | | bne |\tbne $s, $t, label | 若$s != $t，跳 label | bne $s0, $s1, target（s0!=s1 跳 target） |\n      | 无条件分支 | j | j label | 强制跳 label（直接使用地址） | j target（跳 target） |\n      | | jr | jr $s | 强制跳 $s 存储的地址（寄存器间接跳转） | jr $ra（跳 $ra 地址，函数返回） |\n      | | jal | jal label | 跳 label，并将返回地址存入 $ra | jal sum（调用 sum，保存返回地址） |\n   3. 循环与条件语句（if/while/for）\n      1. MIPS 通过 “分支指令 + 跳转指令” 实现高级语言的条件与循环逻辑，核心是 “判断条件→跳转到对应代码块”\n      2. if 语句示例    \n         C 代码：\n         ```c\n         if(i == j) f = g + h; f = f - i;(s0=f,s1=g,s2=h,s3=i,$s4=j)\n         ```  \n         汇编代码：\n         ```asm\n         bne $s3, $s4, L1   # 若i!=j,跳L1(跳过if体)\n         add $s0, $s1, $s2  # if体:f = g + h(i==j时执行)\n         L1:\n         sub $s0, $s0, $s3  # 无论if是否执行,都执行f = f - i\n         ```\n      3. if-else 语句示例  \n         C 代码：\n         ```c\n         if(i == j) f = g + h; else f = f - i;\n         ```  \n         汇编代码：\n         ```asm\n         bne $s3, $s4, L1   # 若i!=j,跳L1(执行else)\n         add $s0, $s1, $s2  # if体:f = g + h\n         j done             # 跳done,跳过else\n         L1:\n         sub $s0, $s0, $s3  # else体:f = f -i\n         done:\n         ```\n      4. while 循环示例  \n         C 代码：\n         ```c\n         int pow=1, x=0; while(pow!=128) { pow*=2; x++; }  (s0=pow,s1=x)\n         ```  \n         汇编代码：\n         ```asm\n         addi $s0, $0, 1    # pow=1\n         add $s1, $0, $0    # x=0\n         addi $t0, $0, 128  # $t0=128 (循环终止条件)\n         while:\n         beq $s0, $t0, done # 若pow==128,跳done (终止循环)\n         sll $s0, $s0, 1    # pow = pow*2  (左移1位)\n         addi $s1, $s1, 1   # x = x+1\n         j while            # 跳回while,继续循环\n         done:\n         ```\n      5. for 循环示例  \n         C 代码：\n         ```c\n         int sum=0, i; for(i=0; i!=10; i++) sum +=i; (s0=i,s1=sum)\n         ```  \n         汇编代码：\n         ```asm\n         addi $s1, $0, 0    # sum=0\n         add $s0, $0, $0    # i=0\n         addi $t0, $0, 10   # $t0=10 (循环终止条件)\n         for:\n         beq $s0, $t0, done # 若i==10，跳done (终止循环)\n         add $s1, $s1, $s0  # sum = sum +i\n         addi $s0, $s0, 1   # i = i+1\n         j for              # 跳回for,继续循环\n         done:\n         ```\n   4. 栈内存深度应用（多函数嵌套与递归）\n      1. 栈的核心特性是 “LIFO（后进先出）”，生长方向为 “高地址→低地址”，$sp始终指向栈顶，主要用于：\n         1. 保存被调用者需保留的寄存器（s0−s7、$ra）\n         2. 传递超过 4 个的函数参数\n         3. 存储递归函数的中间变量\n      2. 多函数嵌套（保存 $ra）  \n         若函数 A 调用函数 B，函数 B 再调用函数 C，jal B会覆盖$ra中 A 的返回地址，因此 B 需先将$ra压栈，再调用 C，示例：\n         ```\n         proc1: # 函数A: 调用proc2\n         addi $sp, $sp, -4  # 栈扩容4字节(存$ra)\n         sw $ra, 0($sp)     # 保存proc1的返回地址到栈\n         jal proc2          # 调用proc2,$ra被更新为proc1中jal后的地址\n         lw $ra, 0($sp)     # 恢复proc1的返回地址\n         addi $sp, $sp, 4   # 栈缩容4字节\n         jr $ra             # 返回proc1的调用者\n\n         proc2: # 函数B: 被proc1调用\n         jr $ra             # 返回proc1 ($ra存储proc1中jal后的地址)\n         ```\n      3. 递归函数示例（阶乘）  \n         C 代码：\n         ```c\n         int factorial(int n) { return n==1 ? 1 : n*factorial(n-1); }\n         ```  \n         汇编代码（$a0=n，$v0= 返回值）：\n         ```asm\n         .data\n         n: .word 5  # 计算5的阶乘\n\n         .text\n         .globl main\n         main:\n         lw $a0, n          # $a0 = 5 (传入factorial的参数)\n         jal factorial      # 调用factorial\n         # 打印结果\n         li $v0, 1          # 系统调用1:打印整数\n         move $a0, $v0      # $a0 = 阶乘结果 (factorial的返回值)\n         syscall\n         # 退出程序\n         li $v0, 10         # 系统调用10: 退出\n         syscall\n         \n         factorial:\n         # 1. 栈扩容8字节 (存$ra和$a0,递归需保存n)\n         addi $sp, $sp, -8\n         sw $ra, 4($sp)     # 保存当前返回地址到栈偏移4\n         sw $a0, 0($sp)     # 保存当前n到栈偏移0\n         \n         # 2. 递归终止条件: n==1\n         li $v0, 1          # $v0=1 (终止条件返回值)\n         beq $a0, $v0, base_case # 若n==1,跳base_case\n\n         # 3. 递归调用: factorial(n-1)\n         addi $a0, $a0, -1  # $a0 = n-1\n         jal factorial      # 调用factorial(n-1),$ra更新为当前jal后的地址\n\n         # 4. 计算n * factorial(n-1)\n         lw $a0, 0($sp)     # 恢复当前n (从栈中取)\n         mul $v0, $a0, $v0  # $v0 = n * factorial(n-1) (返回值)\n\n         # 5. 恢复寄存器+栈缩容\n         base_case:\n         lw $ra, 4($sp)     # 恢复返回地址\n         addi $sp, $sp, 8   # 栈缩容8字节\n         jr $ra             # 返回调用者\n         ```\n\n## 今日总结\n1. 今天速学了html和css的一些基础知识\n","source":"_posts/2025-11-11.md","raw":"---\ntitle: 2025.11.11\ndate: 2025-11-11 09:02:33\ntags:\n---\n# Overview\n1. 昨日总结\n2. 学习笔记\n3. 今日总结\n\n## 昨日总结\n昨天从早上集合后前往上海参加本周的城市之旅活动，逛了几处没去过的地方，不过最大的收获是从一个来参加的老师那里得知了一个日后会常驻举办的活动——宠物交流活动，以后每周有一次带摩羯出去和别的宠物交流的机会，希望借此机会让它的胆子变大吧，而且希望可以人生同样有爱的主人吧  \n不过可惜的是昨天因为行程安排不妥导致昨天没能赶上晚上的飞盘训练，之后的活动不能再犯同样的错误了\n## 学习笔记\n\n### 计算机体系结构与操作系统\nMIPS 汇编语言入门\n1. 计算机抽象层级与指令基础\n   1. 抽象层级（从高到低）：应用软件→操作系统→架构（程序员视角，定义指令 / 操作数位置）→微架构（硬件实现细节）→逻辑→数字电路→模拟电路→器件→物理\n   2. 指令分类：\n      1. 机器语言：二进制码（如01101010 10101101），计算机可直接识别\n      2. 汇编语言：机器语言的符号表示（如add \\$s0,\\$s1,\\$s2），需汇编器转换\n2. MIPS 架构概述\n   1. 学习价值：作为 RISC 架构代表，掌握后易迁移到其他架构\n   2. 核心特点：\n      1. 32 位架构：操作 32 位数据，含32 个 32 位通用寄存器（速度远快于内存，减少访问延迟）\n      2. load/store 架构：仅通过lw（加载）/sw（存储）指令访问内存，其他指令操作寄存器\n      3. 固定指令长度：所有指令均为 32 位，简化硬件解码\n3. 基础算术与逻辑操作\n   1. 核心指令格式：多数指令为 “目标寄存器，源寄存器 1，源寄存器 2”（如add \\$d, \\$s, \\$t）\n   2. 算术指令：\n      1. add \\$d, \\$s, \\$t：\\$d = \\$s + \\$t\n      2. sub \\$d, \\$s, \\$t：\\$d = \\$s - \\$t\n      3. addi \\$d, \\$s, imm：\\$d = \\$s + imm （add后面的i意味计算里使用了数字）\n   3. 复杂表达式实现：需拆分多指令，如 C 代码a=b+c-d对应：  \n      add \\$t0, \\$s1, \\$s2  # \\$t0 = b + c（临时寄存器存中间结果）  \n      sub \\$s0, \\$t0, \\$s3  # \\$s0 = \\$t0 - d = b + c - d\n4. 内存访问基础\n   1. 内存需求：寄存器仅 32 个，无法存储大量数据，需依赖内存（容量大但速度慢）\n   2. 寻址模式：\n      1. 字寻址：每个 32 位数据（字）对应唯一字地址\n   3. 字节寻址：MIPS 实际采用字节寻址（每个字节 1 个地址），字地址 = 字节地址 ×4（因 1 字 = 4 字节），示例：字 2 的字节地址为 8（2×4）\n   4. 内存操作指令：\n      1. 加载字：lw \\$d, offset\\(\\$base\\) -> d = 内存\\[base + offset]（示例：读取字节地址4的字到s3，指令lw \\$s3,4\\(\\$0)）\n      2. 存储字：sw \\$s, offset\\(\\$base\\) -> s = 内存\\[base + offset]()（示例：将t4存入字节地址7，指令sw \\$t4,0x7\\(\\$0)）\n      3. 加载字节（lb）/ 存储字节（sb）：操作单个字节数据  \n\n逻辑指令、移位、数组与函数调用\n1. 逻辑指令\n   1. 核心指令（操作寄存器或立即数）：\n      1. and \\$d, \\$s, \\$t：\\$d = \\$s & \\$t （用于位掩码，如保留低 8 位：0xF234012F & 0x000000FF = 0x0000002F）\n      2. or \\$d, \\$s, \\$t：\\$d = \\$s | \\$t  （用于组合位域，如0xF2340000 | 0x000012BC = 0xF23412BC）\n      3. xor \\$d, \\$s, \\$t：\\$d = \\$s ^ \\$t （位异或）\n      4. nor \\$d, \\$s, \\$t：d= \\(s | $t)  （位或非，用于取反：A nor 0 = ~A）\n      5. 立即数逻辑指令：andi、ori、xori（16 位立即数零扩展，无nori）\n2. 移位指令\n   1. 指令类型（移位量可为立即数或寄存器）：\n      1. sll \\$d, \\$s, shamt：逻辑左移 → \\$d = \\$s << shamt（高位补 0，示例：sll \\$t0,\\$t1,5 → t0=t1 左移 5 位）\n      2. srl \\$d, \\$s, shamt：逻辑右移 → \\$d = \\$s >> shamt（低位补 0）\n      3. sra \\$d, \\$s, shamt：算术右移 → \\$d = \\$s >>> shamt（高位补符号位，用于有符号数）\n   2. 应用：左移 1 位等价于 ×2，左移 3 位等价于 ×8（如 C 代码a=2*b对应sll \\$t0,\\$s1,1）\n3. 常量生成与乘除操作\n   1. 32 位常量生成：MIPS 立即数仅 16 位，需组合lui（加载高位立即数）和ori：\n      1. 示例：C 代码int a=0xFEDC8765对应：  \n         lui \\$s0, 0xFEDC  # \\$s0 = 0xFEDC0000（加载高16位）\n         ori \\$s0, $s0, 0x8765  # \\$s0 = 0xFEDC0000 | 0x8765 = 0xFEDC8765\n   2. 乘除操作：依赖专用寄存器hi（高位结果）和lo（低位结果）：\n      1. 乘法：mult \\$s, \\$t → 结果（64 位）存入 {hi, lo}，需mfhi \\$d（读取 hi）、mflo $d（读取 lo）\n      2. 除法：div \\$s, \\$t → 商存入 lo，余数存入 hi，同样通过mfhi/mflo读取\n4. 数组操作\n   1. 数组存储：数组元素连续存储，基地址为首个元素地址（如 5 元素数组 base=0x12348000，元素地址为 base、base+4、base+8 等）\n   2. 单元素操作示例：  \n      C 代码：\n      ```c\n      array[0] *=2; array[1] *=2(base=0x12348000)\n      ```\n      汇编代码：\n      ```asm\n      lui $s0, 0x1234       # $s0 = 0x12340000\n      ori $s0, $s0, 0x8000  # $s0 = 0x12348000(数组基地址)\n      \n      lw $t1, 0($s0)     # $t1 = array[0]\n      sll $t1, $t1, 1    # $t1 = array[0] * 2\n      sw $t1, 0($s0)     # array[0] = $t1\n      \n      lw $t1, 4($s0)     # $t1 = array[1]\n      sll $t1, $t1, 1    # $t1 = array[1] * 2\n      sw $t1, 4($s0)     # array[1] = $t1\n      ```\n   3. for 循环操作数组：  \n      C 代码：\n      ```c\n      for(i=0;i<1000;i++) array[i] *=8\n      ```\n      汇编代码：\n      ```asm\n      # 初始化：$s0=数组基址(0x23B8F000),$s1=i=0,$t2=1000\n      lui $s0, 0x23B8\n      ori $s0, $s0, 0xF000      \n      addi $s1, $0, 0\n      addi $t2, $0, 1000\n      \n      loop:\n      slt $t0, $s1, $t2  # $t0=1(i<1000)，否则0\n      beq $t0, $0, done  # 若i>=1000，跳至done\n      sll $t0, $s1, 2    # $t0 = i*4(字节偏移)\n      add $t0, $t0, $s0  # $t0 = array[i]地址\n      lw $t1, 0($t0)     # $t1 = array[i]\n      sll $t1, $t1, 3    # $t1 = array[i] *8(左移3位)\n      sw $t1, 0($t0)     # array[i] = $t1\n      addi $s1, $s1, 1   # i = i+1\n      j loop             # 跳回loop\n      \n      done:\n      ```\n5. 函数调用机制\n   1. 核心概念：\n      1. 调用者（Caller）：发起调用的函数（如 main）\n      2. 被调用者（Callee）：被调用的函数（如 sum）\n   2. `MIPS 函数调用约定`：\n      1. 传参：前 4 个参数通过a0−a3 传递，超过 4 个需用栈\n      2. 返回值：通过v0−v1 返回\n      3. 跳转与返回：jal（jump and link）指令跳转（同时将返回地址存入$ra），jr $ra（jump register）指令返回\n   3. 简单函数示例：  \n      C 代码：\n      ```c\n      void main(){simple(); a=b+c;} void simple(){return;}\n      ```  \n      汇编代码：\n      ```asm\n      0x00400200 main: jal simple  # 跳至simple,$ra=0x00400204(下一条指令地址)\n      0x00400204      add $s0, $s1, $s2  # a=b+c\n      ...\n      0x00401020 simple: jr $ra  # 跳回$ra(0x00400204)\n      ```\n6. 分支、循环、栈内存与寻址方式\n   1. 条件标志（CPSR 寄存器）：  \n      | 标志位 | 名称 | 含义 |\n      | :---: | :---: | :---: |\n      | N | Negative（负） | 指令结果为负（结果第 31 位为 1） |\n      | Z | Zero（零） | 指令结果为 0 |\n      | C | Carry（进位） | 指令执行产生进位 / 借位 |\n      | V | Overflow（溢出） | 指令执行产生溢出 |\n   2. 分支指令（流程跳转）：用于 “打破顺序执行”，分为条件分支（满足条件才跳）和无条件分支（强制跳），依赖 CPSR 寄存器的标志位（N/Z/C/V）判断条件，核心分支指令如下：\n      | 指令类型 | 指令 | 格式 | 功能 | 示例 |\n      | :---: | :---: | :---: | :---: | :---: |\n      | 条件分支\t| beq | beq $s, $t, label | 若$s == $t，跳 label | beq $s0, $s1, target（s0==s1 跳 target） | \n      | | bne |\tbne $s, $t, label | 若$s != $t，跳 label | bne $s0, $s1, target（s0!=s1 跳 target） |\n      | 无条件分支 | j | j label | 强制跳 label（直接使用地址） | j target（跳 target） |\n      | | jr | jr $s | 强制跳 $s 存储的地址（寄存器间接跳转） | jr $ra（跳 $ra 地址，函数返回） |\n      | | jal | jal label | 跳 label，并将返回地址存入 $ra | jal sum（调用 sum，保存返回地址） |\n   3. 循环与条件语句（if/while/for）\n      1. MIPS 通过 “分支指令 + 跳转指令” 实现高级语言的条件与循环逻辑，核心是 “判断条件→跳转到对应代码块”\n      2. if 语句示例    \n         C 代码：\n         ```c\n         if(i == j) f = g + h; f = f - i;(s0=f,s1=g,s2=h,s3=i,$s4=j)\n         ```  \n         汇编代码：\n         ```asm\n         bne $s3, $s4, L1   # 若i!=j,跳L1(跳过if体)\n         add $s0, $s1, $s2  # if体:f = g + h(i==j时执行)\n         L1:\n         sub $s0, $s0, $s3  # 无论if是否执行,都执行f = f - i\n         ```\n      3. if-else 语句示例  \n         C 代码：\n         ```c\n         if(i == j) f = g + h; else f = f - i;\n         ```  \n         汇编代码：\n         ```asm\n         bne $s3, $s4, L1   # 若i!=j,跳L1(执行else)\n         add $s0, $s1, $s2  # if体:f = g + h\n         j done             # 跳done,跳过else\n         L1:\n         sub $s0, $s0, $s3  # else体:f = f -i\n         done:\n         ```\n      4. while 循环示例  \n         C 代码：\n         ```c\n         int pow=1, x=0; while(pow!=128) { pow*=2; x++; }  (s0=pow,s1=x)\n         ```  \n         汇编代码：\n         ```asm\n         addi $s0, $0, 1    # pow=1\n         add $s1, $0, $0    # x=0\n         addi $t0, $0, 128  # $t0=128 (循环终止条件)\n         while:\n         beq $s0, $t0, done # 若pow==128,跳done (终止循环)\n         sll $s0, $s0, 1    # pow = pow*2  (左移1位)\n         addi $s1, $s1, 1   # x = x+1\n         j while            # 跳回while,继续循环\n         done:\n         ```\n      5. for 循环示例  \n         C 代码：\n         ```c\n         int sum=0, i; for(i=0; i!=10; i++) sum +=i; (s0=i,s1=sum)\n         ```  \n         汇编代码：\n         ```asm\n         addi $s1, $0, 0    # sum=0\n         add $s0, $0, $0    # i=0\n         addi $t0, $0, 10   # $t0=10 (循环终止条件)\n         for:\n         beq $s0, $t0, done # 若i==10，跳done (终止循环)\n         add $s1, $s1, $s0  # sum = sum +i\n         addi $s0, $s0, 1   # i = i+1\n         j for              # 跳回for,继续循环\n         done:\n         ```\n   4. 栈内存深度应用（多函数嵌套与递归）\n      1. 栈的核心特性是 “LIFO（后进先出）”，生长方向为 “高地址→低地址”，$sp始终指向栈顶，主要用于：\n         1. 保存被调用者需保留的寄存器（s0−s7、$ra）\n         2. 传递超过 4 个的函数参数\n         3. 存储递归函数的中间变量\n      2. 多函数嵌套（保存 $ra）  \n         若函数 A 调用函数 B，函数 B 再调用函数 C，jal B会覆盖$ra中 A 的返回地址，因此 B 需先将$ra压栈，再调用 C，示例：\n         ```\n         proc1: # 函数A: 调用proc2\n         addi $sp, $sp, -4  # 栈扩容4字节(存$ra)\n         sw $ra, 0($sp)     # 保存proc1的返回地址到栈\n         jal proc2          # 调用proc2,$ra被更新为proc1中jal后的地址\n         lw $ra, 0($sp)     # 恢复proc1的返回地址\n         addi $sp, $sp, 4   # 栈缩容4字节\n         jr $ra             # 返回proc1的调用者\n\n         proc2: # 函数B: 被proc1调用\n         jr $ra             # 返回proc1 ($ra存储proc1中jal后的地址)\n         ```\n      3. 递归函数示例（阶乘）  \n         C 代码：\n         ```c\n         int factorial(int n) { return n==1 ? 1 : n*factorial(n-1); }\n         ```  \n         汇编代码（$a0=n，$v0= 返回值）：\n         ```asm\n         .data\n         n: .word 5  # 计算5的阶乘\n\n         .text\n         .globl main\n         main:\n         lw $a0, n          # $a0 = 5 (传入factorial的参数)\n         jal factorial      # 调用factorial\n         # 打印结果\n         li $v0, 1          # 系统调用1:打印整数\n         move $a0, $v0      # $a0 = 阶乘结果 (factorial的返回值)\n         syscall\n         # 退出程序\n         li $v0, 10         # 系统调用10: 退出\n         syscall\n         \n         factorial:\n         # 1. 栈扩容8字节 (存$ra和$a0,递归需保存n)\n         addi $sp, $sp, -8\n         sw $ra, 4($sp)     # 保存当前返回地址到栈偏移4\n         sw $a0, 0($sp)     # 保存当前n到栈偏移0\n         \n         # 2. 递归终止条件: n==1\n         li $v0, 1          # $v0=1 (终止条件返回值)\n         beq $a0, $v0, base_case # 若n==1,跳base_case\n\n         # 3. 递归调用: factorial(n-1)\n         addi $a0, $a0, -1  # $a0 = n-1\n         jal factorial      # 调用factorial(n-1),$ra更新为当前jal后的地址\n\n         # 4. 计算n * factorial(n-1)\n         lw $a0, 0($sp)     # 恢复当前n (从栈中取)\n         mul $v0, $a0, $v0  # $v0 = n * factorial(n-1) (返回值)\n\n         # 5. 恢复寄存器+栈缩容\n         base_case:\n         lw $ra, 4($sp)     # 恢复返回地址\n         addi $sp, $sp, 8   # 栈缩容8字节\n         jr $ra             # 返回调用者\n         ```\n\n## 今日总结\n1. 今天速学了html和css的一些基础知识\n","slug":"2025-11-11","published":1,"updated":"2025-11-18T19:39:17.107Z","comments":1,"layout":"post","photos":[],"_id":"cuidhTNoNA194uAIWwNryrvMv","content":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>昨日总结</li>\n<li>学习笔记</li>\n<li>今日总结</li>\n</ol>\n<h2 id=\"昨日总结\"><a href=\"#昨日总结\" class=\"headerlink\" title=\"昨日总结\"></a>昨日总结</h2><p>昨天从早上集合后前往上海参加本周的城市之旅活动，逛了几处没去过的地方，不过最大的收获是从一个来参加的老师那里得知了一个日后会常驻举办的活动——宠物交流活动，以后每周有一次带摩羯出去和别的宠物交流的机会，希望借此机会让它的胆子变大吧，而且希望可以人生同样有爱的主人吧<br>不过可惜的是昨天因为行程安排不妥导致昨天没能赶上晚上的飞盘训练，之后的活动不能再犯同样的错误了</p>\n<h2 id=\"学习笔记\"><a href=\"#学习笔记\" class=\"headerlink\" title=\"学习笔记\"></a>学习笔记</h2><h3 id=\"计算机体系结构与操作系统\"><a href=\"#计算机体系结构与操作系统\" class=\"headerlink\" title=\"计算机体系结构与操作系统\"></a>计算机体系结构与操作系统</h3><p>MIPS 汇编语言入门</p>\n<ol>\n<li>计算机抽象层级与指令基础<ol>\n<li>抽象层级（从高到低）：应用软件→操作系统→架构（程序员视角，定义指令 &#x2F; 操作数位置）→微架构（硬件实现细节）→逻辑→数字电路→模拟电路→器件→物理</li>\n<li>指令分类：<ol>\n<li>机器语言：二进制码（如01101010 10101101），计算机可直接识别</li>\n<li>汇编语言：机器语言的符号表示（如add $s0,$s1,$s2），需汇编器转换</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>MIPS 架构概述<ol>\n<li>学习价值：作为 RISC 架构代表，掌握后易迁移到其他架构</li>\n<li>核心特点：<ol>\n<li>32 位架构：操作 32 位数据，含32 个 32 位通用寄存器（速度远快于内存，减少访问延迟）</li>\n<li>load&#x2F;store 架构：仅通过lw（加载）&#x2F;sw（存储）指令访问内存，其他指令操作寄存器</li>\n<li>固定指令长度：所有指令均为 32 位，简化硬件解码</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>基础算术与逻辑操作<ol>\n<li>核心指令格式：多数指令为 “目标寄存器，源寄存器 1，源寄存器 2”（如add $d, $s, $t）</li>\n<li>算术指令：<ol>\n<li>add $d, $s, $t：$d &#x3D; $s + $t</li>\n<li>sub $d, $s, $t：$d &#x3D; $s - $t</li>\n<li>addi $d, $s, imm：$d &#x3D; $s + imm （add后面的i意味计算里使用了数字）</li>\n</ol>\n</li>\n<li>复杂表达式实现：需拆分多指令，如 C 代码a&#x3D;b+c-d对应：<br>add $t0, $s1, $s2  # $t0 &#x3D; b + c（临时寄存器存中间结果）<br>sub $s0, $t0, $s3  # $s0 &#x3D; $t0 - d &#x3D; b + c - d</li>\n</ol>\n</li>\n<li>内存访问基础<ol>\n<li>内存需求：寄存器仅 32 个，无法存储大量数据，需依赖内存（容量大但速度慢）</li>\n<li>寻址模式：<ol>\n<li>字寻址：每个 32 位数据（字）对应唯一字地址</li>\n</ol>\n</li>\n<li>字节寻址：MIPS 实际采用字节寻址（每个字节 1 个地址），字地址 &#x3D; 字节地址 ×4（因 1 字 &#x3D; 4 字节），示例：字 2 的字节地址为 8（2×4）</li>\n<li>内存操作指令：<ol>\n<li>加载字：lw $d, offset($base) -&gt; d &#x3D; 内存[base + offset]（示例：读取字节地址4的字到s3，指令lw $s3,4($0)）</li>\n<li>存储字：sw $s, offset($base) -&gt; s &#x3D; 内存[base + offset]()（示例：将t4存入字节地址7，指令sw $t4,0x7($0)）</li>\n<li>加载字节（lb）&#x2F; 存储字节（sb）：操作单个字节数据</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<p>逻辑指令、移位、数组与函数调用</p>\n<ol>\n<li>逻辑指令<ol>\n<li>核心指令（操作寄存器或立即数）：<ol>\n<li>and $d, $s, $t：$d &#x3D; $s &amp; $t （用于位掩码，如保留低 8 位：0xF234012F &amp; 0x000000FF &#x3D; 0x0000002F）</li>\n<li>or $d, $s, $t：$d &#x3D; $s | $t  （用于组合位域，如0xF2340000 | 0x000012BC &#x3D; 0xF23412BC）</li>\n<li>xor $d, $s, $t：$d &#x3D; $s ^ $t （位异或）</li>\n<li>nor $d, $s, $t：d&#x3D; (s | $t)  （位或非，用于取反：A nor 0 &#x3D; ~A）</li>\n<li>立即数逻辑指令：andi、ori、xori（16 位立即数零扩展，无nori）</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>移位指令<ol>\n<li>指令类型（移位量可为立即数或寄存器）：<ol>\n<li>sll $d, $s, shamt：逻辑左移 → $d &#x3D; $s &lt;&lt; shamt（高位补 0，示例：sll $t0,$t1,5 → t0&#x3D;t1 左移 5 位）</li>\n<li>srl $d, $s, shamt：逻辑右移 → $d &#x3D; $s &gt;&gt; shamt（低位补 0）</li>\n<li>sra $d, $s, shamt：算术右移 → $d &#x3D; $s &gt;&gt;&gt; shamt（高位补符号位，用于有符号数）</li>\n</ol>\n</li>\n<li>应用：左移 1 位等价于 ×2，左移 3 位等价于 ×8（如 C 代码a&#x3D;2*b对应sll $t0,$s1,1）</li>\n</ol>\n</li>\n<li>常量生成与乘除操作<ol>\n<li>32 位常量生成：MIPS 立即数仅 16 位，需组合lui（加载高位立即数）和ori：<ol>\n<li>示例：C 代码int a&#x3D;0xFEDC8765对应：<br>lui $s0, 0xFEDC  # $s0 &#x3D; 0xFEDC0000（加载高16位）<br>ori $s0, $s0, 0x8765  # $s0 &#x3D; 0xFEDC0000 | 0x8765 &#x3D; 0xFEDC8765</li>\n</ol>\n</li>\n<li>乘除操作：依赖专用寄存器hi（高位结果）和lo（低位结果）：<ol>\n<li>乘法：mult $s, $t → 结果（64 位）存入 {hi, lo}，需mfhi $d（读取 hi）、mflo $d（读取 lo）</li>\n<li>除法：div $s, $t → 商存入 lo，余数存入 hi，同样通过mfhi&#x2F;mflo读取</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>数组操作<ol>\n<li>数组存储：数组元素连续存储，基地址为首个元素地址（如 5 元素数组 base&#x3D;0x12348000，元素地址为 base、base+4、base+8 等）</li>\n<li>单元素操作示例：<br>C 代码：<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">array</span>[<span class=\"number\">0</span>] *=<span class=\"number\">2</span>; <span class=\"built_in\">array</span>[<span class=\"number\">1</span>] *=<span class=\"number\">2</span>(base=<span class=\"number\">0x12348000</span>)</span><br></pre></td></tr></table></figure>\n汇编代码：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lui $s0, 0x1234       # $s0 = 0x12340000</span><br><span class=\"line\">ori $s0, $s0, 0x8000  # $s0 = 0x12348000(数组基地址)</span><br><span class=\"line\"></span><br><span class=\"line\">lw $t1, 0($s0)     # $t1 = array[0]</span><br><span class=\"line\">sll $t1, $t1, 1    # $t1 = array[0] * 2</span><br><span class=\"line\">sw $t1, 0($s0)     # array[0] = $t1</span><br><span class=\"line\"></span><br><span class=\"line\">lw $t1, 4($s0)     # $t1 = array[1]</span><br><span class=\"line\">sll $t1, $t1, 1    # $t1 = array[1] * 2</span><br><span class=\"line\">sw $t1, 4($s0)     # array[1] = $t1</span><br></pre></td></tr></table></figure></li>\n<li>for 循环操作数组：<br>C 代码：<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span>(i=<span class=\"number\">0</span>;i&lt;<span class=\"number\">1000</span>;i++) <span class=\"built_in\">array</span>[i] *=<span class=\"number\">8</span></span><br></pre></td></tr></table></figure>\n汇编代码：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 初始化：$s0=数组基址(0x23B8F000),$s1=i=0,$t2=1000</span><br><span class=\"line\">lui $s0, 0x23B8</span><br><span class=\"line\">ori $s0, $s0, 0xF000      </span><br><span class=\"line\">addi $s1, $0, 0</span><br><span class=\"line\">addi $t2, $0, 1000</span><br><span class=\"line\"></span><br><span class=\"line\">loop:</span><br><span class=\"line\">slt $t0, $s1, $t2  # $t0=1(i&lt;1000)，否则0</span><br><span class=\"line\">beq $t0, $0, done  # 若i&gt;=1000，跳至done</span><br><span class=\"line\">sll $t0, $s1, 2    # $t0 = i*4(字节偏移)</span><br><span class=\"line\">add $t0, $t0, $s0  # $t0 = array[i]地址</span><br><span class=\"line\">lw $t1, 0($t0)     # $t1 = array[i]</span><br><span class=\"line\">sll $t1, $t1, 3    # $t1 = array[i] *8(左移3位)</span><br><span class=\"line\">sw $t1, 0($t0)     # array[i] = $t1</span><br><span class=\"line\">addi $s1, $s1, 1   # i = i+1</span><br><span class=\"line\">j loop             # 跳回loop</span><br><span class=\"line\"></span><br><span class=\"line\">done:</span><br></pre></td></tr></table></figure></li>\n</ol>\n</li>\n<li>函数调用机制<ol>\n<li>核心概念：<ol>\n<li>调用者（Caller）：发起调用的函数（如 main）</li>\n<li>被调用者（Callee）：被调用的函数（如 sum）</li>\n</ol>\n</li>\n<li><code>MIPS 函数调用约定</code>：<ol>\n<li>传参：前 4 个参数通过a0−a3 传递，超过 4 个需用栈</li>\n<li>返回值：通过v0−v1 返回</li>\n<li>跳转与返回：jal（jump and link）指令跳转（同时将返回地址存入$ra），jr $ra（jump register）指令返回</li>\n</ol>\n</li>\n<li>简单函数示例：<br>C 代码：<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">main</span><span class=\"params\">()</span>&#123;simple(); a=b+c;&#125; <span class=\"type\">void</span> <span class=\"title function_\">simple</span><span class=\"params\">()</span>&#123;<span class=\"keyword\">return</span>;&#125;</span><br><span class=\"line\">```  </span><br><span class=\"line\">汇编代码：</span><br><span class=\"line\">```<span class=\"keyword\">asm</span></span><br><span class=\"line\"><span class=\"number\">0x00400200</span> main: jal simple  # 跳至simple,$ra=<span class=\"number\">0x00400204</span>(下一条指令地址)</span><br><span class=\"line\"><span class=\"number\">0x00400204</span>      add $s0, $s1, $s2  <span class=\"meta\"># a=b+c</span></span><br><span class=\"line\">...</span><br><span class=\"line\"><span class=\"number\">0x00401020</span> simple: jr $ra  # 跳回$ra(<span class=\"number\">0x00400204</span>)</span><br></pre></td></tr></table></figure></li>\n</ol>\n</li>\n<li>分支、循环、栈内存与寻址方式<ol>\n<li>条件标志（CPSR 寄存器）：  <table>\n<thead>\n<tr>\n<th align=\"center\">标志位</th>\n<th align=\"center\">名称</th>\n<th align=\"center\">含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">N</td>\n<td align=\"center\">Negative（负）</td>\n<td align=\"center\">指令结果为负（结果第 31 位为 1）</td>\n</tr>\n<tr>\n<td align=\"center\">Z</td>\n<td align=\"center\">Zero（零）</td>\n<td align=\"center\">指令结果为 0</td>\n</tr>\n<tr>\n<td align=\"center\">C</td>\n<td align=\"center\">Carry（进位）</td>\n<td align=\"center\">指令执行产生进位 &#x2F; 借位</td>\n</tr>\n<tr>\n<td align=\"center\">V</td>\n<td align=\"center\">Overflow（溢出）</td>\n<td align=\"center\">指令执行产生溢出</td>\n</tr>\n</tbody></table>\n</li>\n<li>分支指令（流程跳转）：用于 “打破顺序执行”，分为条件分支（满足条件才跳）和无条件分支（强制跳），依赖 CPSR 寄存器的标志位（N&#x2F;Z&#x2F;C&#x2F;V）判断条件，核心分支指令如下：<table>\n<thead>\n<tr>\n<th align=\"center\">指令类型</th>\n<th align=\"center\">指令</th>\n<th align=\"center\">格式</th>\n<th align=\"center\">功能</th>\n<th align=\"center\">示例</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">条件分支</td>\n<td align=\"center\">beq</td>\n<td align=\"center\">beq $s, $t, label</td>\n<td align=\"center\">若$s &#x3D;&#x3D; $t，跳 label</td>\n<td align=\"center\">beq $s0, $s1, target（s0&#x3D;&#x3D;s1 跳 target）</td>\n</tr>\n<tr>\n<td align=\"center\"></td>\n<td align=\"center\">bne</td>\n<td align=\"center\">bne $s, $t, label</td>\n<td align=\"center\">若$s !&#x3D; $t，跳 label</td>\n<td align=\"center\">bne $s0, $s1, target（s0!&#x3D;s1 跳 target）</td>\n</tr>\n<tr>\n<td align=\"center\">无条件分支</td>\n<td align=\"center\">j</td>\n<td align=\"center\">j label</td>\n<td align=\"center\">强制跳 label（直接使用地址）</td>\n<td align=\"center\">j target（跳 target）</td>\n</tr>\n<tr>\n<td align=\"center\"></td>\n<td align=\"center\">jr</td>\n<td align=\"center\">jr $s</td>\n<td align=\"center\">强制跳 $s 存储的地址（寄存器间接跳转）</td>\n<td align=\"center\">jr $ra（跳 $ra 地址，函数返回）</td>\n</tr>\n<tr>\n<td align=\"center\"></td>\n<td align=\"center\">jal</td>\n<td align=\"center\">jal label</td>\n<td align=\"center\">跳 label，并将返回地址存入 $ra</td>\n<td align=\"center\">jal sum（调用 sum，保存返回地址）</td>\n</tr>\n</tbody></table>\n</li>\n<li>循环与条件语句（if&#x2F;while&#x2F;for）<ol>\n<li>MIPS 通过 “分支指令 + 跳转指令” 实现高级语言的条件与循环逻辑，核心是 “判断条件→跳转到对应代码块”</li>\n<li>if 语句示例<br>C 代码：<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span>(i == j) f = g + h; f = f - i;(s0=f,s1=g,s2=h,s3=i,$s4=j)</span><br><span class=\"line\">```  </span><br><span class=\"line\">汇编代码：</span><br><span class=\"line\">```<span class=\"keyword\">asm</span></span><br><span class=\"line\">bne $s3, $s4, L1   # 若i!=j,跳L1(跳过<span class=\"keyword\">if</span>体)</span><br><span class=\"line\">add $s0, $s1, $s2  <span class=\"meta\"># <span class=\"keyword\">if</span>体:f = g + h(i==j时执行)</span></span><br><span class=\"line\">L1:</span><br><span class=\"line\">sub $s0, $s0, $s3  # 无论<span class=\"keyword\">if</span>是否执行,都执行f = f - i</span><br></pre></td></tr></table></figure></li>\n<li>if-else 语句示例<br>C 代码：<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span>(i == j) f = g + h; <span class=\"keyword\">else</span> f = f - i;</span><br><span class=\"line\">```  </span><br><span class=\"line\">汇编代码：</span><br><span class=\"line\">```<span class=\"keyword\">asm</span></span><br><span class=\"line\">bne $s3, $s4, L1   # 若i!=j,跳L1(执行<span class=\"keyword\">else</span>)</span><br><span class=\"line\">add $s0, $s1, $s2  <span class=\"meta\"># <span class=\"keyword\">if</span>体:f = g + h</span></span><br><span class=\"line\">j done             # 跳done,跳过<span class=\"keyword\">else</span></span><br><span class=\"line\">L1:</span><br><span class=\"line\">sub $s0, $s0, $s3  <span class=\"meta\"># <span class=\"keyword\">else</span>体:f = f -i</span></span><br><span class=\"line\">done:</span><br></pre></td></tr></table></figure></li>\n<li>while 循环示例<br>C 代码：<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> <span class=\"built_in\">pow</span>=<span class=\"number\">1</span>, x=<span class=\"number\">0</span>; <span class=\"keyword\">while</span>(<span class=\"built_in\">pow</span>!=<span class=\"number\">128</span>) &#123; <span class=\"built_in\">pow</span>*=<span class=\"number\">2</span>; x++; &#125;  (s0=<span class=\"built_in\">pow</span>,s1=x)</span><br><span class=\"line\">```  </span><br><span class=\"line\">汇编代码：</span><br><span class=\"line\">```<span class=\"keyword\">asm</span></span><br><span class=\"line\">addi $s0, $<span class=\"number\">0</span>, <span class=\"number\">1</span>    <span class=\"meta\"># pow=1</span></span><br><span class=\"line\">add $s1, $<span class=\"number\">0</span>, $<span class=\"number\">0</span>    <span class=\"meta\"># x=0</span></span><br><span class=\"line\">addi $t0, $<span class=\"number\">0</span>, <span class=\"number\">128</span>  # $t0=<span class=\"number\">128</span> (循环终止条件)</span><br><span class=\"line\"><span class=\"keyword\">while</span>:</span><br><span class=\"line\">beq $s0, $t0, done # 若<span class=\"built_in\">pow</span>==<span class=\"number\">128</span>,跳done (终止循环)</span><br><span class=\"line\">sll $s0, $s0, <span class=\"number\">1</span>    <span class=\"meta\"># pow = pow*2  (左移1位)</span></span><br><span class=\"line\">addi $s1, $s1, <span class=\"number\">1</span>   <span class=\"meta\"># x = x+1</span></span><br><span class=\"line\">j <span class=\"keyword\">while</span>            # 跳回<span class=\"keyword\">while</span>,继续循环</span><br><span class=\"line\">done:</span><br></pre></td></tr></table></figure></li>\n<li>for 循环示例<br>C 代码：<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> sum=<span class=\"number\">0</span>, i; <span class=\"keyword\">for</span>(i=<span class=\"number\">0</span>; i!=<span class=\"number\">10</span>; i++) sum +=i; (s0=i,s1=sum)</span><br><span class=\"line\">```  </span><br><span class=\"line\">汇编代码：</span><br><span class=\"line\">```<span class=\"keyword\">asm</span></span><br><span class=\"line\">addi $s1, $<span class=\"number\">0</span>, <span class=\"number\">0</span>    <span class=\"meta\"># sum=0</span></span><br><span class=\"line\">add $s0, $<span class=\"number\">0</span>, $<span class=\"number\">0</span>    <span class=\"meta\"># i=0</span></span><br><span class=\"line\">addi $t0, $<span class=\"number\">0</span>, <span class=\"number\">10</span>   # $t0=<span class=\"number\">10</span> (循环终止条件)</span><br><span class=\"line\"><span class=\"keyword\">for</span>:</span><br><span class=\"line\">beq $s0, $t0, done # 若i==<span class=\"number\">10</span>，跳done (终止循环)</span><br><span class=\"line\">add $s1, $s1, $s0  <span class=\"meta\"># sum = sum +i</span></span><br><span class=\"line\">addi $s0, $s0, <span class=\"number\">1</span>   <span class=\"meta\"># i = i+1</span></span><br><span class=\"line\">j <span class=\"keyword\">for</span>              # 跳回<span class=\"keyword\">for</span>,继续循环</span><br><span class=\"line\">done:</span><br></pre></td></tr></table></figure></li>\n</ol>\n</li>\n<li>栈内存深度应用（多函数嵌套与递归）<ol>\n<li>栈的核心特性是 “LIFO（后进先出）”，生长方向为 “高地址→低地址”，$sp始终指向栈顶，主要用于：<ol>\n<li>保存被调用者需保留的寄存器（s0−s7、$ra）</li>\n<li>传递超过 4 个的函数参数</li>\n<li>存储递归函数的中间变量</li>\n</ol>\n</li>\n<li>多函数嵌套（保存 $ra）<br>若函数 A 调用函数 B，函数 B 再调用函数 C，jal B会覆盖$ra中 A 的返回地址，因此 B 需先将$ra压栈，再调用 C，示例：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">proc1: # 函数A: 调用proc2</span><br><span class=\"line\">addi $sp, $sp, -4  # 栈扩容4字节(存$ra)</span><br><span class=\"line\">sw $ra, 0($sp)     # 保存proc1的返回地址到栈</span><br><span class=\"line\">jal proc2          # 调用proc2,$ra被更新为proc1中jal后的地址</span><br><span class=\"line\">lw $ra, 0($sp)     # 恢复proc1的返回地址</span><br><span class=\"line\">addi $sp, $sp, 4   # 栈缩容4字节</span><br><span class=\"line\">jr $ra             # 返回proc1的调用者</span><br><span class=\"line\"></span><br><span class=\"line\">proc2: # 函数B: 被proc1调用</span><br><span class=\"line\">jr $ra             # 返回proc1 ($ra存储proc1中jal后的地址)</span><br></pre></td></tr></table></figure></li>\n<li>递归函数示例（阶乘）<br>C 代码：<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">factorial</span><span class=\"params\">(<span class=\"type\">int</span> n)</span> &#123; <span class=\"keyword\">return</span> n==<span class=\"number\">1</span> ? <span class=\"number\">1</span> : n*factorial(n<span class=\"number\">-1</span>); &#125;</span><br><span class=\"line\">```  </span><br><span class=\"line\">汇编代码（$a0=n，$v0= 返回值）：</span><br><span class=\"line\">```<span class=\"keyword\">asm</span></span><br><span class=\"line\">.data</span><br><span class=\"line\">n: .word <span class=\"number\">5</span>  # 计算<span class=\"number\">5</span>的阶乘</span><br><span class=\"line\"></span><br><span class=\"line\">.text</span><br><span class=\"line\">.globl main</span><br><span class=\"line\">main:</span><br><span class=\"line\">lw $a0, n          # $a0 = <span class=\"number\">5</span> (传入factorial的参数)</span><br><span class=\"line\">jal factorial      # 调用factorial</span><br><span class=\"line\"># 打印结果</span><br><span class=\"line\">li $v0, <span class=\"number\">1</span>          # 系统调用<span class=\"number\">1</span>:打印整数</span><br><span class=\"line\">move $a0, $v0      # $a0 = 阶乘结果 (factorial的返回值)</span><br><span class=\"line\">syscall</span><br><span class=\"line\"># 退出程序</span><br><span class=\"line\">li $v0, <span class=\"number\">10</span>         # 系统调用<span class=\"number\">10</span>: 退出</span><br><span class=\"line\">syscall</span><br><span class=\"line\"></span><br><span class=\"line\">factorial:</span><br><span class=\"line\"># <span class=\"number\">1.</span> 栈扩容<span class=\"number\">8</span>字节 (存$ra和$a0,递归需保存n)</span><br><span class=\"line\">addi $sp, $sp, <span class=\"number\">-8</span></span><br><span class=\"line\">sw $ra, <span class=\"number\">4</span>($sp)     # 保存当前返回地址到栈偏移<span class=\"number\">4</span></span><br><span class=\"line\">sw $a0, <span class=\"number\">0</span>($sp)     # 保存当前n到栈偏移<span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"># <span class=\"number\">2.</span> 递归终止条件: n==<span class=\"number\">1</span></span><br><span class=\"line\">li $v0, <span class=\"number\">1</span>          # $v0=<span class=\"number\">1</span> (终止条件返回值)</span><br><span class=\"line\">beq $a0, $v0, base_case # 若n==<span class=\"number\">1</span>,跳base_case</span><br><span class=\"line\"></span><br><span class=\"line\"># <span class=\"number\">3.</span> 递归调用: factorial(n<span class=\"number\">-1</span>)</span><br><span class=\"line\">addi $a0, $a0, <span class=\"number\">-1</span>  # $a0 = n<span class=\"number\">-1</span></span><br><span class=\"line\">jal factorial      # 调用factorial(n<span class=\"number\">-1</span>),$ra更新为当前jal后的地址</span><br><span class=\"line\"></span><br><span class=\"line\"># <span class=\"number\">4.</span> 计算n * factorial(n<span class=\"number\">-1</span>)</span><br><span class=\"line\">lw $a0, <span class=\"number\">0</span>($sp)     # 恢复当前n (从栈中取)</span><br><span class=\"line\">mul $v0, $a0, $v0  # $v0 = n * factorial(n<span class=\"number\">-1</span>) (返回值)</span><br><span class=\"line\"></span><br><span class=\"line\"># <span class=\"number\">5.</span> 恢复寄存器+栈缩容</span><br><span class=\"line\">base_case:</span><br><span class=\"line\">lw $ra, <span class=\"number\">4</span>($sp)     # 恢复返回地址</span><br><span class=\"line\">addi $sp, $sp, <span class=\"number\">8</span>   # 栈缩容<span class=\"number\">8</span>字节</span><br><span class=\"line\">jr $ra             # 返回调用者</span><br></pre></td></tr></table></figure></li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"今日总结\"><a href=\"#今日总结\" class=\"headerlink\" title=\"今日总结\"></a>今日总结</h2><ol>\n<li>今天速学了html和css的一些基础知识</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>昨日总结</li>\n<li>学习笔记</li>\n<li>今日总结</li>\n</ol>\n<h2 id=\"昨日总结\"><a href=\"#昨日总结\" class=\"headerlink\" title=\"昨日总结\"></a>昨日总结</h2><p>昨天从早上集合后前往上海参加本周的城市之旅活动，逛了几处没去过的地方，不过最大的收获是从一个来参加的老师那里得知了一个日后会常驻举办的活动——宠物交流活动，以后每周有一次带摩羯出去和别的宠物交流的机会，希望借此机会让它的胆子变大吧，而且希望可以人生同样有爱的主人吧<br>不过可惜的是昨天因为行程安排不妥导致昨天没能赶上晚上的飞盘训练，之后的活动不能再犯同样的错误了</p>\n<h2 id=\"学习笔记\"><a href=\"#学习笔记\" class=\"headerlink\" title=\"学习笔记\"></a>学习笔记</h2><h3 id=\"计算机体系结构与操作系统\"><a href=\"#计算机体系结构与操作系统\" class=\"headerlink\" title=\"计算机体系结构与操作系统\"></a>计算机体系结构与操作系统</h3><p>MIPS 汇编语言入门</p>\n<ol>\n<li>计算机抽象层级与指令基础<ol>\n<li>抽象层级（从高到低）：应用软件→操作系统→架构（程序员视角，定义指令 &#x2F; 操作数位置）→微架构（硬件实现细节）→逻辑→数字电路→模拟电路→器件→物理</li>\n<li>指令分类：<ol>\n<li>机器语言：二进制码（如01101010 10101101），计算机可直接识别</li>\n<li>汇编语言：机器语言的符号表示（如add $s0,$s1,$s2），需汇编器转换</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>MIPS 架构概述<ol>\n<li>学习价值：作为 RISC 架构代表，掌握后易迁移到其他架构</li>\n<li>核心特点：<ol>\n<li>32 位架构：操作 32 位数据，含32 个 32 位通用寄存器（速度远快于内存，减少访问延迟）</li>\n<li>load&#x2F;store 架构：仅通过lw（加载）&#x2F;sw（存储）指令访问内存，其他指令操作寄存器</li>\n<li>固定指令长度：所有指令均为 32 位，简化硬件解码</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>基础算术与逻辑操作<ol>\n<li>核心指令格式：多数指令为 “目标寄存器，源寄存器 1，源寄存器 2”（如add $d, $s, $t）</li>\n<li>算术指令：<ol>\n<li>add $d, $s, $t：$d &#x3D; $s + $t</li>\n<li>sub $d, $s, $t：$d &#x3D; $s - $t</li>\n<li>addi $d, $s, imm：$d &#x3D; $s + imm （add后面的i意味计算里使用了数字）</li>\n</ol>\n</li>\n<li>复杂表达式实现：需拆分多指令，如 C 代码a&#x3D;b+c-d对应：<br>add $t0, $s1, $s2  # $t0 &#x3D; b + c（临时寄存器存中间结果）<br>sub $s0, $t0, $s3  # $s0 &#x3D; $t0 - d &#x3D; b + c - d</li>\n</ol>\n</li>\n<li>内存访问基础<ol>\n<li>内存需求：寄存器仅 32 个，无法存储大量数据，需依赖内存（容量大但速度慢）</li>\n<li>寻址模式：<ol>\n<li>字寻址：每个 32 位数据（字）对应唯一字地址</li>\n</ol>\n</li>\n<li>字节寻址：MIPS 实际采用字节寻址（每个字节 1 个地址），字地址 &#x3D; 字节地址 ×4（因 1 字 &#x3D; 4 字节），示例：字 2 的字节地址为 8（2×4）</li>\n<li>内存操作指令：<ol>\n<li>加载字：lw $d, offset($base) -&gt; d &#x3D; 内存[base + offset]（示例：读取字节地址4的字到s3，指令lw $s3,4($0)）</li>\n<li>存储字：sw $s, offset($base) -&gt; s &#x3D; 内存[base + offset]()（示例：将t4存入字节地址7，指令sw $t4,0x7($0)）</li>\n<li>加载字节（lb）&#x2F; 存储字节（sb）：操作单个字节数据</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<p>逻辑指令、移位、数组与函数调用</p>\n<ol>\n<li>逻辑指令<ol>\n<li>核心指令（操作寄存器或立即数）：<ol>\n<li>and $d, $s, $t：$d &#x3D; $s &amp; $t （用于位掩码，如保留低 8 位：0xF234012F &amp; 0x000000FF &#x3D; 0x0000002F）</li>\n<li>or $d, $s, $t：$d &#x3D; $s | $t  （用于组合位域，如0xF2340000 | 0x000012BC &#x3D; 0xF23412BC）</li>\n<li>xor $d, $s, $t：$d &#x3D; $s ^ $t （位异或）</li>\n<li>nor $d, $s, $t：d&#x3D; (s | $t)  （位或非，用于取反：A nor 0 &#x3D; ~A）</li>\n<li>立即数逻辑指令：andi、ori、xori（16 位立即数零扩展，无nori）</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>移位指令<ol>\n<li>指令类型（移位量可为立即数或寄存器）：<ol>\n<li>sll $d, $s, shamt：逻辑左移 → $d &#x3D; $s &lt;&lt; shamt（高位补 0，示例：sll $t0,$t1,5 → t0&#x3D;t1 左移 5 位）</li>\n<li>srl $d, $s, shamt：逻辑右移 → $d &#x3D; $s &gt;&gt; shamt（低位补 0）</li>\n<li>sra $d, $s, shamt：算术右移 → $d &#x3D; $s &gt;&gt;&gt; shamt（高位补符号位，用于有符号数）</li>\n</ol>\n</li>\n<li>应用：左移 1 位等价于 ×2，左移 3 位等价于 ×8（如 C 代码a&#x3D;2*b对应sll $t0,$s1,1）</li>\n</ol>\n</li>\n<li>常量生成与乘除操作<ol>\n<li>32 位常量生成：MIPS 立即数仅 16 位，需组合lui（加载高位立即数）和ori：<ol>\n<li>示例：C 代码int a&#x3D;0xFEDC8765对应：<br>lui $s0, 0xFEDC  # $s0 &#x3D; 0xFEDC0000（加载高16位）<br>ori $s0, $s0, 0x8765  # $s0 &#x3D; 0xFEDC0000 | 0x8765 &#x3D; 0xFEDC8765</li>\n</ol>\n</li>\n<li>乘除操作：依赖专用寄存器hi（高位结果）和lo（低位结果）：<ol>\n<li>乘法：mult $s, $t → 结果（64 位）存入 {hi, lo}，需mfhi $d（读取 hi）、mflo $d（读取 lo）</li>\n<li>除法：div $s, $t → 商存入 lo，余数存入 hi，同样通过mfhi&#x2F;mflo读取</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>数组操作<ol>\n<li>数组存储：数组元素连续存储，基地址为首个元素地址（如 5 元素数组 base&#x3D;0x12348000，元素地址为 base、base+4、base+8 等）</li>\n<li>单元素操作示例：<br>C 代码：<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">array</span>[<span class=\"number\">0</span>] *=<span class=\"number\">2</span>; <span class=\"built_in\">array</span>[<span class=\"number\">1</span>] *=<span class=\"number\">2</span>(base=<span class=\"number\">0x12348000</span>)</span><br></pre></td></tr></table></figure>\n汇编代码：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">lui $s0, 0x1234       # $s0 = 0x12340000</span><br><span class=\"line\">ori $s0, $s0, 0x8000  # $s0 = 0x12348000(数组基地址)</span><br><span class=\"line\"></span><br><span class=\"line\">lw $t1, 0($s0)     # $t1 = array[0]</span><br><span class=\"line\">sll $t1, $t1, 1    # $t1 = array[0] * 2</span><br><span class=\"line\">sw $t1, 0($s0)     # array[0] = $t1</span><br><span class=\"line\"></span><br><span class=\"line\">lw $t1, 4($s0)     # $t1 = array[1]</span><br><span class=\"line\">sll $t1, $t1, 1    # $t1 = array[1] * 2</span><br><span class=\"line\">sw $t1, 4($s0)     # array[1] = $t1</span><br></pre></td></tr></table></figure></li>\n<li>for 循环操作数组：<br>C 代码：<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span>(i=<span class=\"number\">0</span>;i&lt;<span class=\"number\">1000</span>;i++) <span class=\"built_in\">array</span>[i] *=<span class=\"number\">8</span></span><br></pre></td></tr></table></figure>\n汇编代码：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 初始化：$s0=数组基址(0x23B8F000),$s1=i=0,$t2=1000</span><br><span class=\"line\">lui $s0, 0x23B8</span><br><span class=\"line\">ori $s0, $s0, 0xF000      </span><br><span class=\"line\">addi $s1, $0, 0</span><br><span class=\"line\">addi $t2, $0, 1000</span><br><span class=\"line\"></span><br><span class=\"line\">loop:</span><br><span class=\"line\">slt $t0, $s1, $t2  # $t0=1(i&lt;1000)，否则0</span><br><span class=\"line\">beq $t0, $0, done  # 若i&gt;=1000，跳至done</span><br><span class=\"line\">sll $t0, $s1, 2    # $t0 = i*4(字节偏移)</span><br><span class=\"line\">add $t0, $t0, $s0  # $t0 = array[i]地址</span><br><span class=\"line\">lw $t1, 0($t0)     # $t1 = array[i]</span><br><span class=\"line\">sll $t1, $t1, 3    # $t1 = array[i] *8(左移3位)</span><br><span class=\"line\">sw $t1, 0($t0)     # array[i] = $t1</span><br><span class=\"line\">addi $s1, $s1, 1   # i = i+1</span><br><span class=\"line\">j loop             # 跳回loop</span><br><span class=\"line\"></span><br><span class=\"line\">done:</span><br></pre></td></tr></table></figure></li>\n</ol>\n</li>\n<li>函数调用机制<ol>\n<li>核心概念：<ol>\n<li>调用者（Caller）：发起调用的函数（如 main）</li>\n<li>被调用者（Callee）：被调用的函数（如 sum）</li>\n</ol>\n</li>\n<li><code>MIPS 函数调用约定</code>：<ol>\n<li>传参：前 4 个参数通过a0−a3 传递，超过 4 个需用栈</li>\n<li>返回值：通过v0−v1 返回</li>\n<li>跳转与返回：jal（jump and link）指令跳转（同时将返回地址存入$ra），jr $ra（jump register）指令返回</li>\n</ol>\n</li>\n<li>简单函数示例：<br>C 代码：<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">void</span> <span class=\"title function_\">main</span><span class=\"params\">()</span>&#123;simple(); a=b+c;&#125; <span class=\"type\">void</span> <span class=\"title function_\">simple</span><span class=\"params\">()</span>&#123;<span class=\"keyword\">return</span>;&#125;</span><br><span class=\"line\">```  </span><br><span class=\"line\">汇编代码：</span><br><span class=\"line\">```<span class=\"keyword\">asm</span></span><br><span class=\"line\"><span class=\"number\">0x00400200</span> main: jal simple  # 跳至simple,$ra=<span class=\"number\">0x00400204</span>(下一条指令地址)</span><br><span class=\"line\"><span class=\"number\">0x00400204</span>      add $s0, $s1, $s2  <span class=\"meta\"># a=b+c</span></span><br><span class=\"line\">...</span><br><span class=\"line\"><span class=\"number\">0x00401020</span> simple: jr $ra  # 跳回$ra(<span class=\"number\">0x00400204</span>)</span><br></pre></td></tr></table></figure></li>\n</ol>\n</li>\n<li>分支、循环、栈内存与寻址方式<ol>\n<li>条件标志（CPSR 寄存器）：  <table>\n<thead>\n<tr>\n<th align=\"center\">标志位</th>\n<th align=\"center\">名称</th>\n<th align=\"center\">含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">N</td>\n<td align=\"center\">Negative（负）</td>\n<td align=\"center\">指令结果为负（结果第 31 位为 1）</td>\n</tr>\n<tr>\n<td align=\"center\">Z</td>\n<td align=\"center\">Zero（零）</td>\n<td align=\"center\">指令结果为 0</td>\n</tr>\n<tr>\n<td align=\"center\">C</td>\n<td align=\"center\">Carry（进位）</td>\n<td align=\"center\">指令执行产生进位 &#x2F; 借位</td>\n</tr>\n<tr>\n<td align=\"center\">V</td>\n<td align=\"center\">Overflow（溢出）</td>\n<td align=\"center\">指令执行产生溢出</td>\n</tr>\n</tbody></table>\n</li>\n<li>分支指令（流程跳转）：用于 “打破顺序执行”，分为条件分支（满足条件才跳）和无条件分支（强制跳），依赖 CPSR 寄存器的标志位（N&#x2F;Z&#x2F;C&#x2F;V）判断条件，核心分支指令如下：<table>\n<thead>\n<tr>\n<th align=\"center\">指令类型</th>\n<th align=\"center\">指令</th>\n<th align=\"center\">格式</th>\n<th align=\"center\">功能</th>\n<th align=\"center\">示例</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">条件分支</td>\n<td align=\"center\">beq</td>\n<td align=\"center\">beq $s, $t, label</td>\n<td align=\"center\">若$s &#x3D;&#x3D; $t，跳 label</td>\n<td align=\"center\">beq $s0, $s1, target（s0&#x3D;&#x3D;s1 跳 target）</td>\n</tr>\n<tr>\n<td align=\"center\"></td>\n<td align=\"center\">bne</td>\n<td align=\"center\">bne $s, $t, label</td>\n<td align=\"center\">若$s !&#x3D; $t，跳 label</td>\n<td align=\"center\">bne $s0, $s1, target（s0!&#x3D;s1 跳 target）</td>\n</tr>\n<tr>\n<td align=\"center\">无条件分支</td>\n<td align=\"center\">j</td>\n<td align=\"center\">j label</td>\n<td align=\"center\">强制跳 label（直接使用地址）</td>\n<td align=\"center\">j target（跳 target）</td>\n</tr>\n<tr>\n<td align=\"center\"></td>\n<td align=\"center\">jr</td>\n<td align=\"center\">jr $s</td>\n<td align=\"center\">强制跳 $s 存储的地址（寄存器间接跳转）</td>\n<td align=\"center\">jr $ra（跳 $ra 地址，函数返回）</td>\n</tr>\n<tr>\n<td align=\"center\"></td>\n<td align=\"center\">jal</td>\n<td align=\"center\">jal label</td>\n<td align=\"center\">跳 label，并将返回地址存入 $ra</td>\n<td align=\"center\">jal sum（调用 sum，保存返回地址）</td>\n</tr>\n</tbody></table>\n</li>\n<li>循环与条件语句（if&#x2F;while&#x2F;for）<ol>\n<li>MIPS 通过 “分支指令 + 跳转指令” 实现高级语言的条件与循环逻辑，核心是 “判断条件→跳转到对应代码块”</li>\n<li>if 语句示例<br>C 代码：<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span>(i == j) f = g + h; f = f - i;(s0=f,s1=g,s2=h,s3=i,$s4=j)</span><br><span class=\"line\">```  </span><br><span class=\"line\">汇编代码：</span><br><span class=\"line\">```<span class=\"keyword\">asm</span></span><br><span class=\"line\">bne $s3, $s4, L1   # 若i!=j,跳L1(跳过<span class=\"keyword\">if</span>体)</span><br><span class=\"line\">add $s0, $s1, $s2  <span class=\"meta\"># <span class=\"keyword\">if</span>体:f = g + h(i==j时执行)</span></span><br><span class=\"line\">L1:</span><br><span class=\"line\">sub $s0, $s0, $s3  # 无论<span class=\"keyword\">if</span>是否执行,都执行f = f - i</span><br></pre></td></tr></table></figure></li>\n<li>if-else 语句示例<br>C 代码：<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">if</span>(i == j) f = g + h; <span class=\"keyword\">else</span> f = f - i;</span><br><span class=\"line\">```  </span><br><span class=\"line\">汇编代码：</span><br><span class=\"line\">```<span class=\"keyword\">asm</span></span><br><span class=\"line\">bne $s3, $s4, L1   # 若i!=j,跳L1(执行<span class=\"keyword\">else</span>)</span><br><span class=\"line\">add $s0, $s1, $s2  <span class=\"meta\"># <span class=\"keyword\">if</span>体:f = g + h</span></span><br><span class=\"line\">j done             # 跳done,跳过<span class=\"keyword\">else</span></span><br><span class=\"line\">L1:</span><br><span class=\"line\">sub $s0, $s0, $s3  <span class=\"meta\"># <span class=\"keyword\">else</span>体:f = f -i</span></span><br><span class=\"line\">done:</span><br></pre></td></tr></table></figure></li>\n<li>while 循环示例<br>C 代码：<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> <span class=\"built_in\">pow</span>=<span class=\"number\">1</span>, x=<span class=\"number\">0</span>; <span class=\"keyword\">while</span>(<span class=\"built_in\">pow</span>!=<span class=\"number\">128</span>) &#123; <span class=\"built_in\">pow</span>*=<span class=\"number\">2</span>; x++; &#125;  (s0=<span class=\"built_in\">pow</span>,s1=x)</span><br><span class=\"line\">```  </span><br><span class=\"line\">汇编代码：</span><br><span class=\"line\">```<span class=\"keyword\">asm</span></span><br><span class=\"line\">addi $s0, $<span class=\"number\">0</span>, <span class=\"number\">1</span>    <span class=\"meta\"># pow=1</span></span><br><span class=\"line\">add $s1, $<span class=\"number\">0</span>, $<span class=\"number\">0</span>    <span class=\"meta\"># x=0</span></span><br><span class=\"line\">addi $t0, $<span class=\"number\">0</span>, <span class=\"number\">128</span>  # $t0=<span class=\"number\">128</span> (循环终止条件)</span><br><span class=\"line\"><span class=\"keyword\">while</span>:</span><br><span class=\"line\">beq $s0, $t0, done # 若<span class=\"built_in\">pow</span>==<span class=\"number\">128</span>,跳done (终止循环)</span><br><span class=\"line\">sll $s0, $s0, <span class=\"number\">1</span>    <span class=\"meta\"># pow = pow*2  (左移1位)</span></span><br><span class=\"line\">addi $s1, $s1, <span class=\"number\">1</span>   <span class=\"meta\"># x = x+1</span></span><br><span class=\"line\">j <span class=\"keyword\">while</span>            # 跳回<span class=\"keyword\">while</span>,继续循环</span><br><span class=\"line\">done:</span><br></pre></td></tr></table></figure></li>\n<li>for 循环示例<br>C 代码：<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> sum=<span class=\"number\">0</span>, i; <span class=\"keyword\">for</span>(i=<span class=\"number\">0</span>; i!=<span class=\"number\">10</span>; i++) sum +=i; (s0=i,s1=sum)</span><br><span class=\"line\">```  </span><br><span class=\"line\">汇编代码：</span><br><span class=\"line\">```<span class=\"keyword\">asm</span></span><br><span class=\"line\">addi $s1, $<span class=\"number\">0</span>, <span class=\"number\">0</span>    <span class=\"meta\"># sum=0</span></span><br><span class=\"line\">add $s0, $<span class=\"number\">0</span>, $<span class=\"number\">0</span>    <span class=\"meta\"># i=0</span></span><br><span class=\"line\">addi $t0, $<span class=\"number\">0</span>, <span class=\"number\">10</span>   # $t0=<span class=\"number\">10</span> (循环终止条件)</span><br><span class=\"line\"><span class=\"keyword\">for</span>:</span><br><span class=\"line\">beq $s0, $t0, done # 若i==<span class=\"number\">10</span>，跳done (终止循环)</span><br><span class=\"line\">add $s1, $s1, $s0  <span class=\"meta\"># sum = sum +i</span></span><br><span class=\"line\">addi $s0, $s0, <span class=\"number\">1</span>   <span class=\"meta\"># i = i+1</span></span><br><span class=\"line\">j <span class=\"keyword\">for</span>              # 跳回<span class=\"keyword\">for</span>,继续循环</span><br><span class=\"line\">done:</span><br></pre></td></tr></table></figure></li>\n</ol>\n</li>\n<li>栈内存深度应用（多函数嵌套与递归）<ol>\n<li>栈的核心特性是 “LIFO（后进先出）”，生长方向为 “高地址→低地址”，$sp始终指向栈顶，主要用于：<ol>\n<li>保存被调用者需保留的寄存器（s0−s7、$ra）</li>\n<li>传递超过 4 个的函数参数</li>\n<li>存储递归函数的中间变量</li>\n</ol>\n</li>\n<li>多函数嵌套（保存 $ra）<br>若函数 A 调用函数 B，函数 B 再调用函数 C，jal B会覆盖$ra中 A 的返回地址，因此 B 需先将$ra压栈，再调用 C，示例：<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">proc1: # 函数A: 调用proc2</span><br><span class=\"line\">addi $sp, $sp, -4  # 栈扩容4字节(存$ra)</span><br><span class=\"line\">sw $ra, 0($sp)     # 保存proc1的返回地址到栈</span><br><span class=\"line\">jal proc2          # 调用proc2,$ra被更新为proc1中jal后的地址</span><br><span class=\"line\">lw $ra, 0($sp)     # 恢复proc1的返回地址</span><br><span class=\"line\">addi $sp, $sp, 4   # 栈缩容4字节</span><br><span class=\"line\">jr $ra             # 返回proc1的调用者</span><br><span class=\"line\"></span><br><span class=\"line\">proc2: # 函数B: 被proc1调用</span><br><span class=\"line\">jr $ra             # 返回proc1 ($ra存储proc1中jal后的地址)</span><br></pre></td></tr></table></figure></li>\n<li>递归函数示例（阶乘）<br>C 代码：<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"type\">int</span> <span class=\"title function_\">factorial</span><span class=\"params\">(<span class=\"type\">int</span> n)</span> &#123; <span class=\"keyword\">return</span> n==<span class=\"number\">1</span> ? <span class=\"number\">1</span> : n*factorial(n<span class=\"number\">-1</span>); &#125;</span><br><span class=\"line\">```  </span><br><span class=\"line\">汇编代码（$a0=n，$v0= 返回值）：</span><br><span class=\"line\">```<span class=\"keyword\">asm</span></span><br><span class=\"line\">.data</span><br><span class=\"line\">n: .word <span class=\"number\">5</span>  # 计算<span class=\"number\">5</span>的阶乘</span><br><span class=\"line\"></span><br><span class=\"line\">.text</span><br><span class=\"line\">.globl main</span><br><span class=\"line\">main:</span><br><span class=\"line\">lw $a0, n          # $a0 = <span class=\"number\">5</span> (传入factorial的参数)</span><br><span class=\"line\">jal factorial      # 调用factorial</span><br><span class=\"line\"># 打印结果</span><br><span class=\"line\">li $v0, <span class=\"number\">1</span>          # 系统调用<span class=\"number\">1</span>:打印整数</span><br><span class=\"line\">move $a0, $v0      # $a0 = 阶乘结果 (factorial的返回值)</span><br><span class=\"line\">syscall</span><br><span class=\"line\"># 退出程序</span><br><span class=\"line\">li $v0, <span class=\"number\">10</span>         # 系统调用<span class=\"number\">10</span>: 退出</span><br><span class=\"line\">syscall</span><br><span class=\"line\"></span><br><span class=\"line\">factorial:</span><br><span class=\"line\"># <span class=\"number\">1.</span> 栈扩容<span class=\"number\">8</span>字节 (存$ra和$a0,递归需保存n)</span><br><span class=\"line\">addi $sp, $sp, <span class=\"number\">-8</span></span><br><span class=\"line\">sw $ra, <span class=\"number\">4</span>($sp)     # 保存当前返回地址到栈偏移<span class=\"number\">4</span></span><br><span class=\"line\">sw $a0, <span class=\"number\">0</span>($sp)     # 保存当前n到栈偏移<span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\"># <span class=\"number\">2.</span> 递归终止条件: n==<span class=\"number\">1</span></span><br><span class=\"line\">li $v0, <span class=\"number\">1</span>          # $v0=<span class=\"number\">1</span> (终止条件返回值)</span><br><span class=\"line\">beq $a0, $v0, base_case # 若n==<span class=\"number\">1</span>,跳base_case</span><br><span class=\"line\"></span><br><span class=\"line\"># <span class=\"number\">3.</span> 递归调用: factorial(n<span class=\"number\">-1</span>)</span><br><span class=\"line\">addi $a0, $a0, <span class=\"number\">-1</span>  # $a0 = n<span class=\"number\">-1</span></span><br><span class=\"line\">jal factorial      # 调用factorial(n<span class=\"number\">-1</span>),$ra更新为当前jal后的地址</span><br><span class=\"line\"></span><br><span class=\"line\"># <span class=\"number\">4.</span> 计算n * factorial(n<span class=\"number\">-1</span>)</span><br><span class=\"line\">lw $a0, <span class=\"number\">0</span>($sp)     # 恢复当前n (从栈中取)</span><br><span class=\"line\">mul $v0, $a0, $v0  # $v0 = n * factorial(n<span class=\"number\">-1</span>) (返回值)</span><br><span class=\"line\"></span><br><span class=\"line\"># <span class=\"number\">5.</span> 恢复寄存器+栈缩容</span><br><span class=\"line\">base_case:</span><br><span class=\"line\">lw $ra, <span class=\"number\">4</span>($sp)     # 恢复返回地址</span><br><span class=\"line\">addi $sp, $sp, <span class=\"number\">8</span>   # 栈缩容<span class=\"number\">8</span>字节</span><br><span class=\"line\">jr $ra             # 返回调用者</span><br></pre></td></tr></table></figure></li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"今日总结\"><a href=\"#今日总结\" class=\"headerlink\" title=\"今日总结\"></a>今日总结</h2><ol>\n<li>今天速学了html和css的一些基础知识</li>\n</ol>\n"},{"title":"2025.11.18","date":"2025-11-18T09:32:42.000Z","_content":"# Overview\n1. 近期总结\n2. 终极目标进程\n\n## 近期总结\n距离上一次博客已经过去一周了，自从进入后半学期后明显开始忙碌起来了，而且好几个活动赶在一起使得这一周多的时间过的飞快。\n\n\n## 终极目标进程\n简单的学习了HTML、CSS、JavaScript，接下来打算学下scss、vue、vite","source":"_posts/2025-11-18.md","raw":"---\ntitle: 2025.11.18\ndate: 2025-11-18 17:32:42\ntags:\n---\n# Overview\n1. 近期总结\n2. 终极目标进程\n\n## 近期总结\n距离上一次博客已经过去一周了，自从进入后半学期后明显开始忙碌起来了，而且好几个活动赶在一起使得这一周多的时间过的飞快。\n\n\n## 终极目标进程\n简单的学习了HTML、CSS、JavaScript，接下来打算学下scss、vue、vite","slug":"2025-11-18","published":1,"updated":"2025-11-18T19:39:17.104Z","comments":1,"layout":"post","photos":[],"_id":"cuideHfsffBABculCj52Nai28","content":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>近期总结</li>\n<li>终极目标进程</li>\n</ol>\n<h2 id=\"近期总结\"><a href=\"#近期总结\" class=\"headerlink\" title=\"近期总结\"></a>近期总结</h2><p>距离上一次博客已经过去一周了，自从进入后半学期后明显开始忙碌起来了，而且好几个活动赶在一起使得这一周多的时间过的飞快。</p>\n<h2 id=\"终极目标进程\"><a href=\"#终极目标进程\" class=\"headerlink\" title=\"终极目标进程\"></a>终极目标进程</h2><p>简单的学习了HTML、CSS、JavaScript，接下来打算学下scss、vue、vite</p>\n","excerpt":"","more":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>近期总结</li>\n<li>终极目标进程</li>\n</ol>\n<h2 id=\"近期总结\"><a href=\"#近期总结\" class=\"headerlink\" title=\"近期总结\"></a>近期总结</h2><p>距离上一次博客已经过去一周了，自从进入后半学期后明显开始忙碌起来了，而且好几个活动赶在一起使得这一周多的时间过的飞快。</p>\n<h2 id=\"终极目标进程\"><a href=\"#终极目标进程\" class=\"headerlink\" title=\"终极目标进程\"></a>终极目标进程</h2><p>简单的学习了HTML、CSS、JavaScript，接下来打算学下scss、vue、vite</p>\n"},{"title":"2025.11.6","date":"2025-11-06T05:53:38.000Z","_content":"# Summary\n1. 今天把《墨菲定律》看完了，整体读下来发现这本书就是一个如何提升自我的工具书，书中从各种心理学效应出发，对于不同的情景下自己该怎么做给出了建议\n2. 今天把一门课的一个作业做完了\n3. 今天的飞盘活动原本还因为下雨没什么人打算散场了，结果到最后变成十几个人的大部队，而且在活动中得知了接下来还会有野餐团建，期待快点到来","source":"_posts/2025-11-6.md","raw":"---\ntitle: 2025.11.6\ndate: 2025-11-06 13:53:38\ntags:\n---\n# Summary\n1. 今天把《墨菲定律》看完了，整体读下来发现这本书就是一个如何提升自我的工具书，书中从各种心理学效应出发，对于不同的情景下自己该怎么做给出了建议\n2. 今天把一门课的一个作业做完了\n3. 今天的飞盘活动原本还因为下雨没什么人打算散场了，结果到最后变成十几个人的大部队，而且在活动中得知了接下来还会有野餐团建，期待快点到来","slug":"2025-11-6","published":1,"updated":"2025-11-18T19:39:17.145Z","comments":1,"layout":"post","photos":[],"_id":"cuid_RMgIXUk4xuq4496w7XNN","content":"<h1 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h1><ol>\n<li>今天把《墨菲定律》看完了，整体读下来发现这本书就是一个如何提升自我的工具书，书中从各种心理学效应出发，对于不同的情景下自己该怎么做给出了建议</li>\n<li>今天把一门课的一个作业做完了</li>\n<li>今天的飞盘活动原本还因为下雨没什么人打算散场了，结果到最后变成十几个人的大部队，而且在活动中得知了接下来还会有野餐团建，期待快点到来</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h1><ol>\n<li>今天把《墨菲定律》看完了，整体读下来发现这本书就是一个如何提升自我的工具书，书中从各种心理学效应出发，对于不同的情景下自己该怎么做给出了建议</li>\n<li>今天把一门课的一个作业做完了</li>\n<li>今天的飞盘活动原本还因为下雨没什么人打算散场了，结果到最后变成十几个人的大部队，而且在活动中得知了接下来还会有野餐团建，期待快点到来</li>\n</ol>\n"},{"title":"2025.11.7","date":"2025-11-07T02:43:32.000Z","_content":"# Overvirw\n1. 静态网站项目准备与学习\n2. 今日总结\n\n## 静态网站项目准备与学习\n1. 浏览器开发者工具的初步接触\n   1. 首先在项目文件夹中调试.html文件，进入浏览器里的静态网页\n   2. 在浏览器中按 F12 来打开开发者工具\n   3. 用「源」选项卡编辑 JS 文件  \n      点击开发者工具中的源代码 -> 点击“+手动添加文件夹” -> 选择项目文件夹打开并允许编辑文件 （这样就可以直接编辑外部.html、.js文件并保存（CTRL + S））  \n      **注意**：必须手动添加文件夹才能够编辑并保存文件内容\n2. 本地开发服务器\n   1. 使用方法：使用Python内置服务器，在PyCharm的终端中输入：\n      python -m http.server 8000  \n      之后就可以在服务器中通过http://协议访问对应的网页\n   2. 作用：在本地搭建一个简单的 Web 服务器，以便在开发静态页面（HTML/CSS/JavaScript）时进行本地预览\n      1. 模拟线上环境，避免本地文件访问限制\n      2. 方便本地调试与实时预览\n      3. 为后续部署到 GitHub Pages 做验证\n   3. **注意**：\n      1. 每次想要打开本地服务器必须先在PyCharm的终端中执行上面的命令，否则打不开对应网页\n      2. 其实在PyCharm终端中执行的代码的本质是创建当前打开文件的本地服务器，所以想要打开必须要先打开对应项目文件夹再执行上面的代码\n3. GitHub Desktop\n   1. 下载GitHub Desktop，并登录GitHub账号，并克隆GitHub库到软件内\n   2. 使用方法：\n      1. 可以通过本地电脑的文件操作或者PyCharm中修改文件后在GitHub Desktop软件内对该次改变进行描述并上传，就可以将改变推送到远程的GitHub库里\n4. 过程中的改变\n   1. 将静态网站项目的文件夹内的.html、.sj、.css文件移动到同一个目录下，并创建assets文件夹用于后续存放图片字体等，最后在每一个项目文件夹里加入了.md的项目介绍文件\n   2. 在F盘中创建用于存放GitHub库的文件夹，并在里面创建blog文件夹用于存放与博客相关的内容，并把之前pynote1文件夹复制到该文件夹内，使得以后可以通过编写该文件夹内的文件来上传到GitHub库里\n\n## 今日总结\n1. ","source":"_posts/2025-11-7.md","raw":"---\ntitle: 2025.11.7\ndate: 2025-11-07 10:43:32\ntags:\n---\n# Overvirw\n1. 静态网站项目准备与学习\n2. 今日总结\n\n## 静态网站项目准备与学习\n1. 浏览器开发者工具的初步接触\n   1. 首先在项目文件夹中调试.html文件，进入浏览器里的静态网页\n   2. 在浏览器中按 F12 来打开开发者工具\n   3. 用「源」选项卡编辑 JS 文件  \n      点击开发者工具中的源代码 -> 点击“+手动添加文件夹” -> 选择项目文件夹打开并允许编辑文件 （这样就可以直接编辑外部.html、.js文件并保存（CTRL + S））  \n      **注意**：必须手动添加文件夹才能够编辑并保存文件内容\n2. 本地开发服务器\n   1. 使用方法：使用Python内置服务器，在PyCharm的终端中输入：\n      python -m http.server 8000  \n      之后就可以在服务器中通过http://协议访问对应的网页\n   2. 作用：在本地搭建一个简单的 Web 服务器，以便在开发静态页面（HTML/CSS/JavaScript）时进行本地预览\n      1. 模拟线上环境，避免本地文件访问限制\n      2. 方便本地调试与实时预览\n      3. 为后续部署到 GitHub Pages 做验证\n   3. **注意**：\n      1. 每次想要打开本地服务器必须先在PyCharm的终端中执行上面的命令，否则打不开对应网页\n      2. 其实在PyCharm终端中执行的代码的本质是创建当前打开文件的本地服务器，所以想要打开必须要先打开对应项目文件夹再执行上面的代码\n3. GitHub Desktop\n   1. 下载GitHub Desktop，并登录GitHub账号，并克隆GitHub库到软件内\n   2. 使用方法：\n      1. 可以通过本地电脑的文件操作或者PyCharm中修改文件后在GitHub Desktop软件内对该次改变进行描述并上传，就可以将改变推送到远程的GitHub库里\n4. 过程中的改变\n   1. 将静态网站项目的文件夹内的.html、.sj、.css文件移动到同一个目录下，并创建assets文件夹用于后续存放图片字体等，最后在每一个项目文件夹里加入了.md的项目介绍文件\n   2. 在F盘中创建用于存放GitHub库的文件夹，并在里面创建blog文件夹用于存放与博客相关的内容，并把之前pynote1文件夹复制到该文件夹内，使得以后可以通过编写该文件夹内的文件来上传到GitHub库里\n\n## 今日总结\n1. ","slug":"2025-11-7","published":1,"updated":"2025-11-18T19:39:17.143Z","comments":1,"layout":"post","photos":[],"_id":"cuidloKlqBlP4oSpI85tIbDvC","content":"<h1 id=\"Overvirw\"><a href=\"#Overvirw\" class=\"headerlink\" title=\"Overvirw\"></a>Overvirw</h1><ol>\n<li>静态网站项目准备与学习</li>\n<li>今日总结</li>\n</ol>\n<h2 id=\"静态网站项目准备与学习\"><a href=\"#静态网站项目准备与学习\" class=\"headerlink\" title=\"静态网站项目准备与学习\"></a>静态网站项目准备与学习</h2><ol>\n<li>浏览器开发者工具的初步接触<ol>\n<li>首先在项目文件夹中调试.html文件，进入浏览器里的静态网页</li>\n<li>在浏览器中按 F12 来打开开发者工具</li>\n<li>用「源」选项卡编辑 JS 文件<br>点击开发者工具中的源代码 -&gt; 点击“+手动添加文件夹” -&gt; 选择项目文件夹打开并允许编辑文件 （这样就可以直接编辑外部.html、.js文件并保存（CTRL + S））<br><strong>注意</strong>：必须手动添加文件夹才能够编辑并保存文件内容</li>\n</ol>\n</li>\n<li>本地开发服务器<ol>\n<li>使用方法：使用Python内置服务器，在PyCharm的终端中输入：<br>python -m http.server 8000<br>之后就可以在服务器中通过http:&#x2F;&#x2F;协议访问对应的网页</li>\n<li>作用：在本地搭建一个简单的 Web 服务器，以便在开发静态页面（HTML&#x2F;CSS&#x2F;JavaScript）时进行本地预览<ol>\n<li>模拟线上环境，避免本地文件访问限制</li>\n<li>方便本地调试与实时预览</li>\n<li>为后续部署到 GitHub Pages 做验证</li>\n</ol>\n</li>\n<li><strong>注意</strong>：<ol>\n<li>每次想要打开本地服务器必须先在PyCharm的终端中执行上面的命令，否则打不开对应网页</li>\n<li>其实在PyCharm终端中执行的代码的本质是创建当前打开文件的本地服务器，所以想要打开必须要先打开对应项目文件夹再执行上面的代码</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>GitHub Desktop<ol>\n<li>下载GitHub Desktop，并登录GitHub账号，并克隆GitHub库到软件内</li>\n<li>使用方法：<ol>\n<li>可以通过本地电脑的文件操作或者PyCharm中修改文件后在GitHub Desktop软件内对该次改变进行描述并上传，就可以将改变推送到远程的GitHub库里</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>过程中的改变<ol>\n<li>将静态网站项目的文件夹内的.html、.sj、.css文件移动到同一个目录下，并创建assets文件夹用于后续存放图片字体等，最后在每一个项目文件夹里加入了.md的项目介绍文件</li>\n<li>在F盘中创建用于存放GitHub库的文件夹，并在里面创建blog文件夹用于存放与博客相关的内容，并把之前pynote1文件夹复制到该文件夹内，使得以后可以通过编写该文件夹内的文件来上传到GitHub库里</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"今日总结\"><a href=\"#今日总结\" class=\"headerlink\" title=\"今日总结\"></a>今日总结</h2><p>1. </p>\n","excerpt":"","more":"<h1 id=\"Overvirw\"><a href=\"#Overvirw\" class=\"headerlink\" title=\"Overvirw\"></a>Overvirw</h1><ol>\n<li>静态网站项目准备与学习</li>\n<li>今日总结</li>\n</ol>\n<h2 id=\"静态网站项目准备与学习\"><a href=\"#静态网站项目准备与学习\" class=\"headerlink\" title=\"静态网站项目准备与学习\"></a>静态网站项目准备与学习</h2><ol>\n<li>浏览器开发者工具的初步接触<ol>\n<li>首先在项目文件夹中调试.html文件，进入浏览器里的静态网页</li>\n<li>在浏览器中按 F12 来打开开发者工具</li>\n<li>用「源」选项卡编辑 JS 文件<br>点击开发者工具中的源代码 -&gt; 点击“+手动添加文件夹” -&gt; 选择项目文件夹打开并允许编辑文件 （这样就可以直接编辑外部.html、.js文件并保存（CTRL + S））<br><strong>注意</strong>：必须手动添加文件夹才能够编辑并保存文件内容</li>\n</ol>\n</li>\n<li>本地开发服务器<ol>\n<li>使用方法：使用Python内置服务器，在PyCharm的终端中输入：<br>python -m http.server 8000<br>之后就可以在服务器中通过http:&#x2F;&#x2F;协议访问对应的网页</li>\n<li>作用：在本地搭建一个简单的 Web 服务器，以便在开发静态页面（HTML&#x2F;CSS&#x2F;JavaScript）时进行本地预览<ol>\n<li>模拟线上环境，避免本地文件访问限制</li>\n<li>方便本地调试与实时预览</li>\n<li>为后续部署到 GitHub Pages 做验证</li>\n</ol>\n</li>\n<li><strong>注意</strong>：<ol>\n<li>每次想要打开本地服务器必须先在PyCharm的终端中执行上面的命令，否则打不开对应网页</li>\n<li>其实在PyCharm终端中执行的代码的本质是创建当前打开文件的本地服务器，所以想要打开必须要先打开对应项目文件夹再执行上面的代码</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>GitHub Desktop<ol>\n<li>下载GitHub Desktop，并登录GitHub账号，并克隆GitHub库到软件内</li>\n<li>使用方法：<ol>\n<li>可以通过本地电脑的文件操作或者PyCharm中修改文件后在GitHub Desktop软件内对该次改变进行描述并上传，就可以将改变推送到远程的GitHub库里</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>过程中的改变<ol>\n<li>将静态网站项目的文件夹内的.html、.sj、.css文件移动到同一个目录下，并创建assets文件夹用于后续存放图片字体等，最后在每一个项目文件夹里加入了.md的项目介绍文件</li>\n<li>在F盘中创建用于存放GitHub库的文件夹，并在里面创建blog文件夹用于存放与博客相关的内容，并把之前pynote1文件夹复制到该文件夹内，使得以后可以通过编写该文件夹内的文件来上传到GitHub库里</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"今日总结\"><a href=\"#今日总结\" class=\"headerlink\" title=\"今日总结\"></a>今日总结</h2><p>1. </p>\n"},{"title":"2025.11.3","date":"2025-11-03T00:35:40.000Z","_content":"# Overview\n1. 学习笔记\n2. 今日总结\n\n## 学习笔记\n\n### 概率\n1. 点估计\n   1. 核心定义  \n      1. 估计量（Estimator）：是样本X1、X2、··· 、Xn的函数（统计量），用于推断总体参数θ，如样本均值¬X = （X1+X2+···+Xn)/n是总体均值μ的估计量\n      2. 估计值（Estimate）：估计量在具体样本下的取值，如由观测值x1、x2、···、xn计算的¬x是μ的点估计值\n   2. 估计量的评估标准\n      1. 无偏估计（Unbiased Estimator）\n         1. 定义：若统计量¬Θ满足E[¬Θ]=θ，则¬Θ是θ的无偏估计量（估计量的期望等于真实参数）\n         2. 关键示例：样本方差S^2是总体方差σ^2的无偏估计量\n      2. 估计量的方差（Variance of an Estimator）\n         1. 核心原则：当¬Θ1和¬Θ2均为θ的无偏估计时，选择方差更小的估计量（抽样分布更集中，估计更精确）\n         2. 最有效估计（Most Efficient Estimator）：在所有θ的无偏估计中，方差最小的估计量\n         3. 示例结论：若三个估计量¬Θ1、¬Θ2、¬Θ3中，仅前两者无偏且¬Θ1方差更小，则¬Θ1是最优选择\n2. 区间估计\n   1. 基础概念\n      1. 区间估计定义：通过样本确定一个区间¬ΘL < Θ < ¬ΘU，其中¬ΘL（下边界）和¬ΘU（上边界）依赖于估计量的抽样分布，反映 “真实参数大概率落在该区间” 的范围\n      2. 置信区间（Confidence Interval）：\n         1. 定义：100(1−α)%置信区间表示 “长期重复抽样下，95%（如α=0.05）的此类区间会包含真实参数”\n         2. 关键误区：**不能说 “某具体区间含参数的概率是1−α”**，因为区间计算后是确定值，要么含参数要么不含；概率仅反映估计 procedure 的可靠性\n         3. 理想区间：短区间 + 高置信度（如 95% 置信区间[6,7]优于 99% 置信区间[3,10]）\n   2. 单样本估计总体均值μ（Single Sample: Estimating μ）\n      1. 场景 1：总体方差σ^2已知（大样本n≥30适用 CLT）\n         1. 抽样分布：由中心极限定理（CLT），¬X ∼ N(μ,σ^2/n)，标准化后Z = （¬X - μ） / σ/√n ∼ N（0,1）\n         2. 置信区间公式：¬x - z(α/2)·σ/√n < μ < ¬x + z(α/2)·σ/√n，其中z(α/2)是标准正态分布右侧面积为α/2的分位数（如 95% 置信度下z(0.025)= 1.96）\n      2. 场景 2：单 - sided 置信界（σ^2已知）\n         1. 适用场景：仅关注 “下界”（如钢棒抗拉强度）或 “上界”（如河流汞含量）\n         2. 公式：\n            1. 下置信界（95%）：μ > ¬x - z(α)·σ/√n\n            2. 上置信界（95%）：μ < ¬x + z(α)·σ/√n\n      3. 场景 3：总体方差σ^2未知（小样本n<30且总体正态）\n         1. 抽样分布：用样本标准差S替代σ，统计量 T = （¬X - μ） / S/√n ∼ t(n-1)（t 分布，自由度df=n−1）\n         2. 置信区间公式：¬x - t(α/2),(n-1)·S/√n < μ < ¬x + t(α/2),(n-1)·S/√n\n   3. 两样本估计总体均值差μ1−μ2（Two Samples: Estimating μ1−μ2）\n      1. 点估计：¬X1 - ¬X2（两样本均值差）\n      2. 三大场景对比：\n         | 场景 | 前提条件 | 抽样分布 | 关键参数 / 公式 |\n         | :---: | :---: | :---: | :---: |\n         | 场景 1：σ^2(1)、σ^2(2)已知 | 大样本（n1≥30，n2≥30），CLT 适用 | Z 分布 | 区间含 √（σ^2(1)/n1 + σ^2(2)/n2） |\n         | 场景 2：σ^2(1) = σ^2(2)未知 | 小样本，总体正态 | t 分布（df=n1+n2−2） | 合并方差 S^2(P) = （（n1-1）S^2(1) + （n2-1）S^2(2)） / n1+n2-2 | \n         | 场景 3：σ^2(1) != σ^2(2)未知| 小样本，总体正态 | t' 分布（df=v）| 自由度 v = （S^2(1)/n1 + S^2(2)/n2）^2 / （S^2(1)/n1）^2/n1-1 + （S^2(2)/n2）^2/n2-1，向下取整 |\n   4. 配对观测（Paired Observations）\n      1. 适用场景：\n         1. 同一单元接受两条件（如 15 人节食前后体重）\n         2. 配对单元接受两条件（如 IQ 相同的两人分属传统 / 新型教学班级）\n         3. 目的：消除 “单元间差异”（如汽车差异对轮胎磨损的影响），提高估计精度\n      2. 核心方法：将配对观测转化为 “差异样本”di = x(1i) - x(2i)，估计μD = μ1 - μ2（差异总体的均值）\n      3. 置信区间公式：\n         1. 小样本（n<30，di正态）：¬d ± t(α/2),(n-1)·Sd/√n\n         2. 大样本（n≥30）：用 Z 分布，¬d ± z(α/2)·Sd/√n\n   5. 单样本估计总体方差σ^2（Single Sample: Estimating σ^2）\n      1. 抽样分布：统计量 X^2 = （n-1）S^2 / σ^2 ∼ X^2(n-1)（X^2分布，自由度n−1），该分布非对称，分位数需区分X^2(α/2)和X^2(1 - α/2)\n      2. 置信区间公式：（n-1）s^2 / X^2(α/2),(n-1) < σ < （n-1）s^2 / X^2(1 - α/2),(n-1)\n   6. 两样本估计总体方差比σ^2(1)/σ^2(2)（Two Samples: Estimating σ^2(1)/σ^2(2)）\n      1. 点估计：s^2(1)/s^2(2)（两样本方差比）\n      2. 抽样分布：统计量 F = σ^2(2)S^2(1) / σ^2(1)S^2(2) ∼ F(n1-1),(n2-1)（F 分布，分子自由度n1−1，分母自由度n2−1），满足 f(1-α/2)（v1，v2） = 1 / f(α/2)（v2，v1）\n      3. 置信区间公式：S^2(1)/S^2(2) · 1/f(α/2)（n1-1，n2-1） < σ^2(1)/σ^2(2) < S^2(1)/S^2(2) · f(α/2)（n2-1，n1-1）\n      4. 核心用途：判断方差是否相等 —— 若区间不含 1，则认为σ^2(1) != σ^2(2)；含 1 则认为方差相等\n\n## 今日总结\n1. 今天参加的这周的城市之旅活动体验感非常好，首先把我之前探索的路线骑了一圈，然后我们去到了一个古镇上参观，最后还去到了长江边上，过程中聊天也挺开心的，希望以后也会这么开心\n2. 今天在结束了城市之旅活动后我还去参加了班级举办的羽毛球活动，在活动上认识了一个非常热情的朋友，即使活动结束后我们俩也聊了许久","source":"_posts/2025-11-3.md","raw":"---\ntitle: 2025.11.3\ndate: 2025-11-03 08:35:40\ntags:\n---\n# Overview\n1. 学习笔记\n2. 今日总结\n\n## 学习笔记\n\n### 概率\n1. 点估计\n   1. 核心定义  \n      1. 估计量（Estimator）：是样本X1、X2、··· 、Xn的函数（统计量），用于推断总体参数θ，如样本均值¬X = （X1+X2+···+Xn)/n是总体均值μ的估计量\n      2. 估计值（Estimate）：估计量在具体样本下的取值，如由观测值x1、x2、···、xn计算的¬x是μ的点估计值\n   2. 估计量的评估标准\n      1. 无偏估计（Unbiased Estimator）\n         1. 定义：若统计量¬Θ满足E[¬Θ]=θ，则¬Θ是θ的无偏估计量（估计量的期望等于真实参数）\n         2. 关键示例：样本方差S^2是总体方差σ^2的无偏估计量\n      2. 估计量的方差（Variance of an Estimator）\n         1. 核心原则：当¬Θ1和¬Θ2均为θ的无偏估计时，选择方差更小的估计量（抽样分布更集中，估计更精确）\n         2. 最有效估计（Most Efficient Estimator）：在所有θ的无偏估计中，方差最小的估计量\n         3. 示例结论：若三个估计量¬Θ1、¬Θ2、¬Θ3中，仅前两者无偏且¬Θ1方差更小，则¬Θ1是最优选择\n2. 区间估计\n   1. 基础概念\n      1. 区间估计定义：通过样本确定一个区间¬ΘL < Θ < ¬ΘU，其中¬ΘL（下边界）和¬ΘU（上边界）依赖于估计量的抽样分布，反映 “真实参数大概率落在该区间” 的范围\n      2. 置信区间（Confidence Interval）：\n         1. 定义：100(1−α)%置信区间表示 “长期重复抽样下，95%（如α=0.05）的此类区间会包含真实参数”\n         2. 关键误区：**不能说 “某具体区间含参数的概率是1−α”**，因为区间计算后是确定值，要么含参数要么不含；概率仅反映估计 procedure 的可靠性\n         3. 理想区间：短区间 + 高置信度（如 95% 置信区间[6,7]优于 99% 置信区间[3,10]）\n   2. 单样本估计总体均值μ（Single Sample: Estimating μ）\n      1. 场景 1：总体方差σ^2已知（大样本n≥30适用 CLT）\n         1. 抽样分布：由中心极限定理（CLT），¬X ∼ N(μ,σ^2/n)，标准化后Z = （¬X - μ） / σ/√n ∼ N（0,1）\n         2. 置信区间公式：¬x - z(α/2)·σ/√n < μ < ¬x + z(α/2)·σ/√n，其中z(α/2)是标准正态分布右侧面积为α/2的分位数（如 95% 置信度下z(0.025)= 1.96）\n      2. 场景 2：单 - sided 置信界（σ^2已知）\n         1. 适用场景：仅关注 “下界”（如钢棒抗拉强度）或 “上界”（如河流汞含量）\n         2. 公式：\n            1. 下置信界（95%）：μ > ¬x - z(α)·σ/√n\n            2. 上置信界（95%）：μ < ¬x + z(α)·σ/√n\n      3. 场景 3：总体方差σ^2未知（小样本n<30且总体正态）\n         1. 抽样分布：用样本标准差S替代σ，统计量 T = （¬X - μ） / S/√n ∼ t(n-1)（t 分布，自由度df=n−1）\n         2. 置信区间公式：¬x - t(α/2),(n-1)·S/√n < μ < ¬x + t(α/2),(n-1)·S/√n\n   3. 两样本估计总体均值差μ1−μ2（Two Samples: Estimating μ1−μ2）\n      1. 点估计：¬X1 - ¬X2（两样本均值差）\n      2. 三大场景对比：\n         | 场景 | 前提条件 | 抽样分布 | 关键参数 / 公式 |\n         | :---: | :---: | :---: | :---: |\n         | 场景 1：σ^2(1)、σ^2(2)已知 | 大样本（n1≥30，n2≥30），CLT 适用 | Z 分布 | 区间含 √（σ^2(1)/n1 + σ^2(2)/n2） |\n         | 场景 2：σ^2(1) = σ^2(2)未知 | 小样本，总体正态 | t 分布（df=n1+n2−2） | 合并方差 S^2(P) = （（n1-1）S^2(1) + （n2-1）S^2(2)） / n1+n2-2 | \n         | 场景 3：σ^2(1) != σ^2(2)未知| 小样本，总体正态 | t' 分布（df=v）| 自由度 v = （S^2(1)/n1 + S^2(2)/n2）^2 / （S^2(1)/n1）^2/n1-1 + （S^2(2)/n2）^2/n2-1，向下取整 |\n   4. 配对观测（Paired Observations）\n      1. 适用场景：\n         1. 同一单元接受两条件（如 15 人节食前后体重）\n         2. 配对单元接受两条件（如 IQ 相同的两人分属传统 / 新型教学班级）\n         3. 目的：消除 “单元间差异”（如汽车差异对轮胎磨损的影响），提高估计精度\n      2. 核心方法：将配对观测转化为 “差异样本”di = x(1i) - x(2i)，估计μD = μ1 - μ2（差异总体的均值）\n      3. 置信区间公式：\n         1. 小样本（n<30，di正态）：¬d ± t(α/2),(n-1)·Sd/√n\n         2. 大样本（n≥30）：用 Z 分布，¬d ± z(α/2)·Sd/√n\n   5. 单样本估计总体方差σ^2（Single Sample: Estimating σ^2）\n      1. 抽样分布：统计量 X^2 = （n-1）S^2 / σ^2 ∼ X^2(n-1)（X^2分布，自由度n−1），该分布非对称，分位数需区分X^2(α/2)和X^2(1 - α/2)\n      2. 置信区间公式：（n-1）s^2 / X^2(α/2),(n-1) < σ < （n-1）s^2 / X^2(1 - α/2),(n-1)\n   6. 两样本估计总体方差比σ^2(1)/σ^2(2)（Two Samples: Estimating σ^2(1)/σ^2(2)）\n      1. 点估计：s^2(1)/s^2(2)（两样本方差比）\n      2. 抽样分布：统计量 F = σ^2(2)S^2(1) / σ^2(1)S^2(2) ∼ F(n1-1),(n2-1)（F 分布，分子自由度n1−1，分母自由度n2−1），满足 f(1-α/2)（v1，v2） = 1 / f(α/2)（v2，v1）\n      3. 置信区间公式：S^2(1)/S^2(2) · 1/f(α/2)（n1-1，n2-1） < σ^2(1)/σ^2(2) < S^2(1)/S^2(2) · f(α/2)（n2-1，n1-1）\n      4. 核心用途：判断方差是否相等 —— 若区间不含 1，则认为σ^2(1) != σ^2(2)；含 1 则认为方差相等\n\n## 今日总结\n1. 今天参加的这周的城市之旅活动体验感非常好，首先把我之前探索的路线骑了一圈，然后我们去到了一个古镇上参观，最后还去到了长江边上，过程中聊天也挺开心的，希望以后也会这么开心\n2. 今天在结束了城市之旅活动后我还去参加了班级举办的羽毛球活动，在活动上认识了一个非常热情的朋友，即使活动结束后我们俩也聊了许久","slug":"2025-11-3","published":1,"updated":"2025-11-18T19:39:17.149Z","comments":1,"layout":"post","photos":[],"_id":"cuid8jw7xBOziFb6M_JA7CCOp","content":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>学习笔记</li>\n<li>今日总结</li>\n</ol>\n<h2 id=\"学习笔记\"><a href=\"#学习笔记\" class=\"headerlink\" title=\"学习笔记\"></a>学习笔记</h2><h3 id=\"概率\"><a href=\"#概率\" class=\"headerlink\" title=\"概率\"></a>概率</h3><ol>\n<li>点估计<ol>\n<li>核心定义  <ol>\n<li>估计量（Estimator）：是样本X1、X2、··· 、Xn的函数（统计量），用于推断总体参数θ，如样本均值¬X &#x3D; （X1+X2+···+Xn)&#x2F;n是总体均值μ的估计量</li>\n<li>估计值（Estimate）：估计量在具体样本下的取值，如由观测值x1、x2、···、xn计算的¬x是μ的点估计值</li>\n</ol>\n</li>\n<li>估计量的评估标准<ol>\n<li>无偏估计（Unbiased Estimator）<ol>\n<li>定义：若统计量¬Θ满足E[¬Θ]&#x3D;θ，则¬Θ是θ的无偏估计量（估计量的期望等于真实参数）</li>\n<li>关键示例：样本方差S^2是总体方差σ^2的无偏估计量</li>\n</ol>\n</li>\n<li>估计量的方差（Variance of an Estimator）<ol>\n<li>核心原则：当¬Θ1和¬Θ2均为θ的无偏估计时，选择方差更小的估计量（抽样分布更集中，估计更精确）</li>\n<li>最有效估计（Most Efficient Estimator）：在所有θ的无偏估计中，方差最小的估计量</li>\n<li>示例结论：若三个估计量¬Θ1、¬Θ2、¬Θ3中，仅前两者无偏且¬Θ1方差更小，则¬Θ1是最优选择</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>区间估计<ol>\n<li>基础概念<ol>\n<li>区间估计定义：通过样本确定一个区间¬ΘL &lt; Θ &lt; ¬ΘU，其中¬ΘL（下边界）和¬ΘU（上边界）依赖于估计量的抽样分布，反映 “真实参数大概率落在该区间” 的范围</li>\n<li>置信区间（Confidence Interval）：<ol>\n<li>定义：100(1−α)%置信区间表示 “长期重复抽样下，95%（如α&#x3D;0.05）的此类区间会包含真实参数”</li>\n<li>关键误区：<strong>不能说 “某具体区间含参数的概率是1−α”</strong>，因为区间计算后是确定值，要么含参数要么不含；概率仅反映估计 procedure 的可靠性</li>\n<li>理想区间：短区间 + 高置信度（如 95% 置信区间[6,7]优于 99% 置信区间[3,10]）</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>单样本估计总体均值μ（Single Sample: Estimating μ）<ol>\n<li>场景 1：总体方差σ^2已知（大样本n≥30适用 CLT）<ol>\n<li>抽样分布：由中心极限定理（CLT），¬X ∼ N(μ,σ^2&#x2F;n)，标准化后Z &#x3D; （¬X - μ） &#x2F; σ&#x2F;√n ∼ N（0,1）</li>\n<li>置信区间公式：¬x - z(α&#x2F;2)·σ&#x2F;√n &lt; μ &lt; ¬x + z(α&#x2F;2)·σ&#x2F;√n，其中z(α&#x2F;2)是标准正态分布右侧面积为α&#x2F;2的分位数（如 95% 置信度下z(0.025)&#x3D; 1.96）</li>\n</ol>\n</li>\n<li>场景 2：单 - sided 置信界（σ^2已知）<ol>\n<li>适用场景：仅关注 “下界”（如钢棒抗拉强度）或 “上界”（如河流汞含量）</li>\n<li>公式：<ol>\n<li>下置信界（95%）：μ &gt; ¬x - z(α)·σ&#x2F;√n</li>\n<li>上置信界（95%）：μ &lt; ¬x + z(α)·σ&#x2F;√n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>场景 3：总体方差σ^2未知（小样本n&lt;30且总体正态）<ol>\n<li>抽样分布：用样本标准差S替代σ，统计量 T &#x3D; （¬X - μ） &#x2F; S&#x2F;√n ∼ t(n-1)（t 分布，自由度df&#x3D;n−1）</li>\n<li>置信区间公式：¬x - t(α&#x2F;2),(n-1)·S&#x2F;√n &lt; μ &lt; ¬x + t(α&#x2F;2),(n-1)·S&#x2F;√n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>两样本估计总体均值差μ1−μ2（Two Samples: Estimating μ1−μ2）<ol>\n<li>点估计：¬X1 - ¬X2（两样本均值差）</li>\n<li>三大场景对比：<table>\n<thead>\n<tr>\n<th align=\"center\">场景</th>\n<th align=\"center\">前提条件</th>\n<th align=\"center\">抽样分布</th>\n<th align=\"center\">关键参数 &#x2F; 公式</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">场景 1：σ^2(1)、σ^2(2)已知</td>\n<td align=\"center\">大样本（n1≥30，n2≥30），CLT 适用</td>\n<td align=\"center\">Z 分布</td>\n<td align=\"center\">区间含 √（σ^2(1)&#x2F;n1 + σ^2(2)&#x2F;n2）</td>\n</tr>\n<tr>\n<td align=\"center\">场景 2：σ^2(1) &#x3D; σ^2(2)未知</td>\n<td align=\"center\">小样本，总体正态</td>\n<td align=\"center\">t 分布（df&#x3D;n1+n2−2）</td>\n<td align=\"center\">合并方差 S^2(P) &#x3D; （（n1-1）S^2(1) + （n2-1）S^2(2)） &#x2F; n1+n2-2</td>\n</tr>\n<tr>\n<td align=\"center\">场景 3：σ^2(1) !&#x3D; σ^2(2)未知</td>\n<td align=\"center\">小样本，总体正态</td>\n<td align=\"center\">t’ 分布（df&#x3D;v）</td>\n<td align=\"center\">自由度 v &#x3D; （S^2(1)&#x2F;n1 + S^2(2)&#x2F;n2）^2 &#x2F; （S^2(1)&#x2F;n1）^2&#x2F;n1-1 + （S^2(2)&#x2F;n2）^2&#x2F;n2-1，向下取整</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n</li>\n<li>配对观测（Paired Observations）<ol>\n<li>适用场景：<ol>\n<li>同一单元接受两条件（如 15 人节食前后体重）</li>\n<li>配对单元接受两条件（如 IQ 相同的两人分属传统 &#x2F; 新型教学班级）</li>\n<li>目的：消除 “单元间差异”（如汽车差异对轮胎磨损的影响），提高估计精度</li>\n</ol>\n</li>\n<li>核心方法：将配对观测转化为 “差异样本”di &#x3D; x(1i) - x(2i)，估计μD &#x3D; μ1 - μ2（差异总体的均值）</li>\n<li>置信区间公式：<ol>\n<li>小样本（n&lt;30，di正态）：¬d ± t(α&#x2F;2),(n-1)·Sd&#x2F;√n</li>\n<li>大样本（n≥30）：用 Z 分布，¬d ± z(α&#x2F;2)·Sd&#x2F;√n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>单样本估计总体方差σ^2（Single Sample: Estimating σ^2）<ol>\n<li>抽样分布：统计量 X^2 &#x3D; （n-1）S^2 &#x2F; σ^2 ∼ X^2(n-1)（X^2分布，自由度n−1），该分布非对称，分位数需区分X^2(α&#x2F;2)和X^2(1 - α&#x2F;2)</li>\n<li>置信区间公式：（n-1）s^2 &#x2F; X^2(α&#x2F;2),(n-1) &lt; σ &lt; （n-1）s^2 &#x2F; X^2(1 - α&#x2F;2),(n-1)</li>\n</ol>\n</li>\n<li>两样本估计总体方差比σ^2(1)&#x2F;σ^2(2)（Two Samples: Estimating σ^2(1)&#x2F;σ^2(2)）<ol>\n<li>点估计：s^2(1)&#x2F;s^2(2)（两样本方差比）</li>\n<li>抽样分布：统计量 F &#x3D; σ^2(2)S^2(1) &#x2F; σ^2(1)S^2(2) ∼ F(n1-1),(n2-1)（F 分布，分子自由度n1−1，分母自由度n2−1），满足 f(1-α&#x2F;2)（v1，v2） &#x3D; 1 &#x2F; f(α&#x2F;2)（v2，v1）</li>\n<li>置信区间公式：S^2(1)&#x2F;S^2(2) · 1&#x2F;f(α&#x2F;2)（n1-1，n2-1） &lt; σ^2(1)&#x2F;σ^2(2) &lt; S^2(1)&#x2F;S^2(2) · f(α&#x2F;2)（n2-1，n1-1）</li>\n<li>核心用途：判断方差是否相等 —— 若区间不含 1，则认为σ^2(1) !&#x3D; σ^2(2)；含 1 则认为方差相等</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"今日总结\"><a href=\"#今日总结\" class=\"headerlink\" title=\"今日总结\"></a>今日总结</h2><ol>\n<li>今天参加的这周的城市之旅活动体验感非常好，首先把我之前探索的路线骑了一圈，然后我们去到了一个古镇上参观，最后还去到了长江边上，过程中聊天也挺开心的，希望以后也会这么开心</li>\n<li>今天在结束了城市之旅活动后我还去参加了班级举办的羽毛球活动，在活动上认识了一个非常热情的朋友，即使活动结束后我们俩也聊了许久</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>学习笔记</li>\n<li>今日总结</li>\n</ol>\n<h2 id=\"学习笔记\"><a href=\"#学习笔记\" class=\"headerlink\" title=\"学习笔记\"></a>学习笔记</h2><h3 id=\"概率\"><a href=\"#概率\" class=\"headerlink\" title=\"概率\"></a>概率</h3><ol>\n<li>点估计<ol>\n<li>核心定义  <ol>\n<li>估计量（Estimator）：是样本X1、X2、··· 、Xn的函数（统计量），用于推断总体参数θ，如样本均值¬X &#x3D; （X1+X2+···+Xn)&#x2F;n是总体均值μ的估计量</li>\n<li>估计值（Estimate）：估计量在具体样本下的取值，如由观测值x1、x2、···、xn计算的¬x是μ的点估计值</li>\n</ol>\n</li>\n<li>估计量的评估标准<ol>\n<li>无偏估计（Unbiased Estimator）<ol>\n<li>定义：若统计量¬Θ满足E[¬Θ]&#x3D;θ，则¬Θ是θ的无偏估计量（估计量的期望等于真实参数）</li>\n<li>关键示例：样本方差S^2是总体方差σ^2的无偏估计量</li>\n</ol>\n</li>\n<li>估计量的方差（Variance of an Estimator）<ol>\n<li>核心原则：当¬Θ1和¬Θ2均为θ的无偏估计时，选择方差更小的估计量（抽样分布更集中，估计更精确）</li>\n<li>最有效估计（Most Efficient Estimator）：在所有θ的无偏估计中，方差最小的估计量</li>\n<li>示例结论：若三个估计量¬Θ1、¬Θ2、¬Θ3中，仅前两者无偏且¬Θ1方差更小，则¬Θ1是最优选择</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>区间估计<ol>\n<li>基础概念<ol>\n<li>区间估计定义：通过样本确定一个区间¬ΘL &lt; Θ &lt; ¬ΘU，其中¬ΘL（下边界）和¬ΘU（上边界）依赖于估计量的抽样分布，反映 “真实参数大概率落在该区间” 的范围</li>\n<li>置信区间（Confidence Interval）：<ol>\n<li>定义：100(1−α)%置信区间表示 “长期重复抽样下，95%（如α&#x3D;0.05）的此类区间会包含真实参数”</li>\n<li>关键误区：<strong>不能说 “某具体区间含参数的概率是1−α”</strong>，因为区间计算后是确定值，要么含参数要么不含；概率仅反映估计 procedure 的可靠性</li>\n<li>理想区间：短区间 + 高置信度（如 95% 置信区间[6,7]优于 99% 置信区间[3,10]）</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>单样本估计总体均值μ（Single Sample: Estimating μ）<ol>\n<li>场景 1：总体方差σ^2已知（大样本n≥30适用 CLT）<ol>\n<li>抽样分布：由中心极限定理（CLT），¬X ∼ N(μ,σ^2&#x2F;n)，标准化后Z &#x3D; （¬X - μ） &#x2F; σ&#x2F;√n ∼ N（0,1）</li>\n<li>置信区间公式：¬x - z(α&#x2F;2)·σ&#x2F;√n &lt; μ &lt; ¬x + z(α&#x2F;2)·σ&#x2F;√n，其中z(α&#x2F;2)是标准正态分布右侧面积为α&#x2F;2的分位数（如 95% 置信度下z(0.025)&#x3D; 1.96）</li>\n</ol>\n</li>\n<li>场景 2：单 - sided 置信界（σ^2已知）<ol>\n<li>适用场景：仅关注 “下界”（如钢棒抗拉强度）或 “上界”（如河流汞含量）</li>\n<li>公式：<ol>\n<li>下置信界（95%）：μ &gt; ¬x - z(α)·σ&#x2F;√n</li>\n<li>上置信界（95%）：μ &lt; ¬x + z(α)·σ&#x2F;√n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>场景 3：总体方差σ^2未知（小样本n&lt;30且总体正态）<ol>\n<li>抽样分布：用样本标准差S替代σ，统计量 T &#x3D; （¬X - μ） &#x2F; S&#x2F;√n ∼ t(n-1)（t 分布，自由度df&#x3D;n−1）</li>\n<li>置信区间公式：¬x - t(α&#x2F;2),(n-1)·S&#x2F;√n &lt; μ &lt; ¬x + t(α&#x2F;2),(n-1)·S&#x2F;√n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>两样本估计总体均值差μ1−μ2（Two Samples: Estimating μ1−μ2）<ol>\n<li>点估计：¬X1 - ¬X2（两样本均值差）</li>\n<li>三大场景对比：<table>\n<thead>\n<tr>\n<th align=\"center\">场景</th>\n<th align=\"center\">前提条件</th>\n<th align=\"center\">抽样分布</th>\n<th align=\"center\">关键参数 &#x2F; 公式</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">场景 1：σ^2(1)、σ^2(2)已知</td>\n<td align=\"center\">大样本（n1≥30，n2≥30），CLT 适用</td>\n<td align=\"center\">Z 分布</td>\n<td align=\"center\">区间含 √（σ^2(1)&#x2F;n1 + σ^2(2)&#x2F;n2）</td>\n</tr>\n<tr>\n<td align=\"center\">场景 2：σ^2(1) &#x3D; σ^2(2)未知</td>\n<td align=\"center\">小样本，总体正态</td>\n<td align=\"center\">t 分布（df&#x3D;n1+n2−2）</td>\n<td align=\"center\">合并方差 S^2(P) &#x3D; （（n1-1）S^2(1) + （n2-1）S^2(2)） &#x2F; n1+n2-2</td>\n</tr>\n<tr>\n<td align=\"center\">场景 3：σ^2(1) !&#x3D; σ^2(2)未知</td>\n<td align=\"center\">小样本，总体正态</td>\n<td align=\"center\">t’ 分布（df&#x3D;v）</td>\n<td align=\"center\">自由度 v &#x3D; （S^2(1)&#x2F;n1 + S^2(2)&#x2F;n2）^2 &#x2F; （S^2(1)&#x2F;n1）^2&#x2F;n1-1 + （S^2(2)&#x2F;n2）^2&#x2F;n2-1，向下取整</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n</li>\n<li>配对观测（Paired Observations）<ol>\n<li>适用场景：<ol>\n<li>同一单元接受两条件（如 15 人节食前后体重）</li>\n<li>配对单元接受两条件（如 IQ 相同的两人分属传统 &#x2F; 新型教学班级）</li>\n<li>目的：消除 “单元间差异”（如汽车差异对轮胎磨损的影响），提高估计精度</li>\n</ol>\n</li>\n<li>核心方法：将配对观测转化为 “差异样本”di &#x3D; x(1i) - x(2i)，估计μD &#x3D; μ1 - μ2（差异总体的均值）</li>\n<li>置信区间公式：<ol>\n<li>小样本（n&lt;30，di正态）：¬d ± t(α&#x2F;2),(n-1)·Sd&#x2F;√n</li>\n<li>大样本（n≥30）：用 Z 分布，¬d ± z(α&#x2F;2)·Sd&#x2F;√n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>单样本估计总体方差σ^2（Single Sample: Estimating σ^2）<ol>\n<li>抽样分布：统计量 X^2 &#x3D; （n-1）S^2 &#x2F; σ^2 ∼ X^2(n-1)（X^2分布，自由度n−1），该分布非对称，分位数需区分X^2(α&#x2F;2)和X^2(1 - α&#x2F;2)</li>\n<li>置信区间公式：（n-1）s^2 &#x2F; X^2(α&#x2F;2),(n-1) &lt; σ &lt; （n-1）s^2 &#x2F; X^2(1 - α&#x2F;2),(n-1)</li>\n</ol>\n</li>\n<li>两样本估计总体方差比σ^2(1)&#x2F;σ^2(2)（Two Samples: Estimating σ^2(1)&#x2F;σ^2(2)）<ol>\n<li>点估计：s^2(1)&#x2F;s^2(2)（两样本方差比）</li>\n<li>抽样分布：统计量 F &#x3D; σ^2(2)S^2(1) &#x2F; σ^2(1)S^2(2) ∼ F(n1-1),(n2-1)（F 分布，分子自由度n1−1，分母自由度n2−1），满足 f(1-α&#x2F;2)（v1，v2） &#x3D; 1 &#x2F; f(α&#x2F;2)（v2，v1）</li>\n<li>置信区间公式：S^2(1)&#x2F;S^2(2) · 1&#x2F;f(α&#x2F;2)（n1-1，n2-1） &lt; σ^2(1)&#x2F;σ^2(2) &lt; S^2(1)&#x2F;S^2(2) · f(α&#x2F;2)（n2-1，n1-1）</li>\n<li>核心用途：判断方差是否相等 —— 若区间不含 1，则认为σ^2(1) !&#x3D; σ^2(2)；含 1 则认为方差相等</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"今日总结\"><a href=\"#今日总结\" class=\"headerlink\" title=\"今日总结\"></a>今日总结</h2><ol>\n<li>今天参加的这周的城市之旅活动体验感非常好，首先把我之前探索的路线骑了一圈，然后我们去到了一个古镇上参观，最后还去到了长江边上，过程中聊天也挺开心的，希望以后也会这么开心</li>\n<li>今天在结束了城市之旅活动后我还去参加了班级举办的羽毛球活动，在活动上认识了一个非常热情的朋友，即使活动结束后我们俩也聊了许久</li>\n</ol>\n"},{"title":"2025.11.5","date":"2025-11-05T07:01:48.000Z","_content":"# Overview\n1. 昨日总结\n2. 学习笔记\n3. 今日总结\n\n## 昨日总结\n1. 昨天去看牙了，最后拔掉了一颗智齿，还是比想象中轻松的，虽然到了晚上会有点疼但是可以忍受\n2. 昨天在中途休息的时候去到了一家特别大的书店，在里面逛了一圈后我买了6本书，并且成功用一天的时间看完了一本《追逐繁星的孩子》，接下来也要继续多多看书\n3. 晚上继续带摩羯出去锻炼胆量，明显还是一到外面的环境里就害怕\n\n## 学习笔记\n\n### 计算机体系结构与操作系统\n1. 数制系统\n   1. 核心概念：数制是表示数字的 “规则”，计算机底层仅能识别二进制（0 和 1），但为了简化表示，会用到十进制（日常使用）和十六进制（简化二进制书写）\n   2. 二进制转十进制：按权展开法  \n      二进制数的每一位都有 “权重”，权重为 2 的 “位数 - 1” 次方（从右往左，位数从 0 开始）。将每一位数字乘以对应权重，再求和，即可得到十进制数。\n   3. 十进制转二进制：除 2 取余法  \n      将十进制数反复除以 2，记录每次的余数（余数为 0 或 1），最后将余数从后往前排列，即可得到二进制数。\n   4. 二进制与十六进制转换：十六进制的 1 位对应二进制的 4 位（因为 16=2⁴），转换时只需将二进制数按 4 位分组（不足 4 位补 0），再将每组转换为对应的十六进制数即可\n2. 逻辑门：数字电路的 “基本积木”\n   1. 单输入逻辑门\n      1. NOT 门（非门）：功能是 “取反”，输入为 0 时输出 1，输入为 1 时输出 0。\n      2. 缓冲器（BUF）：功能是 “保持输入”，输入为 0 时输出 0，输入为 1 时输出 1（相当于 “无操作”，主要用于增强信号）\n   2. 双输入逻辑门：核心双输入逻辑门的功能：\n      | 逻辑门类型 | 功能描述 | 逻辑表达式 |\n      | :---: | :---:| :---: |\n      | AND 门（与门） | 只有 A、B 都为 1 时，Y 才为 1 | Y=A・B（“・” 表示与） |\n      | OR 门（或门） | A、B 只要有一个为 1，Y 就为 1 | Y=A+B（“+” 表示或） |\t\n      | XOR 门（异或门） | A、B 不同时，Y 为 1；相同为 0 | Y=A⊕B\t|\n      | NAND 门（与非门） | 只有 A、B 都为 1 时，Y 为 0（AND 门取反） | Y=¬(A·B) |\n      | NOR 门（或非门） | A、B 只要有一个为 1，Y 就为 0（OR 门取反） | Y=¬(A+B) | \n3. 组合逻辑电路\n   1. 核心定义：组合逻辑电路是由多个逻辑门组成的电路，**无记忆功能**—— 输出仅由当前输入决定，与过去的输入无关\n   2.  电路组成与描述方式：  \n       描述组合逻辑电路的核心方式是 “布尔方程”—— 用逻辑运算符（・、+、¬）表示输入与输出的关系  \n       组合逻辑电路的组成包括三部分：\n       1. 输入：外部信号来源（如传感器信号，用 A、B、C 等变量表示）\n       2. 内部节点：电路中间的信号节点（如多个门之间的连接点，用 n1、n2 等表示）\n       3. 输出：电路最终的信号（如机器启动信号，用 Y、Z 等变量表示）\n4. 布尔代数\n   1. 核心定义：布尔代数是描述逻辑关系的 “数学工具”，变量仅取值 0 或 1（对应假和真），运算包括与（・）、或（+）、非（¬），主要用于简化布尔方程（减少逻辑门数量，降低电路成本）\n   2. 核心公理（基础规则，无需证明）  \n       布尔代数的公理是推导所有定理的基础，核心公理及对偶公理（将 “・” 与 “+” 互换、0 与 1 互换，公理仍成立）如下表：\n      | 公理编号 | 公理内容 | 对偶公理（A'） | 含义说明 |\n      | :---: | :---: | :---: | :---: |\n      | A1（二进制域） | B=0，若 B≠1\t | B=1，若 B≠0 | 变量仅取 0 或 1（二进制域） |\n      | A2（非运算（NOT）） | ¬0=1 | ¬1=0 | 非运算的基本规则 |\n      | A3（与 / 或运算（AND/OR）） | 0·0=0 | 1+1=1 | 与 / 或运算的边界情况 |\n      | A4（与 / 或运算（AND/OR）） | 1·1=1 | 0+0=0 | 与 / 或运算的边界情况 |\n      | A5（与 / 或运算（AND/OR）） | 0·1=1·0=0 | 1+0=0+1=1 | 与 / 或运算的交换性边界情况 |\n   3. 核心定理（可通过公理推导，需记忆）  \n      布尔代数的定理是简化方程的关键，常用定理及对偶定理如下表（B、C、D 为布尔变量）：\n      | 定理名 | 定理内容 | 对偶定理（T'） | 含义说明 |\n      | :---: | :---: | :---: | :---: |\n      | Identity Theorem（同一律） | B·1=B；B+0=B | B+1=1；B·0=0 | 与 1 相乘 / 或 0 相加，结果不变 |\n      | Null Element Theorem（零律） | B·0=0；B+1=1 | B+0=0；B·1=1 | 与 0 相乘 / 或 1 相加，结果为 0/1 |\n      | Idempotency Theorem（幂等律） | B·B=B；B+B=B | B+B=B；B·B=B | 与 / 或自身，结果不变 |\n      | Involution Theorem（对合律） | ¬(¬B)=B | ¬(¬B)=B | 两次非运算，结果还原 |\n      | Complement theorem（互补律） | B·¬B=0；B+¬B=1 | B+¬B=1；B·¬B=0 | 与自身非相乘为 0，相加为 1 |\n      | Commutativity（交换律） | B·C=C·B；B+C=C+B | B+C=C+B；B·C=C·B | 与 / 或运算的顺序不影响结果 |\n      | Associativity（结合律） | (B·C)·D=B·(C·D)；(B+C)+D=B+(C+D) | (B+C)+D=B+(C+D)；(B·C)·D=B·(C·D) | 与 / 或运算的分组不影响结果 |\n      | Distributivity（分配律） | B·(C+D)=B·C+B·D；B+C·D=(B+C)·(B+D) | B+(C·D)=(B+C)·(B+D)；B·(C+D)=B·C+B·D | 与对或 / 或对与的分配规则 |\n      | Covering（覆盖律） | B·(B+C)=B；B+(B·C)=B | B+(B·C)=B；B·(B+C)=B | 变量与自身和 / 积，结果为自身 |\n      | Combining（合并律） | B·C+B·¬C=B；(B+C)·(B+¬C)=B | (B+C)·(B+¬C)=B；B·C+B·¬C=B | 提取相同变量，合并不同变量 |\n      | Consensus（共识律） | B·C+¬B·D+C·D=B·C+¬B·D；(B+C)·(¬B+D)·(C+D)=(B+C)·(¬B+D) | (B+C)·(¬B+D)·(C+D)=(B+C)·(¬B+D)；B·C+¬B·D+C·D=B·C+¬B·D | 消除冗余的共识项 |\n      | De Morgan's Theorem（德摩根定律） | ¬(B·C)=¬B+¬C；¬(B+C)=¬B·¬C | ¬(B+C)=¬B·¬C；¬(B·C)=¬B+¬C | 与的非等于非的或，或的非等于非的与 |\n5. 数字构建块\n   1. 组合逻辑电路\n      1. 核心特性：无记忆功能，输出仅由当前输入决定，包含输入（如 A、B、C）、输出（如 Y、Z）和内部节点（如 n1），通过电路元素（E1、E2、E3）实现逻辑关系，可用布尔方程描述（如 n1=E1 (A,B)、Z=E2 (A,C)、Y=E3 (n1,B,Z)）\n      2. 常用组件：\n         1. 多路复用器（Mux）：从 N 个输入中选择 1 个输出，需log(2)N位选择信号（S）。以 2:1 Mux 为例，选择信号 S=0 时输出 D0，S=1 时输出 D1，其真值表如下：\n            | S | D1 | D0 | Y |\n            | :---: | :---: | :---: | :---: |\n            | 0 | 0 | 0 | 0 |\n            | 0 | 0 | 1 | 1 |\n            | 0 | 1 | 0 | 0 |\n            | 0 | 1 | 1 | 1 |\n            | 1 | 0 | 0 | 0 |\n            | 1 | 0 | 1 | 0 |\n            | 1 | 1 | 0 | 1 |\n            | 1 | 1 | 1 | 1 |\n         2. 解码器：N 个输入对应2^N个输出，采用 “独热编码”（仅 1 个输出为高电平）。以 2:4 Decoder 为例，输入 A1、A0 控制输出 Y3-Y0，真值表关键逻辑为：A1A0=00 → Y0=1；A1A0=01 → Y1=1；A1A0 = 10 → Y2=1；A1A0=11 → Y3=1\n         3. 移位器：分三类，具体功能及示例（输入 11001）如下：\n            | 类型 | 功能 | 示例（输入 11001） |\n            | :---: | :---: | :---: |\n            | 逻辑移位器 | 左右移位，空位补 0 | 右移 2 位：11001>>2=00110；左移 2 位：11001<<2=00100 |\n            | 算术移位器 | 左移同逻辑移位，右移空位补最高有效位（MSB） | 右移 2 位：11001>>>2=11110；左移 2 位：11001<<<2=00100 |\n            | 旋转移位器 | 循环移位，移出位补到另一端 | 右旋转 2 位：11001 ROR 2=01110；左旋转 2 位：11001 ROL 2=00111 |\n   2. 时序逻辑电路\n      1. 核心特性：有短期记忆功能，通过输出到输入的反馈存储信息，能为事件提供时序顺序\n      2. 基础电路：双稳态电路，可存储 1 位状态（Q），存在两种稳定状态：Q=0 时¬Q=1；Q=1 时¬Q=0，但无输入控制状态\n      3. 常用组件\n         1. S-R 锁存器：含置位（S）、复位（R）输入，四种工作状态如下：\n            1. S=1、R=0：置位，Q=1、¬Q=0\n            2. S=0、R=1：复位，Q=0、¬Q=1\n            3. S=0、R=0：保持，Q=Q_prev（前一状态）\n            4. S=1、R=1：**无效**，Q=0、¬Q=0（Q≠¬Q）\n         2. D 锁存器：含时钟（CLK）、数据（D）输入，`避免 S-R 锁存器的无效状态`：\n            1. CLK=1：透明模式，D 直接传递到 Q\n            2. CLK=0：不透明模式，Q 保持前一状态（Q_prev）\n         3. D 触发器：边沿触发（仅时钟上升沿有效），输入为 CLK 和 D\n            1. 时钟从 0→1（上升沿）：采样 D 值并传递到 Q\n            2. 其他时刻：Q 保持前一状态，仅在上升沿变化\n6. 算术组件\n   1. 加法器\n      1. 半加器：仅处理 2 位输入（A、B），输出和（S）与进位输出（Cout），真值表如下：\n         | A | B | Cout | S |\n         | :---: | :---: | :---: | :---: |\n         | 0 | 0 | 0 | 0 |\n         | 0 | 1 | 0 | 1 |\n         | 1 | 0 | 0 | 1 |\n         | 1 | 1 | 1 | 0 |\n      2. 全加器：在半加器基础上增加进位输入（Cin），处理 3 位输入（A、B、Cin），输出和（S）与进位输出（Cout），真值表含 8 种输入组合，关键逻辑为 S=A⊕B⊕Cin、Cout=AB+ACin+BCin\n      3. 纹波进位加法器：将多个 1 位全加器链式连接，进位信号从低位向高位 “ripple” 传递，`缺点是速度慢（依赖进位传递延迟）`\n   2. 减法器\n      1. 含输入 X（被减数）、Y（减数）、借位输入（Bin），输出差值（D）、借位输出（Bout），核心逻辑如下：\n         1. 无 Bin 时：D=X⊕Y，Bout=X⋅Y\n         2. 有 Bin 时，D=X⊕Y⊕Bin，Bout=XBin+XY+YBin\n   3. 算术逻辑单元（ALU）\n      1. 通过 2 位控制信号（ALUControl [1:0]）选择运算功能，是处理器核心算术逻辑组件，功能表如下：\n         | ALUControl[1:0] | 功能 |\n         | :---: | :---: |\n         | 00 | 加法（Add） |\n         | 01 | 减法（Subtract） |\n         | 10 | 与运算（AND） |\n         | 11 | 或运算（OR） |\n7. 其他数字模块\n   1. 计数器\n      1. 功能：在每个时钟边沿实现计数递增，循环遍历数字（如 000→001→010→…→111→000…）\n      2. 应用：数字时钟显示、程序计数器（跟踪当前执行指令地址）\n      3. 结构：含时钟（CLK）、复位（Reset）输入和状态输出（Q），复位信号可重置计数状态\n   2. 移位寄存器\n      1. 功能：每个时钟边沿控制 1 位数据移入（Sin）和移出（Sout），实现串行数据与并行数据的转换（串并转换）\n      2. 结构：含串行输入（Sin）、串行输出（Sout）、时钟（CLK）和并行输出（Q0~QN-1）\n   3. 存储阵列\n      1. 核心功能：高效存储大量数据，通过 N 位地址访问 M 位数据（地址→数据映射）\n      2. 分类：\n         | 类型 | 特性 | 存储原理 | 应用 |\n         | :---: | :---: | :---: | :---: |\n         | DRAM（动态 RAM） | 易失性（断电失数据）、速度较慢、成本低 | 电容存储电荷 | 计算机主内存 |\n         | SRAM（静态 RAM） | 易失性、速度快、成本高 | 交叉耦合反相器 | 高速缓存（Cache） |\n         | ROM（只读存储器） | 非易失性（断电保数据）、读快写难 / 慢 | 制造时编程或电编程 | 相机闪存、U 盘 |\n   4. 逻辑阵列\n      1. PLA（可编程逻辑阵列）：由 “与阵列” 和 “或阵列” 组成，仅实现组合逻辑，内部连接固定，通过编程配置逻辑功能（如实现 AB+AC、NC+RC 等布尔表达式）\n      2. FPGA（现场可编程门阵列）：由逻辑元素（LEs）阵列构成，可实现组合逻辑和时序逻辑，内部连接可编程，部分 FPGA 还集成乘法器、RAM 等模块，灵活性高\n\n## 今日总结\n1. 今天开始上了后半学期的新课，教课的是一位印尼的老师，虽然听口语还是有点困难，但是一节课下来也完全知道在讲什么，而且明显感觉老师的教学比较活跃，课堂气氛不错，继续努力吧\n2. 办理了住宿证明，以及在读证明，只差学生证了\n3. 保险起见，今天的网球活动就不参加了\n4. 英语学习","source":"_posts/2025-11-5.md","raw":"---\ntitle: 2025.11.5\ndate: 2025-11-05 15:01:48\ntags:\n---\n# Overview\n1. 昨日总结\n2. 学习笔记\n3. 今日总结\n\n## 昨日总结\n1. 昨天去看牙了，最后拔掉了一颗智齿，还是比想象中轻松的，虽然到了晚上会有点疼但是可以忍受\n2. 昨天在中途休息的时候去到了一家特别大的书店，在里面逛了一圈后我买了6本书，并且成功用一天的时间看完了一本《追逐繁星的孩子》，接下来也要继续多多看书\n3. 晚上继续带摩羯出去锻炼胆量，明显还是一到外面的环境里就害怕\n\n## 学习笔记\n\n### 计算机体系结构与操作系统\n1. 数制系统\n   1. 核心概念：数制是表示数字的 “规则”，计算机底层仅能识别二进制（0 和 1），但为了简化表示，会用到十进制（日常使用）和十六进制（简化二进制书写）\n   2. 二进制转十进制：按权展开法  \n      二进制数的每一位都有 “权重”，权重为 2 的 “位数 - 1” 次方（从右往左，位数从 0 开始）。将每一位数字乘以对应权重，再求和，即可得到十进制数。\n   3. 十进制转二进制：除 2 取余法  \n      将十进制数反复除以 2，记录每次的余数（余数为 0 或 1），最后将余数从后往前排列，即可得到二进制数。\n   4. 二进制与十六进制转换：十六进制的 1 位对应二进制的 4 位（因为 16=2⁴），转换时只需将二进制数按 4 位分组（不足 4 位补 0），再将每组转换为对应的十六进制数即可\n2. 逻辑门：数字电路的 “基本积木”\n   1. 单输入逻辑门\n      1. NOT 门（非门）：功能是 “取反”，输入为 0 时输出 1，输入为 1 时输出 0。\n      2. 缓冲器（BUF）：功能是 “保持输入”，输入为 0 时输出 0，输入为 1 时输出 1（相当于 “无操作”，主要用于增强信号）\n   2. 双输入逻辑门：核心双输入逻辑门的功能：\n      | 逻辑门类型 | 功能描述 | 逻辑表达式 |\n      | :---: | :---:| :---: |\n      | AND 门（与门） | 只有 A、B 都为 1 时，Y 才为 1 | Y=A・B（“・” 表示与） |\n      | OR 门（或门） | A、B 只要有一个为 1，Y 就为 1 | Y=A+B（“+” 表示或） |\t\n      | XOR 门（异或门） | A、B 不同时，Y 为 1；相同为 0 | Y=A⊕B\t|\n      | NAND 门（与非门） | 只有 A、B 都为 1 时，Y 为 0（AND 门取反） | Y=¬(A·B) |\n      | NOR 门（或非门） | A、B 只要有一个为 1，Y 就为 0（OR 门取反） | Y=¬(A+B) | \n3. 组合逻辑电路\n   1. 核心定义：组合逻辑电路是由多个逻辑门组成的电路，**无记忆功能**—— 输出仅由当前输入决定，与过去的输入无关\n   2.  电路组成与描述方式：  \n       描述组合逻辑电路的核心方式是 “布尔方程”—— 用逻辑运算符（・、+、¬）表示输入与输出的关系  \n       组合逻辑电路的组成包括三部分：\n       1. 输入：外部信号来源（如传感器信号，用 A、B、C 等变量表示）\n       2. 内部节点：电路中间的信号节点（如多个门之间的连接点，用 n1、n2 等表示）\n       3. 输出：电路最终的信号（如机器启动信号，用 Y、Z 等变量表示）\n4. 布尔代数\n   1. 核心定义：布尔代数是描述逻辑关系的 “数学工具”，变量仅取值 0 或 1（对应假和真），运算包括与（・）、或（+）、非（¬），主要用于简化布尔方程（减少逻辑门数量，降低电路成本）\n   2. 核心公理（基础规则，无需证明）  \n       布尔代数的公理是推导所有定理的基础，核心公理及对偶公理（将 “・” 与 “+” 互换、0 与 1 互换，公理仍成立）如下表：\n      | 公理编号 | 公理内容 | 对偶公理（A'） | 含义说明 |\n      | :---: | :---: | :---: | :---: |\n      | A1（二进制域） | B=0，若 B≠1\t | B=1，若 B≠0 | 变量仅取 0 或 1（二进制域） |\n      | A2（非运算（NOT）） | ¬0=1 | ¬1=0 | 非运算的基本规则 |\n      | A3（与 / 或运算（AND/OR）） | 0·0=0 | 1+1=1 | 与 / 或运算的边界情况 |\n      | A4（与 / 或运算（AND/OR）） | 1·1=1 | 0+0=0 | 与 / 或运算的边界情况 |\n      | A5（与 / 或运算（AND/OR）） | 0·1=1·0=0 | 1+0=0+1=1 | 与 / 或运算的交换性边界情况 |\n   3. 核心定理（可通过公理推导，需记忆）  \n      布尔代数的定理是简化方程的关键，常用定理及对偶定理如下表（B、C、D 为布尔变量）：\n      | 定理名 | 定理内容 | 对偶定理（T'） | 含义说明 |\n      | :---: | :---: | :---: | :---: |\n      | Identity Theorem（同一律） | B·1=B；B+0=B | B+1=1；B·0=0 | 与 1 相乘 / 或 0 相加，结果不变 |\n      | Null Element Theorem（零律） | B·0=0；B+1=1 | B+0=0；B·1=1 | 与 0 相乘 / 或 1 相加，结果为 0/1 |\n      | Idempotency Theorem（幂等律） | B·B=B；B+B=B | B+B=B；B·B=B | 与 / 或自身，结果不变 |\n      | Involution Theorem（对合律） | ¬(¬B)=B | ¬(¬B)=B | 两次非运算，结果还原 |\n      | Complement theorem（互补律） | B·¬B=0；B+¬B=1 | B+¬B=1；B·¬B=0 | 与自身非相乘为 0，相加为 1 |\n      | Commutativity（交换律） | B·C=C·B；B+C=C+B | B+C=C+B；B·C=C·B | 与 / 或运算的顺序不影响结果 |\n      | Associativity（结合律） | (B·C)·D=B·(C·D)；(B+C)+D=B+(C+D) | (B+C)+D=B+(C+D)；(B·C)·D=B·(C·D) | 与 / 或运算的分组不影响结果 |\n      | Distributivity（分配律） | B·(C+D)=B·C+B·D；B+C·D=(B+C)·(B+D) | B+(C·D)=(B+C)·(B+D)；B·(C+D)=B·C+B·D | 与对或 / 或对与的分配规则 |\n      | Covering（覆盖律） | B·(B+C)=B；B+(B·C)=B | B+(B·C)=B；B·(B+C)=B | 变量与自身和 / 积，结果为自身 |\n      | Combining（合并律） | B·C+B·¬C=B；(B+C)·(B+¬C)=B | (B+C)·(B+¬C)=B；B·C+B·¬C=B | 提取相同变量，合并不同变量 |\n      | Consensus（共识律） | B·C+¬B·D+C·D=B·C+¬B·D；(B+C)·(¬B+D)·(C+D)=(B+C)·(¬B+D) | (B+C)·(¬B+D)·(C+D)=(B+C)·(¬B+D)；B·C+¬B·D+C·D=B·C+¬B·D | 消除冗余的共识项 |\n      | De Morgan's Theorem（德摩根定律） | ¬(B·C)=¬B+¬C；¬(B+C)=¬B·¬C | ¬(B+C)=¬B·¬C；¬(B·C)=¬B+¬C | 与的非等于非的或，或的非等于非的与 |\n5. 数字构建块\n   1. 组合逻辑电路\n      1. 核心特性：无记忆功能，输出仅由当前输入决定，包含输入（如 A、B、C）、输出（如 Y、Z）和内部节点（如 n1），通过电路元素（E1、E2、E3）实现逻辑关系，可用布尔方程描述（如 n1=E1 (A,B)、Z=E2 (A,C)、Y=E3 (n1,B,Z)）\n      2. 常用组件：\n         1. 多路复用器（Mux）：从 N 个输入中选择 1 个输出，需log(2)N位选择信号（S）。以 2:1 Mux 为例，选择信号 S=0 时输出 D0，S=1 时输出 D1，其真值表如下：\n            | S | D1 | D0 | Y |\n            | :---: | :---: | :---: | :---: |\n            | 0 | 0 | 0 | 0 |\n            | 0 | 0 | 1 | 1 |\n            | 0 | 1 | 0 | 0 |\n            | 0 | 1 | 1 | 1 |\n            | 1 | 0 | 0 | 0 |\n            | 1 | 0 | 1 | 0 |\n            | 1 | 1 | 0 | 1 |\n            | 1 | 1 | 1 | 1 |\n         2. 解码器：N 个输入对应2^N个输出，采用 “独热编码”（仅 1 个输出为高电平）。以 2:4 Decoder 为例，输入 A1、A0 控制输出 Y3-Y0，真值表关键逻辑为：A1A0=00 → Y0=1；A1A0=01 → Y1=1；A1A0 = 10 → Y2=1；A1A0=11 → Y3=1\n         3. 移位器：分三类，具体功能及示例（输入 11001）如下：\n            | 类型 | 功能 | 示例（输入 11001） |\n            | :---: | :---: | :---: |\n            | 逻辑移位器 | 左右移位，空位补 0 | 右移 2 位：11001>>2=00110；左移 2 位：11001<<2=00100 |\n            | 算术移位器 | 左移同逻辑移位，右移空位补最高有效位（MSB） | 右移 2 位：11001>>>2=11110；左移 2 位：11001<<<2=00100 |\n            | 旋转移位器 | 循环移位，移出位补到另一端 | 右旋转 2 位：11001 ROR 2=01110；左旋转 2 位：11001 ROL 2=00111 |\n   2. 时序逻辑电路\n      1. 核心特性：有短期记忆功能，通过输出到输入的反馈存储信息，能为事件提供时序顺序\n      2. 基础电路：双稳态电路，可存储 1 位状态（Q），存在两种稳定状态：Q=0 时¬Q=1；Q=1 时¬Q=0，但无输入控制状态\n      3. 常用组件\n         1. S-R 锁存器：含置位（S）、复位（R）输入，四种工作状态如下：\n            1. S=1、R=0：置位，Q=1、¬Q=0\n            2. S=0、R=1：复位，Q=0、¬Q=1\n            3. S=0、R=0：保持，Q=Q_prev（前一状态）\n            4. S=1、R=1：**无效**，Q=0、¬Q=0（Q≠¬Q）\n         2. D 锁存器：含时钟（CLK）、数据（D）输入，`避免 S-R 锁存器的无效状态`：\n            1. CLK=1：透明模式，D 直接传递到 Q\n            2. CLK=0：不透明模式，Q 保持前一状态（Q_prev）\n         3. D 触发器：边沿触发（仅时钟上升沿有效），输入为 CLK 和 D\n            1. 时钟从 0→1（上升沿）：采样 D 值并传递到 Q\n            2. 其他时刻：Q 保持前一状态，仅在上升沿变化\n6. 算术组件\n   1. 加法器\n      1. 半加器：仅处理 2 位输入（A、B），输出和（S）与进位输出（Cout），真值表如下：\n         | A | B | Cout | S |\n         | :---: | :---: | :---: | :---: |\n         | 0 | 0 | 0 | 0 |\n         | 0 | 1 | 0 | 1 |\n         | 1 | 0 | 0 | 1 |\n         | 1 | 1 | 1 | 0 |\n      2. 全加器：在半加器基础上增加进位输入（Cin），处理 3 位输入（A、B、Cin），输出和（S）与进位输出（Cout），真值表含 8 种输入组合，关键逻辑为 S=A⊕B⊕Cin、Cout=AB+ACin+BCin\n      3. 纹波进位加法器：将多个 1 位全加器链式连接，进位信号从低位向高位 “ripple” 传递，`缺点是速度慢（依赖进位传递延迟）`\n   2. 减法器\n      1. 含输入 X（被减数）、Y（减数）、借位输入（Bin），输出差值（D）、借位输出（Bout），核心逻辑如下：\n         1. 无 Bin 时：D=X⊕Y，Bout=X⋅Y\n         2. 有 Bin 时，D=X⊕Y⊕Bin，Bout=XBin+XY+YBin\n   3. 算术逻辑单元（ALU）\n      1. 通过 2 位控制信号（ALUControl [1:0]）选择运算功能，是处理器核心算术逻辑组件，功能表如下：\n         | ALUControl[1:0] | 功能 |\n         | :---: | :---: |\n         | 00 | 加法（Add） |\n         | 01 | 减法（Subtract） |\n         | 10 | 与运算（AND） |\n         | 11 | 或运算（OR） |\n7. 其他数字模块\n   1. 计数器\n      1. 功能：在每个时钟边沿实现计数递增，循环遍历数字（如 000→001→010→…→111→000…）\n      2. 应用：数字时钟显示、程序计数器（跟踪当前执行指令地址）\n      3. 结构：含时钟（CLK）、复位（Reset）输入和状态输出（Q），复位信号可重置计数状态\n   2. 移位寄存器\n      1. 功能：每个时钟边沿控制 1 位数据移入（Sin）和移出（Sout），实现串行数据与并行数据的转换（串并转换）\n      2. 结构：含串行输入（Sin）、串行输出（Sout）、时钟（CLK）和并行输出（Q0~QN-1）\n   3. 存储阵列\n      1. 核心功能：高效存储大量数据，通过 N 位地址访问 M 位数据（地址→数据映射）\n      2. 分类：\n         | 类型 | 特性 | 存储原理 | 应用 |\n         | :---: | :---: | :---: | :---: |\n         | DRAM（动态 RAM） | 易失性（断电失数据）、速度较慢、成本低 | 电容存储电荷 | 计算机主内存 |\n         | SRAM（静态 RAM） | 易失性、速度快、成本高 | 交叉耦合反相器 | 高速缓存（Cache） |\n         | ROM（只读存储器） | 非易失性（断电保数据）、读快写难 / 慢 | 制造时编程或电编程 | 相机闪存、U 盘 |\n   4. 逻辑阵列\n      1. PLA（可编程逻辑阵列）：由 “与阵列” 和 “或阵列” 组成，仅实现组合逻辑，内部连接固定，通过编程配置逻辑功能（如实现 AB+AC、NC+RC 等布尔表达式）\n      2. FPGA（现场可编程门阵列）：由逻辑元素（LEs）阵列构成，可实现组合逻辑和时序逻辑，内部连接可编程，部分 FPGA 还集成乘法器、RAM 等模块，灵活性高\n\n## 今日总结\n1. 今天开始上了后半学期的新课，教课的是一位印尼的老师，虽然听口语还是有点困难，但是一节课下来也完全知道在讲什么，而且明显感觉老师的教学比较活跃，课堂气氛不错，继续努力吧\n2. 办理了住宿证明，以及在读证明，只差学生证了\n3. 保险起见，今天的网球活动就不参加了\n4. 英语学习","slug":"2025-11-5","published":1,"updated":"2025-11-18T19:39:17.147Z","comments":1,"layout":"post","photos":[],"_id":"cuidLPgk8BvotvEAWvL62Us_Q","content":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>昨日总结</li>\n<li>学习笔记</li>\n<li>今日总结</li>\n</ol>\n<h2 id=\"昨日总结\"><a href=\"#昨日总结\" class=\"headerlink\" title=\"昨日总结\"></a>昨日总结</h2><ol>\n<li>昨天去看牙了，最后拔掉了一颗智齿，还是比想象中轻松的，虽然到了晚上会有点疼但是可以忍受</li>\n<li>昨天在中途休息的时候去到了一家特别大的书店，在里面逛了一圈后我买了6本书，并且成功用一天的时间看完了一本《追逐繁星的孩子》，接下来也要继续多多看书</li>\n<li>晚上继续带摩羯出去锻炼胆量，明显还是一到外面的环境里就害怕</li>\n</ol>\n<h2 id=\"学习笔记\"><a href=\"#学习笔记\" class=\"headerlink\" title=\"学习笔记\"></a>学习笔记</h2><h3 id=\"计算机体系结构与操作系统\"><a href=\"#计算机体系结构与操作系统\" class=\"headerlink\" title=\"计算机体系结构与操作系统\"></a>计算机体系结构与操作系统</h3><ol>\n<li>数制系统<ol>\n<li>核心概念：数制是表示数字的 “规则”，计算机底层仅能识别二进制（0 和 1），但为了简化表示，会用到十进制（日常使用）和十六进制（简化二进制书写）</li>\n<li>二进制转十进制：按权展开法<br>二进制数的每一位都有 “权重”，权重为 2 的 “位数 - 1” 次方（从右往左，位数从 0 开始）。将每一位数字乘以对应权重，再求和，即可得到十进制数。</li>\n<li>十进制转二进制：除 2 取余法<br>将十进制数反复除以 2，记录每次的余数（余数为 0 或 1），最后将余数从后往前排列，即可得到二进制数。</li>\n<li>二进制与十六进制转换：十六进制的 1 位对应二进制的 4 位（因为 16&#x3D;2⁴），转换时只需将二进制数按 4 位分组（不足 4 位补 0），再将每组转换为对应的十六进制数即可</li>\n</ol>\n</li>\n<li>逻辑门：数字电路的 “基本积木”<ol>\n<li>单输入逻辑门<ol>\n<li>NOT 门（非门）：功能是 “取反”，输入为 0 时输出 1，输入为 1 时输出 0。</li>\n<li>缓冲器（BUF）：功能是 “保持输入”，输入为 0 时输出 0，输入为 1 时输出 1（相当于 “无操作”，主要用于增强信号）</li>\n</ol>\n</li>\n<li>双输入逻辑门：核心双输入逻辑门的功能：<table>\n<thead>\n<tr>\n<th align=\"center\">逻辑门类型</th>\n<th align=\"center\">功能描述</th>\n<th align=\"center\">逻辑表达式</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">AND 门（与门）</td>\n<td align=\"center\">只有 A、B 都为 1 时，Y 才为 1</td>\n<td align=\"center\">Y&#x3D;A・B（“・” 表示与）</td>\n</tr>\n<tr>\n<td align=\"center\">OR 门（或门）</td>\n<td align=\"center\">A、B 只要有一个为 1，Y 就为 1</td>\n<td align=\"center\">Y&#x3D;A+B（“+” 表示或）</td>\n</tr>\n<tr>\n<td align=\"center\">XOR 门（异或门）</td>\n<td align=\"center\">A、B 不同时，Y 为 1；相同为 0</td>\n<td align=\"center\">Y&#x3D;A⊕B</td>\n</tr>\n<tr>\n<td align=\"center\">NAND 门（与非门）</td>\n<td align=\"center\">只有 A、B 都为 1 时，Y 为 0（AND 门取反）</td>\n<td align=\"center\">Y&#x3D;¬(A·B)</td>\n</tr>\n<tr>\n<td align=\"center\">NOR 门（或非门）</td>\n<td align=\"center\">A、B 只要有一个为 1，Y 就为 0（OR 门取反）</td>\n<td align=\"center\">Y&#x3D;¬(A+B)</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n</li>\n<li>组合逻辑电路<ol>\n<li>核心定义：组合逻辑电路是由多个逻辑门组成的电路，<strong>无记忆功能</strong>—— 输出仅由当前输入决定，与过去的输入无关</li>\n<li>电路组成与描述方式：<br>描述组合逻辑电路的核心方式是 “布尔方程”—— 用逻辑运算符（・、+、¬）表示输入与输出的关系<br>组合逻辑电路的组成包括三部分：<ol>\n<li>输入：外部信号来源（如传感器信号，用 A、B、C 等变量表示）</li>\n<li>内部节点：电路中间的信号节点（如多个门之间的连接点，用 n1、n2 等表示）</li>\n<li>输出：电路最终的信号（如机器启动信号，用 Y、Z 等变量表示）</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>布尔代数<ol>\n<li>核心定义：布尔代数是描述逻辑关系的 “数学工具”，变量仅取值 0 或 1（对应假和真），运算包括与（・）、或（+）、非（¬），主要用于简化布尔方程（减少逻辑门数量，降低电路成本）</li>\n<li>核心公理（基础规则，无需证明）<br> 布尔代数的公理是推导所有定理的基础，核心公理及对偶公理（将 “・” 与 “+” 互换、0 与 1 互换，公理仍成立）如下表：<table>\n<thead>\n<tr>\n<th align=\"center\">公理编号</th>\n<th align=\"center\">公理内容</th>\n<th align=\"center\">对偶公理（A’）</th>\n<th align=\"center\">含义说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">A1（二进制域）</td>\n<td align=\"center\">B&#x3D;0，若 B≠1</td>\n<td align=\"center\">B&#x3D;1，若 B≠0</td>\n<td align=\"center\">变量仅取 0 或 1（二进制域）</td>\n</tr>\n<tr>\n<td align=\"center\">A2（非运算（NOT））</td>\n<td align=\"center\">¬0&#x3D;1</td>\n<td align=\"center\">¬1&#x3D;0</td>\n<td align=\"center\">非运算的基本规则</td>\n</tr>\n<tr>\n<td align=\"center\">A3（与 &#x2F; 或运算（AND&#x2F;OR））</td>\n<td align=\"center\">0·0&#x3D;0</td>\n<td align=\"center\">1+1&#x3D;1</td>\n<td align=\"center\">与 &#x2F; 或运算的边界情况</td>\n</tr>\n<tr>\n<td align=\"center\">A4（与 &#x2F; 或运算（AND&#x2F;OR））</td>\n<td align=\"center\">1·1&#x3D;1</td>\n<td align=\"center\">0+0&#x3D;0</td>\n<td align=\"center\">与 &#x2F; 或运算的边界情况</td>\n</tr>\n<tr>\n<td align=\"center\">A5（与 &#x2F; 或运算（AND&#x2F;OR））</td>\n<td align=\"center\">0·1&#x3D;1·0&#x3D;0</td>\n<td align=\"center\">1+0&#x3D;0+1&#x3D;1</td>\n<td align=\"center\">与 &#x2F; 或运算的交换性边界情况</td>\n</tr>\n</tbody></table>\n</li>\n<li>核心定理（可通过公理推导，需记忆）<br>布尔代数的定理是简化方程的关键，常用定理及对偶定理如下表（B、C、D 为布尔变量）：<table>\n<thead>\n<tr>\n<th align=\"center\">定理名</th>\n<th align=\"center\">定理内容</th>\n<th align=\"center\">对偶定理（T’）</th>\n<th align=\"center\">含义说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">Identity Theorem（同一律）</td>\n<td align=\"center\">B·1&#x3D;B；B+0&#x3D;B</td>\n<td align=\"center\">B+1&#x3D;1；B·0&#x3D;0</td>\n<td align=\"center\">与 1 相乘 &#x2F; 或 0 相加，结果不变</td>\n</tr>\n<tr>\n<td align=\"center\">Null Element Theorem（零律）</td>\n<td align=\"center\">B·0&#x3D;0；B+1&#x3D;1</td>\n<td align=\"center\">B+0&#x3D;0；B·1&#x3D;1</td>\n<td align=\"center\">与 0 相乘 &#x2F; 或 1 相加，结果为 0&#x2F;1</td>\n</tr>\n<tr>\n<td align=\"center\">Idempotency Theorem（幂等律）</td>\n<td align=\"center\">B·B&#x3D;B；B+B&#x3D;B</td>\n<td align=\"center\">B+B&#x3D;B；B·B&#x3D;B</td>\n<td align=\"center\">与 &#x2F; 或自身，结果不变</td>\n</tr>\n<tr>\n<td align=\"center\">Involution Theorem（对合律）</td>\n<td align=\"center\">¬(¬B)&#x3D;B</td>\n<td align=\"center\">¬(¬B)&#x3D;B</td>\n<td align=\"center\">两次非运算，结果还原</td>\n</tr>\n<tr>\n<td align=\"center\">Complement theorem（互补律）</td>\n<td align=\"center\">B·¬B&#x3D;0；B+¬B&#x3D;1</td>\n<td align=\"center\">B+¬B&#x3D;1；B·¬B&#x3D;0</td>\n<td align=\"center\">与自身非相乘为 0，相加为 1</td>\n</tr>\n<tr>\n<td align=\"center\">Commutativity（交换律）</td>\n<td align=\"center\">B·C&#x3D;C·B；B+C&#x3D;C+B</td>\n<td align=\"center\">B+C&#x3D;C+B；B·C&#x3D;C·B</td>\n<td align=\"center\">与 &#x2F; 或运算的顺序不影响结果</td>\n</tr>\n<tr>\n<td align=\"center\">Associativity（结合律）</td>\n<td align=\"center\">(B·C)·D&#x3D;B·(C·D)；(B+C)+D&#x3D;B+(C+D)</td>\n<td align=\"center\">(B+C)+D&#x3D;B+(C+D)；(B·C)·D&#x3D;B·(C·D)</td>\n<td align=\"center\">与 &#x2F; 或运算的分组不影响结果</td>\n</tr>\n<tr>\n<td align=\"center\">Distributivity（分配律）</td>\n<td align=\"center\">B·(C+D)&#x3D;B·C+B·D；B+C·D&#x3D;(B+C)·(B+D)</td>\n<td align=\"center\">B+(C·D)&#x3D;(B+C)·(B+D)；B·(C+D)&#x3D;B·C+B·D</td>\n<td align=\"center\">与对或 &#x2F; 或对与的分配规则</td>\n</tr>\n<tr>\n<td align=\"center\">Covering（覆盖律）</td>\n<td align=\"center\">B·(B+C)&#x3D;B；B+(B·C)&#x3D;B</td>\n<td align=\"center\">B+(B·C)&#x3D;B；B·(B+C)&#x3D;B</td>\n<td align=\"center\">变量与自身和 &#x2F; 积，结果为自身</td>\n</tr>\n<tr>\n<td align=\"center\">Combining（合并律）</td>\n<td align=\"center\">B·C+B·¬C&#x3D;B；(B+C)·(B+¬C)&#x3D;B</td>\n<td align=\"center\">(B+C)·(B+¬C)&#x3D;B；B·C+B·¬C&#x3D;B</td>\n<td align=\"center\">提取相同变量，合并不同变量</td>\n</tr>\n<tr>\n<td align=\"center\">Consensus（共识律）</td>\n<td align=\"center\">B·C+¬B·D+C·D&#x3D;B·C+¬B·D；(B+C)·(¬B+D)·(C+D)&#x3D;(B+C)·(¬B+D)</td>\n<td align=\"center\">(B+C)·(¬B+D)·(C+D)&#x3D;(B+C)·(¬B+D)；B·C+¬B·D+C·D&#x3D;B·C+¬B·D</td>\n<td align=\"center\">消除冗余的共识项</td>\n</tr>\n<tr>\n<td align=\"center\">De Morgan’s Theorem（德摩根定律）</td>\n<td align=\"center\">¬(B·C)&#x3D;¬B+¬C；¬(B+C)&#x3D;¬B·¬C</td>\n<td align=\"center\">¬(B+C)&#x3D;¬B·¬C；¬(B·C)&#x3D;¬B+¬C</td>\n<td align=\"center\">与的非等于非的或，或的非等于非的与</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n</li>\n<li>数字构建块<ol>\n<li>组合逻辑电路<ol>\n<li>核心特性：无记忆功能，输出仅由当前输入决定，包含输入（如 A、B、C）、输出（如 Y、Z）和内部节点（如 n1），通过电路元素（E1、E2、E3）实现逻辑关系，可用布尔方程描述（如 n1&#x3D;E1 (A,B)、Z&#x3D;E2 (A,C)、Y&#x3D;E3 (n1,B,Z)）</li>\n<li>常用组件：<ol>\n<li>多路复用器（Mux）：从 N 个输入中选择 1 个输出，需log(2)N位选择信号（S）。以 2:1 Mux 为例，选择信号 S&#x3D;0 时输出 D0，S&#x3D;1 时输出 D1，其真值表如下：<table>\n<thead>\n<tr>\n<th align=\"center\">S</th>\n<th align=\"center\">D1</th>\n<th align=\"center\">D0</th>\n<th align=\"center\">Y</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n</tr>\n</tbody></table>\n</li>\n<li>解码器：N 个输入对应2^N个输出，采用 “独热编码”（仅 1 个输出为高电平）。以 2:4 Decoder 为例，输入 A1、A0 控制输出 Y3-Y0，真值表关键逻辑为：A1A0&#x3D;00 → Y0&#x3D;1；A1A0&#x3D;01 → Y1&#x3D;1；A1A0 &#x3D; 10 → Y2&#x3D;1；A1A0&#x3D;11 → Y3&#x3D;1</li>\n<li>移位器：分三类，具体功能及示例（输入 11001）如下：<table>\n<thead>\n<tr>\n<th align=\"center\">类型</th>\n<th align=\"center\">功能</th>\n<th align=\"center\">示例（输入 11001）</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">逻辑移位器</td>\n<td align=\"center\">左右移位，空位补 0</td>\n<td align=\"center\">右移 2 位：11001&gt;&gt;2&#x3D;00110；左移 2 位：11001&lt;&lt;2&#x3D;00100</td>\n</tr>\n<tr>\n<td align=\"center\">算术移位器</td>\n<td align=\"center\">左移同逻辑移位，右移空位补最高有效位（MSB）</td>\n<td align=\"center\">右移 2 位：11001&gt;&gt;&gt;2&#x3D;11110；左移 2 位：11001&lt;&lt;&lt;2&#x3D;00100</td>\n</tr>\n<tr>\n<td align=\"center\">旋转移位器</td>\n<td align=\"center\">循环移位，移出位补到另一端</td>\n<td align=\"center\">右旋转 2 位：11001 ROR 2&#x3D;01110；左旋转 2 位：11001 ROL 2&#x3D;00111</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>时序逻辑电路<ol>\n<li>核心特性：有短期记忆功能，通过输出到输入的反馈存储信息，能为事件提供时序顺序</li>\n<li>基础电路：双稳态电路，可存储 1 位状态（Q），存在两种稳定状态：Q&#x3D;0 时¬Q&#x3D;1；Q&#x3D;1 时¬Q&#x3D;0，但无输入控制状态</li>\n<li>常用组件<ol>\n<li>S-R 锁存器：含置位（S）、复位（R）输入，四种工作状态如下：<ol>\n<li>S&#x3D;1、R&#x3D;0：置位，Q&#x3D;1、¬Q&#x3D;0</li>\n<li>S&#x3D;0、R&#x3D;1：复位，Q&#x3D;0、¬Q&#x3D;1</li>\n<li>S&#x3D;0、R&#x3D;0：保持，Q&#x3D;Q_prev（前一状态）</li>\n<li>S&#x3D;1、R&#x3D;1：<strong>无效</strong>，Q&#x3D;0、¬Q&#x3D;0（Q≠¬Q）</li>\n</ol>\n</li>\n<li>D 锁存器：含时钟（CLK）、数据（D）输入，<code>避免 S-R 锁存器的无效状态</code>：<ol>\n<li>CLK&#x3D;1：透明模式，D 直接传递到 Q</li>\n<li>CLK&#x3D;0：不透明模式，Q 保持前一状态（Q_prev）</li>\n</ol>\n</li>\n<li>D 触发器：边沿触发（仅时钟上升沿有效），输入为 CLK 和 D<ol>\n<li>时钟从 0→1（上升沿）：采样 D 值并传递到 Q</li>\n<li>其他时刻：Q 保持前一状态，仅在上升沿变化</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>算术组件<ol>\n<li>加法器<ol>\n<li>半加器：仅处理 2 位输入（A、B），输出和（S）与进位输出（Cout），真值表如下：<table>\n<thead>\n<tr>\n<th align=\"center\">A</th>\n<th align=\"center\">B</th>\n<th align=\"center\">Cout</th>\n<th align=\"center\">S</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n</tr>\n</tbody></table>\n</li>\n<li>全加器：在半加器基础上增加进位输入（Cin），处理 3 位输入（A、B、Cin），输出和（S）与进位输出（Cout），真值表含 8 种输入组合，关键逻辑为 S&#x3D;A⊕B⊕Cin、Cout&#x3D;AB+ACin+BCin</li>\n<li>纹波进位加法器：将多个 1 位全加器链式连接，进位信号从低位向高位 “ripple” 传递，<code>缺点是速度慢（依赖进位传递延迟）</code></li>\n</ol>\n</li>\n<li>减法器<ol>\n<li>含输入 X（被减数）、Y（减数）、借位输入（Bin），输出差值（D）、借位输出（Bout），核心逻辑如下：<ol>\n<li>无 Bin 时：D&#x3D;X⊕Y，Bout&#x3D;X⋅Y</li>\n<li>有 Bin 时，D&#x3D;X⊕Y⊕Bin，Bout&#x3D;XBin+XY+YBin</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>算术逻辑单元（ALU）<ol>\n<li>通过 2 位控制信号（ALUControl [1:0]）选择运算功能，是处理器核心算术逻辑组件，功能表如下：<table>\n<thead>\n<tr>\n<th align=\"center\">ALUControl[1:0]</th>\n<th align=\"center\">功能</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">00</td>\n<td align=\"center\">加法（Add）</td>\n</tr>\n<tr>\n<td align=\"center\">01</td>\n<td align=\"center\">减法（Subtract）</td>\n</tr>\n<tr>\n<td align=\"center\">10</td>\n<td align=\"center\">与运算（AND）</td>\n</tr>\n<tr>\n<td align=\"center\">11</td>\n<td align=\"center\">或运算（OR）</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>其他数字模块<ol>\n<li>计数器<ol>\n<li>功能：在每个时钟边沿实现计数递增，循环遍历数字（如 000→001→010→…→111→000…）</li>\n<li>应用：数字时钟显示、程序计数器（跟踪当前执行指令地址）</li>\n<li>结构：含时钟（CLK）、复位（Reset）输入和状态输出（Q），复位信号可重置计数状态</li>\n</ol>\n</li>\n<li>移位寄存器<ol>\n<li>功能：每个时钟边沿控制 1 位数据移入（Sin）和移出（Sout），实现串行数据与并行数据的转换（串并转换）</li>\n<li>结构：含串行输入（Sin）、串行输出（Sout）、时钟（CLK）和并行输出（Q0~QN-1）</li>\n</ol>\n</li>\n<li>存储阵列<ol>\n<li>核心功能：高效存储大量数据，通过 N 位地址访问 M 位数据（地址→数据映射）</li>\n<li>分类：<table>\n<thead>\n<tr>\n<th align=\"center\">类型</th>\n<th align=\"center\">特性</th>\n<th align=\"center\">存储原理</th>\n<th align=\"center\">应用</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">DRAM（动态 RAM）</td>\n<td align=\"center\">易失性（断电失数据）、速度较慢、成本低</td>\n<td align=\"center\">电容存储电荷</td>\n<td align=\"center\">计算机主内存</td>\n</tr>\n<tr>\n<td align=\"center\">SRAM（静态 RAM）</td>\n<td align=\"center\">易失性、速度快、成本高</td>\n<td align=\"center\">交叉耦合反相器</td>\n<td align=\"center\">高速缓存（Cache）</td>\n</tr>\n<tr>\n<td align=\"center\">ROM（只读存储器）</td>\n<td align=\"center\">非易失性（断电保数据）、读快写难 &#x2F; 慢</td>\n<td align=\"center\">制造时编程或电编程</td>\n<td align=\"center\">相机闪存、U 盘</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n</li>\n<li>逻辑阵列<ol>\n<li>PLA（可编程逻辑阵列）：由 “与阵列” 和 “或阵列” 组成，仅实现组合逻辑，内部连接固定，通过编程配置逻辑功能（如实现 AB+AC、NC+RC 等布尔表达式）</li>\n<li>FPGA（现场可编程门阵列）：由逻辑元素（LEs）阵列构成，可实现组合逻辑和时序逻辑，内部连接可编程，部分 FPGA 还集成乘法器、RAM 等模块，灵活性高</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"今日总结\"><a href=\"#今日总结\" class=\"headerlink\" title=\"今日总结\"></a>今日总结</h2><ol>\n<li>今天开始上了后半学期的新课，教课的是一位印尼的老师，虽然听口语还是有点困难，但是一节课下来也完全知道在讲什么，而且明显感觉老师的教学比较活跃，课堂气氛不错，继续努力吧</li>\n<li>办理了住宿证明，以及在读证明，只差学生证了</li>\n<li>保险起见，今天的网球活动就不参加了</li>\n<li>英语学习</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>昨日总结</li>\n<li>学习笔记</li>\n<li>今日总结</li>\n</ol>\n<h2 id=\"昨日总结\"><a href=\"#昨日总结\" class=\"headerlink\" title=\"昨日总结\"></a>昨日总结</h2><ol>\n<li>昨天去看牙了，最后拔掉了一颗智齿，还是比想象中轻松的，虽然到了晚上会有点疼但是可以忍受</li>\n<li>昨天在中途休息的时候去到了一家特别大的书店，在里面逛了一圈后我买了6本书，并且成功用一天的时间看完了一本《追逐繁星的孩子》，接下来也要继续多多看书</li>\n<li>晚上继续带摩羯出去锻炼胆量，明显还是一到外面的环境里就害怕</li>\n</ol>\n<h2 id=\"学习笔记\"><a href=\"#学习笔记\" class=\"headerlink\" title=\"学习笔记\"></a>学习笔记</h2><h3 id=\"计算机体系结构与操作系统\"><a href=\"#计算机体系结构与操作系统\" class=\"headerlink\" title=\"计算机体系结构与操作系统\"></a>计算机体系结构与操作系统</h3><ol>\n<li>数制系统<ol>\n<li>核心概念：数制是表示数字的 “规则”，计算机底层仅能识别二进制（0 和 1），但为了简化表示，会用到十进制（日常使用）和十六进制（简化二进制书写）</li>\n<li>二进制转十进制：按权展开法<br>二进制数的每一位都有 “权重”，权重为 2 的 “位数 - 1” 次方（从右往左，位数从 0 开始）。将每一位数字乘以对应权重，再求和，即可得到十进制数。</li>\n<li>十进制转二进制：除 2 取余法<br>将十进制数反复除以 2，记录每次的余数（余数为 0 或 1），最后将余数从后往前排列，即可得到二进制数。</li>\n<li>二进制与十六进制转换：十六进制的 1 位对应二进制的 4 位（因为 16&#x3D;2⁴），转换时只需将二进制数按 4 位分组（不足 4 位补 0），再将每组转换为对应的十六进制数即可</li>\n</ol>\n</li>\n<li>逻辑门：数字电路的 “基本积木”<ol>\n<li>单输入逻辑门<ol>\n<li>NOT 门（非门）：功能是 “取反”，输入为 0 时输出 1，输入为 1 时输出 0。</li>\n<li>缓冲器（BUF）：功能是 “保持输入”，输入为 0 时输出 0，输入为 1 时输出 1（相当于 “无操作”，主要用于增强信号）</li>\n</ol>\n</li>\n<li>双输入逻辑门：核心双输入逻辑门的功能：<table>\n<thead>\n<tr>\n<th align=\"center\">逻辑门类型</th>\n<th align=\"center\">功能描述</th>\n<th align=\"center\">逻辑表达式</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">AND 门（与门）</td>\n<td align=\"center\">只有 A、B 都为 1 时，Y 才为 1</td>\n<td align=\"center\">Y&#x3D;A・B（“・” 表示与）</td>\n</tr>\n<tr>\n<td align=\"center\">OR 门（或门）</td>\n<td align=\"center\">A、B 只要有一个为 1，Y 就为 1</td>\n<td align=\"center\">Y&#x3D;A+B（“+” 表示或）</td>\n</tr>\n<tr>\n<td align=\"center\">XOR 门（异或门）</td>\n<td align=\"center\">A、B 不同时，Y 为 1；相同为 0</td>\n<td align=\"center\">Y&#x3D;A⊕B</td>\n</tr>\n<tr>\n<td align=\"center\">NAND 门（与非门）</td>\n<td align=\"center\">只有 A、B 都为 1 时，Y 为 0（AND 门取反）</td>\n<td align=\"center\">Y&#x3D;¬(A·B)</td>\n</tr>\n<tr>\n<td align=\"center\">NOR 门（或非门）</td>\n<td align=\"center\">A、B 只要有一个为 1，Y 就为 0（OR 门取反）</td>\n<td align=\"center\">Y&#x3D;¬(A+B)</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n</li>\n<li>组合逻辑电路<ol>\n<li>核心定义：组合逻辑电路是由多个逻辑门组成的电路，<strong>无记忆功能</strong>—— 输出仅由当前输入决定，与过去的输入无关</li>\n<li>电路组成与描述方式：<br>描述组合逻辑电路的核心方式是 “布尔方程”—— 用逻辑运算符（・、+、¬）表示输入与输出的关系<br>组合逻辑电路的组成包括三部分：<ol>\n<li>输入：外部信号来源（如传感器信号，用 A、B、C 等变量表示）</li>\n<li>内部节点：电路中间的信号节点（如多个门之间的连接点，用 n1、n2 等表示）</li>\n<li>输出：电路最终的信号（如机器启动信号，用 Y、Z 等变量表示）</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>布尔代数<ol>\n<li>核心定义：布尔代数是描述逻辑关系的 “数学工具”，变量仅取值 0 或 1（对应假和真），运算包括与（・）、或（+）、非（¬），主要用于简化布尔方程（减少逻辑门数量，降低电路成本）</li>\n<li>核心公理（基础规则，无需证明）<br> 布尔代数的公理是推导所有定理的基础，核心公理及对偶公理（将 “・” 与 “+” 互换、0 与 1 互换，公理仍成立）如下表：<table>\n<thead>\n<tr>\n<th align=\"center\">公理编号</th>\n<th align=\"center\">公理内容</th>\n<th align=\"center\">对偶公理（A’）</th>\n<th align=\"center\">含义说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">A1（二进制域）</td>\n<td align=\"center\">B&#x3D;0，若 B≠1</td>\n<td align=\"center\">B&#x3D;1，若 B≠0</td>\n<td align=\"center\">变量仅取 0 或 1（二进制域）</td>\n</tr>\n<tr>\n<td align=\"center\">A2（非运算（NOT））</td>\n<td align=\"center\">¬0&#x3D;1</td>\n<td align=\"center\">¬1&#x3D;0</td>\n<td align=\"center\">非运算的基本规则</td>\n</tr>\n<tr>\n<td align=\"center\">A3（与 &#x2F; 或运算（AND&#x2F;OR））</td>\n<td align=\"center\">0·0&#x3D;0</td>\n<td align=\"center\">1+1&#x3D;1</td>\n<td align=\"center\">与 &#x2F; 或运算的边界情况</td>\n</tr>\n<tr>\n<td align=\"center\">A4（与 &#x2F; 或运算（AND&#x2F;OR））</td>\n<td align=\"center\">1·1&#x3D;1</td>\n<td align=\"center\">0+0&#x3D;0</td>\n<td align=\"center\">与 &#x2F; 或运算的边界情况</td>\n</tr>\n<tr>\n<td align=\"center\">A5（与 &#x2F; 或运算（AND&#x2F;OR））</td>\n<td align=\"center\">0·1&#x3D;1·0&#x3D;0</td>\n<td align=\"center\">1+0&#x3D;0+1&#x3D;1</td>\n<td align=\"center\">与 &#x2F; 或运算的交换性边界情况</td>\n</tr>\n</tbody></table>\n</li>\n<li>核心定理（可通过公理推导，需记忆）<br>布尔代数的定理是简化方程的关键，常用定理及对偶定理如下表（B、C、D 为布尔变量）：<table>\n<thead>\n<tr>\n<th align=\"center\">定理名</th>\n<th align=\"center\">定理内容</th>\n<th align=\"center\">对偶定理（T’）</th>\n<th align=\"center\">含义说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">Identity Theorem（同一律）</td>\n<td align=\"center\">B·1&#x3D;B；B+0&#x3D;B</td>\n<td align=\"center\">B+1&#x3D;1；B·0&#x3D;0</td>\n<td align=\"center\">与 1 相乘 &#x2F; 或 0 相加，结果不变</td>\n</tr>\n<tr>\n<td align=\"center\">Null Element Theorem（零律）</td>\n<td align=\"center\">B·0&#x3D;0；B+1&#x3D;1</td>\n<td align=\"center\">B+0&#x3D;0；B·1&#x3D;1</td>\n<td align=\"center\">与 0 相乘 &#x2F; 或 1 相加，结果为 0&#x2F;1</td>\n</tr>\n<tr>\n<td align=\"center\">Idempotency Theorem（幂等律）</td>\n<td align=\"center\">B·B&#x3D;B；B+B&#x3D;B</td>\n<td align=\"center\">B+B&#x3D;B；B·B&#x3D;B</td>\n<td align=\"center\">与 &#x2F; 或自身，结果不变</td>\n</tr>\n<tr>\n<td align=\"center\">Involution Theorem（对合律）</td>\n<td align=\"center\">¬(¬B)&#x3D;B</td>\n<td align=\"center\">¬(¬B)&#x3D;B</td>\n<td align=\"center\">两次非运算，结果还原</td>\n</tr>\n<tr>\n<td align=\"center\">Complement theorem（互补律）</td>\n<td align=\"center\">B·¬B&#x3D;0；B+¬B&#x3D;1</td>\n<td align=\"center\">B+¬B&#x3D;1；B·¬B&#x3D;0</td>\n<td align=\"center\">与自身非相乘为 0，相加为 1</td>\n</tr>\n<tr>\n<td align=\"center\">Commutativity（交换律）</td>\n<td align=\"center\">B·C&#x3D;C·B；B+C&#x3D;C+B</td>\n<td align=\"center\">B+C&#x3D;C+B；B·C&#x3D;C·B</td>\n<td align=\"center\">与 &#x2F; 或运算的顺序不影响结果</td>\n</tr>\n<tr>\n<td align=\"center\">Associativity（结合律）</td>\n<td align=\"center\">(B·C)·D&#x3D;B·(C·D)；(B+C)+D&#x3D;B+(C+D)</td>\n<td align=\"center\">(B+C)+D&#x3D;B+(C+D)；(B·C)·D&#x3D;B·(C·D)</td>\n<td align=\"center\">与 &#x2F; 或运算的分组不影响结果</td>\n</tr>\n<tr>\n<td align=\"center\">Distributivity（分配律）</td>\n<td align=\"center\">B·(C+D)&#x3D;B·C+B·D；B+C·D&#x3D;(B+C)·(B+D)</td>\n<td align=\"center\">B+(C·D)&#x3D;(B+C)·(B+D)；B·(C+D)&#x3D;B·C+B·D</td>\n<td align=\"center\">与对或 &#x2F; 或对与的分配规则</td>\n</tr>\n<tr>\n<td align=\"center\">Covering（覆盖律）</td>\n<td align=\"center\">B·(B+C)&#x3D;B；B+(B·C)&#x3D;B</td>\n<td align=\"center\">B+(B·C)&#x3D;B；B·(B+C)&#x3D;B</td>\n<td align=\"center\">变量与自身和 &#x2F; 积，结果为自身</td>\n</tr>\n<tr>\n<td align=\"center\">Combining（合并律）</td>\n<td align=\"center\">B·C+B·¬C&#x3D;B；(B+C)·(B+¬C)&#x3D;B</td>\n<td align=\"center\">(B+C)·(B+¬C)&#x3D;B；B·C+B·¬C&#x3D;B</td>\n<td align=\"center\">提取相同变量，合并不同变量</td>\n</tr>\n<tr>\n<td align=\"center\">Consensus（共识律）</td>\n<td align=\"center\">B·C+¬B·D+C·D&#x3D;B·C+¬B·D；(B+C)·(¬B+D)·(C+D)&#x3D;(B+C)·(¬B+D)</td>\n<td align=\"center\">(B+C)·(¬B+D)·(C+D)&#x3D;(B+C)·(¬B+D)；B·C+¬B·D+C·D&#x3D;B·C+¬B·D</td>\n<td align=\"center\">消除冗余的共识项</td>\n</tr>\n<tr>\n<td align=\"center\">De Morgan’s Theorem（德摩根定律）</td>\n<td align=\"center\">¬(B·C)&#x3D;¬B+¬C；¬(B+C)&#x3D;¬B·¬C</td>\n<td align=\"center\">¬(B+C)&#x3D;¬B·¬C；¬(B·C)&#x3D;¬B+¬C</td>\n<td align=\"center\">与的非等于非的或，或的非等于非的与</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n</li>\n<li>数字构建块<ol>\n<li>组合逻辑电路<ol>\n<li>核心特性：无记忆功能，输出仅由当前输入决定，包含输入（如 A、B、C）、输出（如 Y、Z）和内部节点（如 n1），通过电路元素（E1、E2、E3）实现逻辑关系，可用布尔方程描述（如 n1&#x3D;E1 (A,B)、Z&#x3D;E2 (A,C)、Y&#x3D;E3 (n1,B,Z)）</li>\n<li>常用组件：<ol>\n<li>多路复用器（Mux）：从 N 个输入中选择 1 个输出，需log(2)N位选择信号（S）。以 2:1 Mux 为例，选择信号 S&#x3D;0 时输出 D0，S&#x3D;1 时输出 D1，其真值表如下：<table>\n<thead>\n<tr>\n<th align=\"center\">S</th>\n<th align=\"center\">D1</th>\n<th align=\"center\">D0</th>\n<th align=\"center\">Y</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n</tr>\n</tbody></table>\n</li>\n<li>解码器：N 个输入对应2^N个输出，采用 “独热编码”（仅 1 个输出为高电平）。以 2:4 Decoder 为例，输入 A1、A0 控制输出 Y3-Y0，真值表关键逻辑为：A1A0&#x3D;00 → Y0&#x3D;1；A1A0&#x3D;01 → Y1&#x3D;1；A1A0 &#x3D; 10 → Y2&#x3D;1；A1A0&#x3D;11 → Y3&#x3D;1</li>\n<li>移位器：分三类，具体功能及示例（输入 11001）如下：<table>\n<thead>\n<tr>\n<th align=\"center\">类型</th>\n<th align=\"center\">功能</th>\n<th align=\"center\">示例（输入 11001）</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">逻辑移位器</td>\n<td align=\"center\">左右移位，空位补 0</td>\n<td align=\"center\">右移 2 位：11001&gt;&gt;2&#x3D;00110；左移 2 位：11001&lt;&lt;2&#x3D;00100</td>\n</tr>\n<tr>\n<td align=\"center\">算术移位器</td>\n<td align=\"center\">左移同逻辑移位，右移空位补最高有效位（MSB）</td>\n<td align=\"center\">右移 2 位：11001&gt;&gt;&gt;2&#x3D;11110；左移 2 位：11001&lt;&lt;&lt;2&#x3D;00100</td>\n</tr>\n<tr>\n<td align=\"center\">旋转移位器</td>\n<td align=\"center\">循环移位，移出位补到另一端</td>\n<td align=\"center\">右旋转 2 位：11001 ROR 2&#x3D;01110；左旋转 2 位：11001 ROL 2&#x3D;00111</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>时序逻辑电路<ol>\n<li>核心特性：有短期记忆功能，通过输出到输入的反馈存储信息，能为事件提供时序顺序</li>\n<li>基础电路：双稳态电路，可存储 1 位状态（Q），存在两种稳定状态：Q&#x3D;0 时¬Q&#x3D;1；Q&#x3D;1 时¬Q&#x3D;0，但无输入控制状态</li>\n<li>常用组件<ol>\n<li>S-R 锁存器：含置位（S）、复位（R）输入，四种工作状态如下：<ol>\n<li>S&#x3D;1、R&#x3D;0：置位，Q&#x3D;1、¬Q&#x3D;0</li>\n<li>S&#x3D;0、R&#x3D;1：复位，Q&#x3D;0、¬Q&#x3D;1</li>\n<li>S&#x3D;0、R&#x3D;0：保持，Q&#x3D;Q_prev（前一状态）</li>\n<li>S&#x3D;1、R&#x3D;1：<strong>无效</strong>，Q&#x3D;0、¬Q&#x3D;0（Q≠¬Q）</li>\n</ol>\n</li>\n<li>D 锁存器：含时钟（CLK）、数据（D）输入，<code>避免 S-R 锁存器的无效状态</code>：<ol>\n<li>CLK&#x3D;1：透明模式，D 直接传递到 Q</li>\n<li>CLK&#x3D;0：不透明模式，Q 保持前一状态（Q_prev）</li>\n</ol>\n</li>\n<li>D 触发器：边沿触发（仅时钟上升沿有效），输入为 CLK 和 D<ol>\n<li>时钟从 0→1（上升沿）：采样 D 值并传递到 Q</li>\n<li>其他时刻：Q 保持前一状态，仅在上升沿变化</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>算术组件<ol>\n<li>加法器<ol>\n<li>半加器：仅处理 2 位输入（A、B），输出和（S）与进位输出（Cout），真值表如下：<table>\n<thead>\n<tr>\n<th align=\"center\">A</th>\n<th align=\"center\">B</th>\n<th align=\"center\">Cout</th>\n<th align=\"center\">S</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n</tr>\n<tr>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n<td align=\"center\">0</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">1</td>\n<td align=\"center\">0</td>\n</tr>\n</tbody></table>\n</li>\n<li>全加器：在半加器基础上增加进位输入（Cin），处理 3 位输入（A、B、Cin），输出和（S）与进位输出（Cout），真值表含 8 种输入组合，关键逻辑为 S&#x3D;A⊕B⊕Cin、Cout&#x3D;AB+ACin+BCin</li>\n<li>纹波进位加法器：将多个 1 位全加器链式连接，进位信号从低位向高位 “ripple” 传递，<code>缺点是速度慢（依赖进位传递延迟）</code></li>\n</ol>\n</li>\n<li>减法器<ol>\n<li>含输入 X（被减数）、Y（减数）、借位输入（Bin），输出差值（D）、借位输出（Bout），核心逻辑如下：<ol>\n<li>无 Bin 时：D&#x3D;X⊕Y，Bout&#x3D;X⋅Y</li>\n<li>有 Bin 时，D&#x3D;X⊕Y⊕Bin，Bout&#x3D;XBin+XY+YBin</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>算术逻辑单元（ALU）<ol>\n<li>通过 2 位控制信号（ALUControl [1:0]）选择运算功能，是处理器核心算术逻辑组件，功能表如下：<table>\n<thead>\n<tr>\n<th align=\"center\">ALUControl[1:0]</th>\n<th align=\"center\">功能</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">00</td>\n<td align=\"center\">加法（Add）</td>\n</tr>\n<tr>\n<td align=\"center\">01</td>\n<td align=\"center\">减法（Subtract）</td>\n</tr>\n<tr>\n<td align=\"center\">10</td>\n<td align=\"center\">与运算（AND）</td>\n</tr>\n<tr>\n<td align=\"center\">11</td>\n<td align=\"center\">或运算（OR）</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>其他数字模块<ol>\n<li>计数器<ol>\n<li>功能：在每个时钟边沿实现计数递增，循环遍历数字（如 000→001→010→…→111→000…）</li>\n<li>应用：数字时钟显示、程序计数器（跟踪当前执行指令地址）</li>\n<li>结构：含时钟（CLK）、复位（Reset）输入和状态输出（Q），复位信号可重置计数状态</li>\n</ol>\n</li>\n<li>移位寄存器<ol>\n<li>功能：每个时钟边沿控制 1 位数据移入（Sin）和移出（Sout），实现串行数据与并行数据的转换（串并转换）</li>\n<li>结构：含串行输入（Sin）、串行输出（Sout）、时钟（CLK）和并行输出（Q0~QN-1）</li>\n</ol>\n</li>\n<li>存储阵列<ol>\n<li>核心功能：高效存储大量数据，通过 N 位地址访问 M 位数据（地址→数据映射）</li>\n<li>分类：<table>\n<thead>\n<tr>\n<th align=\"center\">类型</th>\n<th align=\"center\">特性</th>\n<th align=\"center\">存储原理</th>\n<th align=\"center\">应用</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">DRAM（动态 RAM）</td>\n<td align=\"center\">易失性（断电失数据）、速度较慢、成本低</td>\n<td align=\"center\">电容存储电荷</td>\n<td align=\"center\">计算机主内存</td>\n</tr>\n<tr>\n<td align=\"center\">SRAM（静态 RAM）</td>\n<td align=\"center\">易失性、速度快、成本高</td>\n<td align=\"center\">交叉耦合反相器</td>\n<td align=\"center\">高速缓存（Cache）</td>\n</tr>\n<tr>\n<td align=\"center\">ROM（只读存储器）</td>\n<td align=\"center\">非易失性（断电保数据）、读快写难 &#x2F; 慢</td>\n<td align=\"center\">制造时编程或电编程</td>\n<td align=\"center\">相机闪存、U 盘</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n</li>\n<li>逻辑阵列<ol>\n<li>PLA（可编程逻辑阵列）：由 “与阵列” 和 “或阵列” 组成，仅实现组合逻辑，内部连接固定，通过编程配置逻辑功能（如实现 AB+AC、NC+RC 等布尔表达式）</li>\n<li>FPGA（现场可编程门阵列）：由逻辑元素（LEs）阵列构成，可实现组合逻辑和时序逻辑，内部连接可编程，部分 FPGA 还集成乘法器、RAM 等模块，灵活性高</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"今日总结\"><a href=\"#今日总结\" class=\"headerlink\" title=\"今日总结\"></a>今日总结</h2><ol>\n<li>今天开始上了后半学期的新课，教课的是一位印尼的老师，虽然听口语还是有点困难，但是一节课下来也完全知道在讲什么，而且明显感觉老师的教学比较活跃，课堂气氛不错，继续努力吧</li>\n<li>办理了住宿证明，以及在读证明，只差学生证了</li>\n<li>保险起见，今天的网球活动就不参加了</li>\n<li>英语学习</li>\n</ol>\n"},{"title":"2025.9.15","date":"2025-09-15T03:51:17.000Z","_content":"# Overview\n1. 周末总结\n2. 今日收获\n## 周末总结\n1. 录好了需要上交的吉他视频\n2. 带摩羯检查，确认没有问题\n3. 本学期第一次志愿者活动，抓了一只毛发打结非常严重的小狗给剃毛。（就是以后天气热的情况下再也不穿防水服了，差点给我干脱水了，实在太闷热了）\n4. 周日晚上完成了第一周的10km，虽然配速有点慢，不过能跑下来就好\n## 9.15学习收获\n1. 今天开始跟一个系列视频（不看字幕听懂英语剧）\n2. 今天把这周的课件都预习完了\n### 数据科学（统计）\n1. **中心极限定理（CLT）核心结论（在大样本条件下）**\n   2. 样本均值近似正态分布\n   3. 样本均值接近总体均值\n   4. 样本均值方差 = 总体方差 / 样本量\n5. **均值标准误差（SEM）**\n   6. 计算公式：SEM = 总体标准差 / 样本量 ** 1/2\n   7. 近似方法：样本量足够大时，用样本标准差代替总体标准差\n8. **\\*基于单个样本估计总体均值的步骤：**\n   9. 按总体偏度确定样本量\n   10. 随机抽取独立样本\n   11. 计算样本均值与标准差\n   12. 用样本标准差估算SEM\n   13. 用SEM构建样本均值的置信区间\n### 概率\n1. **条件概率**\n   2. P(A|B) = P(A∩B) / P(B) \\[P(B) != 0]\n3. **乘法原理**\n   4. P(A∩B) = P(A)P(B|A) = P(B)P(A|B) \\[P(A) != 0,P(B) != 0]\n   5. 链式法则：P(A1 ∩ A2 ∩ ··· ∩ An) = P(A1)P(A2 | A1)P(A3 | A1 ∩ A2) ··· P(An)P(An | A1 ∩ A2 ∩ ··· ∩ An-1)\n6. **全概率公式**\n   7. 常用应用：将样本空间划分成两个区域，从而有：P(A) = P(A|B)P(B) + P(A|B^)P(B^)\n8. **\\*\\*贝叶斯公式**\n   9. 常用于：某一情况发生后，两个前提之一发生的概率，P(C|A) = P(A|C)P(C) / \\[P(A|C)P(C) + P(A|C^)P(C^)]\n   10. \\* 核心思想：在知道某个结果发生后，计算对某一前提发生的概率\n11. **独立事件**\n    12. 定义：P(A∩B) = P(A)P(B)，P(A|B) = P(A),P(B|A) = P(B)\n    13. \\*注意：独立不等于对立,不是一个发生了另一个就不会发生\n           ","source":"_posts/2025-9-15.md","raw":"---\ntitle: 2025.9.15\ndate: 2025-09-15 11:51:17\ntags:\n---\n# Overview\n1. 周末总结\n2. 今日收获\n## 周末总结\n1. 录好了需要上交的吉他视频\n2. 带摩羯检查，确认没有问题\n3. 本学期第一次志愿者活动，抓了一只毛发打结非常严重的小狗给剃毛。（就是以后天气热的情况下再也不穿防水服了，差点给我干脱水了，实在太闷热了）\n4. 周日晚上完成了第一周的10km，虽然配速有点慢，不过能跑下来就好\n## 9.15学习收获\n1. 今天开始跟一个系列视频（不看字幕听懂英语剧）\n2. 今天把这周的课件都预习完了\n### 数据科学（统计）\n1. **中心极限定理（CLT）核心结论（在大样本条件下）**\n   2. 样本均值近似正态分布\n   3. 样本均值接近总体均值\n   4. 样本均值方差 = 总体方差 / 样本量\n5. **均值标准误差（SEM）**\n   6. 计算公式：SEM = 总体标准差 / 样本量 ** 1/2\n   7. 近似方法：样本量足够大时，用样本标准差代替总体标准差\n8. **\\*基于单个样本估计总体均值的步骤：**\n   9. 按总体偏度确定样本量\n   10. 随机抽取独立样本\n   11. 计算样本均值与标准差\n   12. 用样本标准差估算SEM\n   13. 用SEM构建样本均值的置信区间\n### 概率\n1. **条件概率**\n   2. P(A|B) = P(A∩B) / P(B) \\[P(B) != 0]\n3. **乘法原理**\n   4. P(A∩B) = P(A)P(B|A) = P(B)P(A|B) \\[P(A) != 0,P(B) != 0]\n   5. 链式法则：P(A1 ∩ A2 ∩ ··· ∩ An) = P(A1)P(A2 | A1)P(A3 | A1 ∩ A2) ··· P(An)P(An | A1 ∩ A2 ∩ ··· ∩ An-1)\n6. **全概率公式**\n   7. 常用应用：将样本空间划分成两个区域，从而有：P(A) = P(A|B)P(B) + P(A|B^)P(B^)\n8. **\\*\\*贝叶斯公式**\n   9. 常用于：某一情况发生后，两个前提之一发生的概率，P(C|A) = P(A|C)P(C) / \\[P(A|C)P(C) + P(A|C^)P(C^)]\n   10. \\* 核心思想：在知道某个结果发生后，计算对某一前提发生的概率\n11. **独立事件**\n    12. 定义：P(A∩B) = P(A)P(B)，P(A|B) = P(A),P(B|A) = P(B)\n    13. \\*注意：独立不等于对立,不是一个发生了另一个就不会发生\n           ","slug":"2025-9-15","published":1,"updated":"2025-11-18T19:39:17.137Z","comments":1,"layout":"post","photos":[],"_id":"cuid7FykKcx-iynTiNVsTMsqI","content":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>周末总结</li>\n<li>今日收获</li>\n</ol>\n<h2 id=\"周末总结\"><a href=\"#周末总结\" class=\"headerlink\" title=\"周末总结\"></a>周末总结</h2><ol>\n<li>录好了需要上交的吉他视频</li>\n<li>带摩羯检查，确认没有问题</li>\n<li>本学期第一次志愿者活动，抓了一只毛发打结非常严重的小狗给剃毛。（就是以后天气热的情况下再也不穿防水服了，差点给我干脱水了，实在太闷热了）</li>\n<li>周日晚上完成了第一周的10km，虽然配速有点慢，不过能跑下来就好</li>\n</ol>\n<h2 id=\"9-15学习收获\"><a href=\"#9-15学习收获\" class=\"headerlink\" title=\"9.15学习收获\"></a>9.15学习收获</h2><ol>\n<li>今天开始跟一个系列视频（不看字幕听懂英语剧）</li>\n<li>今天把这周的课件都预习完了</li>\n</ol>\n<h3 id=\"数据科学（统计）\"><a href=\"#数据科学（统计）\" class=\"headerlink\" title=\"数据科学（统计）\"></a>数据科学（统计）</h3><ol>\n<li><strong>中心极限定理（CLT）核心结论（在大样本条件下）</strong><ol start=\"2\">\n<li>样本均值近似正态分布</li>\n<li>样本均值接近总体均值</li>\n<li>样本均值方差 &#x3D; 总体方差 &#x2F; 样本量</li>\n</ol>\n</li>\n<li><strong>均值标准误差（SEM）</strong><ol start=\"6\">\n<li>计算公式：SEM &#x3D; 总体标准差 &#x2F; 样本量 ** 1&#x2F;2</li>\n<li>近似方法：样本量足够大时，用样本标准差代替总体标准差</li>\n</ol>\n</li>\n<li><strong>*基于单个样本估计总体均值的步骤：</strong><ol start=\"9\">\n<li>按总体偏度确定样本量</li>\n<li>随机抽取独立样本</li>\n<li>计算样本均值与标准差</li>\n<li>用样本标准差估算SEM</li>\n<li>用SEM构建样本均值的置信区间</li>\n</ol>\n</li>\n</ol>\n<h3 id=\"概率\"><a href=\"#概率\" class=\"headerlink\" title=\"概率\"></a>概率</h3><ol>\n<li><strong>条件概率</strong><ol start=\"2\">\n<li>P(A|B) &#x3D; P(A∩B) &#x2F; P(B) [P(B) !&#x3D; 0]</li>\n</ol>\n</li>\n<li><strong>乘法原理</strong><ol start=\"4\">\n<li>P(A∩B) &#x3D; P(A)P(B|A) &#x3D; P(B)P(A|B) [P(A) !&#x3D; 0,P(B) !&#x3D; 0]</li>\n<li>链式法则：P(A1 ∩ A2 ∩ ··· ∩ An) &#x3D; P(A1)P(A2 | A1)P(A3 | A1 ∩ A2) ··· P(An)P(An | A1 ∩ A2 ∩ ··· ∩ An-1)</li>\n</ol>\n</li>\n<li><strong>全概率公式</strong><ol start=\"7\">\n<li>常用应用：将样本空间划分成两个区域，从而有：P(A) &#x3D; P(A|B)P(B) + P(A|B^)P(B^)</li>\n</ol>\n</li>\n<li><strong>**贝叶斯公式</strong><ol start=\"9\">\n<li>常用于：某一情况发生后，两个前提之一发生的概率，P(C|A) &#x3D; P(A|C)P(C) &#x2F; [P(A|C)P(C) + P(A|C^)P(C^)]</li>\n<li>* 核心思想：在知道某个结果发生后，计算对某一前提发生的概率</li>\n</ol>\n</li>\n<li><strong>独立事件</strong><ol start=\"12\">\n<li>定义：P(A∩B) &#x3D; P(A)P(B)，P(A|B) &#x3D; P(A),P(B|A) &#x3D; P(B)</li>\n<li>*注意：独立不等于对立,不是一个发生了另一个就不会发生</li>\n</ol>\n</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>周末总结</li>\n<li>今日收获</li>\n</ol>\n<h2 id=\"周末总结\"><a href=\"#周末总结\" class=\"headerlink\" title=\"周末总结\"></a>周末总结</h2><ol>\n<li>录好了需要上交的吉他视频</li>\n<li>带摩羯检查，确认没有问题</li>\n<li>本学期第一次志愿者活动，抓了一只毛发打结非常严重的小狗给剃毛。（就是以后天气热的情况下再也不穿防水服了，差点给我干脱水了，实在太闷热了）</li>\n<li>周日晚上完成了第一周的10km，虽然配速有点慢，不过能跑下来就好</li>\n</ol>\n<h2 id=\"9-15学习收获\"><a href=\"#9-15学习收获\" class=\"headerlink\" title=\"9.15学习收获\"></a>9.15学习收获</h2><ol>\n<li>今天开始跟一个系列视频（不看字幕听懂英语剧）</li>\n<li>今天把这周的课件都预习完了</li>\n</ol>\n<h3 id=\"数据科学（统计）\"><a href=\"#数据科学（统计）\" class=\"headerlink\" title=\"数据科学（统计）\"></a>数据科学（统计）</h3><ol>\n<li><strong>中心极限定理（CLT）核心结论（在大样本条件下）</strong><ol start=\"2\">\n<li>样本均值近似正态分布</li>\n<li>样本均值接近总体均值</li>\n<li>样本均值方差 &#x3D; 总体方差 &#x2F; 样本量</li>\n</ol>\n</li>\n<li><strong>均值标准误差（SEM）</strong><ol start=\"6\">\n<li>计算公式：SEM &#x3D; 总体标准差 &#x2F; 样本量 ** 1&#x2F;2</li>\n<li>近似方法：样本量足够大时，用样本标准差代替总体标准差</li>\n</ol>\n</li>\n<li><strong>*基于单个样本估计总体均值的步骤：</strong><ol start=\"9\">\n<li>按总体偏度确定样本量</li>\n<li>随机抽取独立样本</li>\n<li>计算样本均值与标准差</li>\n<li>用样本标准差估算SEM</li>\n<li>用SEM构建样本均值的置信区间</li>\n</ol>\n</li>\n</ol>\n<h3 id=\"概率\"><a href=\"#概率\" class=\"headerlink\" title=\"概率\"></a>概率</h3><ol>\n<li><strong>条件概率</strong><ol start=\"2\">\n<li>P(A|B) &#x3D; P(A∩B) &#x2F; P(B) [P(B) !&#x3D; 0]</li>\n</ol>\n</li>\n<li><strong>乘法原理</strong><ol start=\"4\">\n<li>P(A∩B) &#x3D; P(A)P(B|A) &#x3D; P(B)P(A|B) [P(A) !&#x3D; 0,P(B) !&#x3D; 0]</li>\n<li>链式法则：P(A1 ∩ A2 ∩ ··· ∩ An) &#x3D; P(A1)P(A2 | A1)P(A3 | A1 ∩ A2) ··· P(An)P(An | A1 ∩ A2 ∩ ··· ∩ An-1)</li>\n</ol>\n</li>\n<li><strong>全概率公式</strong><ol start=\"7\">\n<li>常用应用：将样本空间划分成两个区域，从而有：P(A) &#x3D; P(A|B)P(B) + P(A|B^)P(B^)</li>\n</ol>\n</li>\n<li><strong>**贝叶斯公式</strong><ol start=\"9\">\n<li>常用于：某一情况发生后，两个前提之一发生的概率，P(C|A) &#x3D; P(A|C)P(C) &#x2F; [P(A|C)P(C) + P(A|C^)P(C^)]</li>\n<li>* 核心思想：在知道某个结果发生后，计算对某一前提发生的概率</li>\n</ol>\n</li>\n<li><strong>独立事件</strong><ol start=\"12\">\n<li>定义：P(A∩B) &#x3D; P(A)P(B)，P(A|B) &#x3D; P(A),P(B|A) &#x3D; P(B)</li>\n<li>*注意：独立不等于对立,不是一个发生了另一个就不会发生</li>\n</ol>\n</li>\n</ol>\n"},{"title":"2025.9.11","date":"2025-09-11T03:21:43.000Z","_content":"# Overview\n今天学习了Markdown的一些基本语法  \nMarkdown的核心理念是：利用简单的符号在打字的同时完成排版  \nMarkdown的优势：  \n通用性（是很多知识管理软件的基础，博客、论坛、公众号都原生支持Markdown，.md的文件在任何电脑和系统上都能打开和阅读）；    \n`是AI时代的标准沟通语言（AI所输出的内容格式，以及AI提示词的最佳格式）；`  \n可以转换成Word、PPT、PDF等主流文件格式\n## Markdown写法\n### 标题\n1. \"#\" + 空格 + 一级标题\n2. \"##\" + 空格 + 二级标题\n3. · · · 以此类推，几个 # 就是几级标题\n### 文字\n1. \\*\\* 加粗字 \\*\\*\n2. \\* 斜体字 \\*\n3. \\*\\*\\* 加粗斜体字 \\*\\*\\*\n4. \\` 高亮文字 \\`\n5. \\~\\~ 删除线文字 \\~\\~\n### 列表\n1. 无序列表： 减号 + 空格 + 列表项\n2. 有序列表： 数字 + 空格 + 列表项号\n3. 任务列表（非原生）：  \n\\-[ ] 未完成任务  \n\\-[x] 已完成任务\n### 引用\n1. \\> 引用内容\n2. \\>\\> 嵌套引用\n3. \\>\\>\\> 以此类推\n### 强制换行\n第一行 + 两个空格  \n第二行\n### 分割线\n\\-\\-\\-  \n(注意：使用分割线要与上下空一行，避免与上下文本产生格式冲突)\n### 链接\n1. 普通链接  \n\\[链接名称](网址)\n2. 直接链接  \n\\<网址>\n3. 锚点链接（当多次用到同一链接时）  \n\\[文字标题][锚点名称]  \n文章结尾：  \n[锚点名称]:网址\n### 注脚\n要添加注脚的文字1[^01]  \n要添加注脚的文字2[^02]  \n文章结尾：  \n[^01]: 注脚内容1  \n[^02]: 注脚内容2\n### 图片\n1. 只插入图片  \n\\!\\[图片描述](图片的网络链接、本地的绝对路径或相对路径)  \n（*注意：方括号里的文字是当图片显示不出来时会打的文字）\n2. 带链接的图片  \n\\[插入图片的代码格式](链接网址)\n### 表格\n\\| 名字 \\| 姓氏 \\| 电子邮箱 \\|（表头）  \n\\| --- \\| --- \\| --- \\|（分割行）  \n\\| 名字1 \\| 姓氏1 \\| 邮箱1 \\|（数据内容）  \n\\| 名字2 \\| 姓氏2 \\| 邮箱2 \\|\n  \n\\| :--- \\| :---: \\| ---: \\|（分割行的对齐写法）  \n\\| 左对齐 \\| 居中对齐 \\| 右对齐 \\|\n### 代码\n1. 行内代码  \n文字 \\`代码1\\` 文字 \\`代码2\\`\n2. 代码块  \n\\`\\`\\`代码类型  \n代码内容  \n\\`\\`\\`\n","source":"_posts/2025-9-11.md","raw":"---\ntitle: 2025.9.11\ndate: 2025-09-11 11:21:43\ntags:\n---\n# Overview\n今天学习了Markdown的一些基本语法  \nMarkdown的核心理念是：利用简单的符号在打字的同时完成排版  \nMarkdown的优势：  \n通用性（是很多知识管理软件的基础，博客、论坛、公众号都原生支持Markdown，.md的文件在任何电脑和系统上都能打开和阅读）；    \n`是AI时代的标准沟通语言（AI所输出的内容格式，以及AI提示词的最佳格式）；`  \n可以转换成Word、PPT、PDF等主流文件格式\n## Markdown写法\n### 标题\n1. \"#\" + 空格 + 一级标题\n2. \"##\" + 空格 + 二级标题\n3. · · · 以此类推，几个 # 就是几级标题\n### 文字\n1. \\*\\* 加粗字 \\*\\*\n2. \\* 斜体字 \\*\n3. \\*\\*\\* 加粗斜体字 \\*\\*\\*\n4. \\` 高亮文字 \\`\n5. \\~\\~ 删除线文字 \\~\\~\n### 列表\n1. 无序列表： 减号 + 空格 + 列表项\n2. 有序列表： 数字 + 空格 + 列表项号\n3. 任务列表（非原生）：  \n\\-[ ] 未完成任务  \n\\-[x] 已完成任务\n### 引用\n1. \\> 引用内容\n2. \\>\\> 嵌套引用\n3. \\>\\>\\> 以此类推\n### 强制换行\n第一行 + 两个空格  \n第二行\n### 分割线\n\\-\\-\\-  \n(注意：使用分割线要与上下空一行，避免与上下文本产生格式冲突)\n### 链接\n1. 普通链接  \n\\[链接名称](网址)\n2. 直接链接  \n\\<网址>\n3. 锚点链接（当多次用到同一链接时）  \n\\[文字标题][锚点名称]  \n文章结尾：  \n[锚点名称]:网址\n### 注脚\n要添加注脚的文字1[^01]  \n要添加注脚的文字2[^02]  \n文章结尾：  \n[^01]: 注脚内容1  \n[^02]: 注脚内容2\n### 图片\n1. 只插入图片  \n\\!\\[图片描述](图片的网络链接、本地的绝对路径或相对路径)  \n（*注意：方括号里的文字是当图片显示不出来时会打的文字）\n2. 带链接的图片  \n\\[插入图片的代码格式](链接网址)\n### 表格\n\\| 名字 \\| 姓氏 \\| 电子邮箱 \\|（表头）  \n\\| --- \\| --- \\| --- \\|（分割行）  \n\\| 名字1 \\| 姓氏1 \\| 邮箱1 \\|（数据内容）  \n\\| 名字2 \\| 姓氏2 \\| 邮箱2 \\|\n  \n\\| :--- \\| :---: \\| ---: \\|（分割行的对齐写法）  \n\\| 左对齐 \\| 居中对齐 \\| 右对齐 \\|\n### 代码\n1. 行内代码  \n文字 \\`代码1\\` 文字 \\`代码2\\`\n2. 代码块  \n\\`\\`\\`代码类型  \n代码内容  \n\\`\\`\\`\n","slug":"2025-9-11","published":1,"updated":"2025-11-18T19:39:17.139Z","comments":1,"layout":"post","photos":[],"_id":"cuidIZxVjQUyuIZvRMXNL1AhG","content":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><p>今天学习了Markdown的一些基本语法<br>Markdown的核心理念是：利用简单的符号在打字的同时完成排版<br>Markdown的优势：<br>通用性（是很多知识管理软件的基础，博客、论坛、公众号都原生支持Markdown，.md的文件在任何电脑和系统上都能打开和阅读）；<br><code>是AI时代的标准沟通语言（AI所输出的内容格式，以及AI提示词的最佳格式）；</code><br>可以转换成Word、PPT、PDF等主流文件格式</p>\n<h2 id=\"Markdown写法\"><a href=\"#Markdown写法\" class=\"headerlink\" title=\"Markdown写法\"></a>Markdown写法</h2><h3 id=\"标题\"><a href=\"#标题\" class=\"headerlink\" title=\"标题\"></a>标题</h3><ol>\n<li>“#” + 空格 + 一级标题</li>\n<li>“##” + 空格 + 二级标题</li>\n<li>· · · 以此类推，几个 # 就是几级标题</li>\n</ol>\n<h3 id=\"文字\"><a href=\"#文字\" class=\"headerlink\" title=\"文字\"></a>文字</h3><ol>\n<li>** 加粗字 **</li>\n<li>* 斜体字 *</li>\n<li>*** 加粗斜体字 ***</li>\n<li>` 高亮文字 `</li>\n<li>~~ 删除线文字 ~~</li>\n</ol>\n<h3 id=\"列表\"><a href=\"#列表\" class=\"headerlink\" title=\"列表\"></a>列表</h3><ol>\n<li>无序列表： 减号 + 空格 + 列表项</li>\n<li>有序列表： 数字 + 空格 + 列表项号</li>\n<li>任务列表（非原生）：<br>-[ ] 未完成任务<br>-[x] 已完成任务</li>\n</ol>\n<h3 id=\"引用\"><a href=\"#引用\" class=\"headerlink\" title=\"引用\"></a>引用</h3><ol>\n<li>&gt; 引用内容</li>\n<li>&gt;&gt; 嵌套引用</li>\n<li>&gt;&gt;&gt; 以此类推</li>\n</ol>\n<h3 id=\"强制换行\"><a href=\"#强制换行\" class=\"headerlink\" title=\"强制换行\"></a>强制换行</h3><p>第一行 + 两个空格<br>第二行</p>\n<h3 id=\"分割线\"><a href=\"#分割线\" class=\"headerlink\" title=\"分割线\"></a>分割线</h3><p>---<br>(注意：使用分割线要与上下空一行，避免与上下文本产生格式冲突)</p>\n<h3 id=\"链接\"><a href=\"#链接\" class=\"headerlink\" title=\"链接\"></a>链接</h3><ol>\n<li>普通链接<br>[链接名称](网址)</li>\n<li>直接链接<br>&lt;网址&gt;</li>\n<li>锚点链接（当多次用到同一链接时）<br>[文字标题][锚点名称]<br>文章结尾：<br>[锚点名称]:网址</li>\n</ol>\n<h3 id=\"注脚\"><a href=\"#注脚\" class=\"headerlink\" title=\"注脚\"></a>注脚</h3><p>要添加注脚的文字1[^01]<br>要添加注脚的文字2[^02]<br>文章结尾：<br>[^01]: 注脚内容1<br>[^02]: 注脚内容2</p>\n<h3 id=\"图片\"><a href=\"#图片\" class=\"headerlink\" title=\"图片\"></a>图片</h3><ol>\n<li>只插入图片<br>![图片描述](图片的网络链接、本地的绝对路径或相对路径)<br>（*注意：方括号里的文字是当图片显示不出来时会打的文字）</li>\n<li>带链接的图片<br>[插入图片的代码格式](链接网址)</li>\n</ol>\n<h3 id=\"表格\"><a href=\"#表格\" class=\"headerlink\" title=\"表格\"></a>表格</h3><p>| 名字 | 姓氏 | 电子邮箱 |（表头）<br>| — | — | — |（分割行）<br>| 名字1 | 姓氏1 | 邮箱1 |（数据内容）<br>| 名字2 | 姓氏2 | 邮箱2 |</p>\n<p>| :— | :—: | —: |（分割行的对齐写法）<br>| 左对齐 | 居中对齐 | 右对齐 |</p>\n<h3 id=\"代码\"><a href=\"#代码\" class=\"headerlink\" title=\"代码\"></a>代码</h3><ol>\n<li>行内代码<br>文字 `代码1` 文字 `代码2`</li>\n<li>代码块<br>```代码类型<br>代码内容<br>```</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><p>今天学习了Markdown的一些基本语法<br>Markdown的核心理念是：利用简单的符号在打字的同时完成排版<br>Markdown的优势：<br>通用性（是很多知识管理软件的基础，博客、论坛、公众号都原生支持Markdown，.md的文件在任何电脑和系统上都能打开和阅读）；<br><code>是AI时代的标准沟通语言（AI所输出的内容格式，以及AI提示词的最佳格式）；</code><br>可以转换成Word、PPT、PDF等主流文件格式</p>\n<h2 id=\"Markdown写法\"><a href=\"#Markdown写法\" class=\"headerlink\" title=\"Markdown写法\"></a>Markdown写法</h2><h3 id=\"标题\"><a href=\"#标题\" class=\"headerlink\" title=\"标题\"></a>标题</h3><ol>\n<li>“#” + 空格 + 一级标题</li>\n<li>“##” + 空格 + 二级标题</li>\n<li>· · · 以此类推，几个 # 就是几级标题</li>\n</ol>\n<h3 id=\"文字\"><a href=\"#文字\" class=\"headerlink\" title=\"文字\"></a>文字</h3><ol>\n<li>** 加粗字 **</li>\n<li>* 斜体字 *</li>\n<li>*** 加粗斜体字 ***</li>\n<li>` 高亮文字 `</li>\n<li>~~ 删除线文字 ~~</li>\n</ol>\n<h3 id=\"列表\"><a href=\"#列表\" class=\"headerlink\" title=\"列表\"></a>列表</h3><ol>\n<li>无序列表： 减号 + 空格 + 列表项</li>\n<li>有序列表： 数字 + 空格 + 列表项号</li>\n<li>任务列表（非原生）：<br>-[ ] 未完成任务<br>-[x] 已完成任务</li>\n</ol>\n<h3 id=\"引用\"><a href=\"#引用\" class=\"headerlink\" title=\"引用\"></a>引用</h3><ol>\n<li>&gt; 引用内容</li>\n<li>&gt;&gt; 嵌套引用</li>\n<li>&gt;&gt;&gt; 以此类推</li>\n</ol>\n<h3 id=\"强制换行\"><a href=\"#强制换行\" class=\"headerlink\" title=\"强制换行\"></a>强制换行</h3><p>第一行 + 两个空格<br>第二行</p>\n<h3 id=\"分割线\"><a href=\"#分割线\" class=\"headerlink\" title=\"分割线\"></a>分割线</h3><p>---<br>(注意：使用分割线要与上下空一行，避免与上下文本产生格式冲突)</p>\n<h3 id=\"链接\"><a href=\"#链接\" class=\"headerlink\" title=\"链接\"></a>链接</h3><ol>\n<li>普通链接<br>[链接名称](网址)</li>\n<li>直接链接<br>&lt;网址&gt;</li>\n<li>锚点链接（当多次用到同一链接时）<br>[文字标题][锚点名称]<br>文章结尾：<br>[锚点名称]:网址</li>\n</ol>\n<h3 id=\"注脚\"><a href=\"#注脚\" class=\"headerlink\" title=\"注脚\"></a>注脚</h3><p>要添加注脚的文字1[^01]<br>要添加注脚的文字2[^02]<br>文章结尾：<br>[^01]: 注脚内容1<br>[^02]: 注脚内容2</p>\n<h3 id=\"图片\"><a href=\"#图片\" class=\"headerlink\" title=\"图片\"></a>图片</h3><ol>\n<li>只插入图片<br>![图片描述](图片的网络链接、本地的绝对路径或相对路径)<br>（*注意：方括号里的文字是当图片显示不出来时会打的文字）</li>\n<li>带链接的图片<br>[插入图片的代码格式](链接网址)</li>\n</ol>\n<h3 id=\"表格\"><a href=\"#表格\" class=\"headerlink\" title=\"表格\"></a>表格</h3><p>| 名字 | 姓氏 | 电子邮箱 |（表头）<br>| — | — | — |（分割行）<br>| 名字1 | 姓氏1 | 邮箱1 |（数据内容）<br>| 名字2 | 姓氏2 | 邮箱2 |</p>\n<p>| :— | :—: | —: |（分割行的对齐写法）<br>| 左对齐 | 居中对齐 | 右对齐 |</p>\n<h3 id=\"代码\"><a href=\"#代码\" class=\"headerlink\" title=\"代码\"></a>代码</h3><ol>\n<li>行内代码<br>文字 `代码1` 文字 `代码2`</li>\n<li>代码块<br>```代码类型<br>代码内容<br>```</li>\n</ol>\n"},{"title":"2025.9.16","date":"2025-09-16T08:02:32.000Z","_content":"# Summary\n1. 今天把之前做的python的基础语法的笔记复习完了\n2. 今天通过用AI解决了在PyCharm中打开学校Jupyter实验文件运行不了的问题\n3. 找到了一个适合一个人学习的地方","source":"_posts/2025-9-16.md","raw":"---\ntitle: 2025.9.16\ndate: 2025-09-16 16:02:32\ntags:\n---\n# Summary\n1. 今天把之前做的python的基础语法的笔记复习完了\n2. 今天通过用AI解决了在PyCharm中打开学校Jupyter实验文件运行不了的问题\n3. 找到了一个适合一个人学习的地方","slug":"2025-9-16","published":1,"updated":"2025-11-18T19:39:17.135Z","comments":1,"layout":"post","photos":[],"_id":"cuidMpjuqCgxwS8Wf5pL0_onX","content":"<h1 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h1><ol>\n<li>今天把之前做的python的基础语法的笔记复习完了</li>\n<li>今天通过用AI解决了在PyCharm中打开学校Jupyter实验文件运行不了的问题</li>\n<li>找到了一个适合一个人学习的地方</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h1><ol>\n<li>今天把之前做的python的基础语法的笔记复习完了</li>\n<li>今天通过用AI解决了在PyCharm中打开学校Jupyter实验文件运行不了的问题</li>\n<li>找到了一个适合一个人学习的地方</li>\n</ol>\n"},{"title":"2025.10.30","date":"2025-10-29T08:25:23.000Z","_content":"\n# Overview\n1. 学习笔记\n2. 今日总结\n3. 摘录\n\n## 学习笔记\n\n### 概率\n1. 数据与数据表示\n   1. 图表类型：\n      1. 柱状图（Bar graph）\n      2. 饼图（Pie Chart）\n      3. 交叉表（Cross Table）：可以变成并排的簇状图（几个柱作为一个整体）或堆叠的分组条形图（一个柱上有几个不同的特性）\n      4. 直方图（Histogram）\n      5. 累积频率图（Ogive）：连接各区间上限累积百分比的线，展示累积频率分布\n      6. 茎叶图（Stem and Leaf Plot）：同时展示数据的分布和原始值（中间的主干数据加上两边的枝干数据）\n      7. 时间序列图（Time Series Plot）：横轴为时间，纵轴为序列值，展示数据随时间的变化趋势\n      8. 散点图（Scatterplot）：观测两个定量变量的关系，需关注关联方向（正 / 负）、形式（线性 / 非线性）、强度（紧密 / 松散）\n   2. 频率表\n      1. 分类数据频率表：列出类别及对应数量（频率），相对频率表则列出百分比（比例）\n         1. 频率表：  \n            | 舱位 | 数量 |  \n            | --- | --- |  \n            | 头等舱（First） | 324 |  \n            | 二等舱（Second） | 285 |  \n            | 三等舱（Third） | 710 |  \n            | 船员（Crew） | 889 |  \n         2. 相对频率表  \n             | 舱位 | 百分比（%） |  \n             | --- | --- |  \n             | 头等舱（First） | 14.67 |  \n             | 二等舱（Second） | 12.91 |  \n             | 三等舱（Third） | 32.16 |  \n             | 船员（Crew） | 40.26 |  \n      2. 数值数据频率表：\n         1. 构建规则：根据样本量n选择，如下表：\n            | 样本量（n） | 组数（k） |  \n            | --- | --- |  \n            | <50 | 5-7 |  \n            | 50-100 | 7-8 |  \n            | 101-500 | 8-10 |  \n            | 501-1000 | 10-11 |  \n            | 1001-5000 | 11-14 |  \n            | >5000 | 14-20 |  \n         2. 选择组宽：class width = (最大观测值 - 最小观测值) / 组数k （注意：需向上取整（根据数据小数位数））\n         3. 组的要求：包含所有数据且不重叠，每个观测属于唯一一组\n2. 四种测量尺度\n    | 尺度类型 | 核心特征 | 示例 |\n    | :---: | :---: | :---: |\n    | 名义尺度（Nominal） | 仅用于命名 / 标签，非定量值，无顺序和大小关系 | 欧洲国家、运动员 T 恤号码、性别、发色 |\n    | 顺序尺度（Ordinal） | 有顺序，非定量值，无法精确衡量差值 | 幸福感等级、服务满意度 |\n    | 区间尺度（Interval） | 定量，有顺序，可衡量差值，无 “真零”（零无实际意义），无法计算比率 | 摄氏温度（60℃与 50℃差值 = 80℃与 70℃差值 = 10℃，但 0℃不代表无温度） |\n    | 比率尺度（Ratio） | 定量，有顺序，可衡量差值，有 “真零”（零代表无），可计算比率 | 体重（20kg 是 10kg 的 2 倍）、身高 |\n3. 分布描述\n   1. 集中趋势测量（反映数据典型值）\n      1. 均值（Mean，x̄）：算术平均，公式为 x̄ = (∑(i=1 到 n) xi) / (n - 1)\n      2. 中位数（Median，m）：有序数据的中点，即第 50 百分位数\n      3. 众数（Mode）：数据中出现频率最高的数值，可能有多个（如双峰、多峰分布）\n   2. 离散程度测量（反映数据变异性）\n      1. 范围（Range）：最大值与最小值的差值，公式为 Range = 最大观测值 - 最小观测值\n      2. 四分位距（Interquartile Range，IQR）：上四分位数（Q3）与下四分位数（Q1）的差值，公式为 IQR = Q3 - Q1\n         1. 计算Q1和Q3的规则：\n            1. 若n为奇数：Q1是**前**(n+1/2)-1个数据的中位数，Q3是**后**(n+1/2)-1个数据的中位数\n            2. 若n为偶数：Q1是**前**n/2个数据的中位数，Q1是**后**n/2个数据的中位数\n      3. 方差（Variance，s^2）与标准差（Standard Deviation，s）：\n         1. 方差：衡量数据与均值的偏离程度，样本方差公式为 s^2 = ∑(i=1 到 n) (xi - x̄)^2 / n-1 （**分母用n-1是因为∑(xi - x̄) = 0，即仅n−1个偏差可自由变化**）\n         2. 标准差：方差的平方根，单位与原始数据一致，`值越大说明数据越分散，越小则越集中`\n      4. 形状（反映数据分布形态）：\n         1. 偏度（Skewness）：衡量分布的不对称性\n            1. 负偏（Negatively skewed）：均值 < 中位数 < 众数，分布左侧长尾\n            2. 正态（Normal，无偏）：均值 = 中位数 = 众数，分布对称\n            3. 正偏（Positively skewed）：众数 < 中位数 < 均值，分布右侧长尾\n         2. 众数数量：\n            1. 单峰（Unimodal）：只有一个众数\n            2. 双峰（Bimodal）：有两个众数\n            3. 多峰（Multimodal）：有三个及以上众数\n         3. 异常值（Outliers）：\n            1. 定义：远离数据主体的观测值，可能由实验误差导致，有时需从数据集中剔除\n            2. 判断标准：若观测值落在`Q1 - 1.5IQR以下`或`Q3 + 1.5IQR以上`，则可能为异常值\n4. 箱线图（Box-and-whisker plot）\n   1. 定义：一种图形化展示数据分布的工具，呈现中位数、Q1、Q3及潜在异常值\n   2. 组成部分：\n      1. 箱体：从Q1延伸至Q3，箱内横线代表中位数\n      2. 须（Whiskers）：从箱体两端延伸至 Q1 - 1.5IQR 和 Q3 + 1.5IQR 范围内的最小和最大数据点\n      3. 异常值：超出须范围的数据点，单独标记\n   3. 用途：作为诊断工具，直观观察数据分布的集中趋势、离散程度和异常值，非用于正式的异常值检验\n![箱线图](/images/箱线图.png)\n5. 随机变量及其性质\n   1. 随机变量定义：设随机实验的样本空间为S，若对每个样本点 s∈S，都有唯一的实数X(s)与之对应，则称X=X(s)为随机变量\n      1. 示例：抛 10 次硬币实验，样本空间S = {s|s是十次正反面的序列}，定义随机变量X(s)为序列中正面出现的次数，则X(s)的取值范围为Rx = {1，2，···，10}\n   2. 随机变量类型\n      1. 离散随机变量（Discrete Random Variable）：取值为有限个或可列无限个\n      2. 连续随机变量（Continuous Random Variable）：取值充满某个区间\n   3. 随机变量的特征\n      1. 均值（期望，Mean/Expectation，μ）：\n         1. 离散随机变量：μ = E[X] = ∑x xp(x)，其中p(x) = P(X = x)为概率质量函数\n         2. 连续随机变量：μ = E[X] = ∫(负无穷 到 正无穷) xf(x)dx，其中f(x)为概率密度函数，且∫(负无穷 到 正无穷) f(x)dx = 1\n      2. 中位数（Median，m）：\n         1. 离散随机变量：满足 P(X ≤ m) ≥ 1/2 且 P(X ≥ m) ≥ 1/2 的数值\n         2. 连续随机变量：概率密度函数下面积被x=m分为两部分，每部分面积为1/2，即 ∫(负无穷 到 m) f(x)dx = 1/2\n      3. 众数（Mode）：概率密度函数（或概率质量函数）的局部最大值点，可能有多个\n      4. 方差（Variance，σ^2）：衡量随机变量取值与均值的偏离程度，公式为σ^2 = E[(X−μ)^2]，其中：\n         1. 离散随机变量：σ^2 = ∑x (x-μ)^2p(x)\n         2. 连续随机变量：σ^2 = ∫(负无穷 到 正无穷) (x-μ)^f(x)dx\n      5. `累积分布函数（Cumulative Distribution Function，CDF，F(x)）：F(x) = P(X≤x)，其中：`\n         1. 离散随机变量：F(x) = ∑(t≤x) p(t)\n         2. 离散随机变量：F(x) = ∫(负无穷 到 x) f(t)dt\n6. 抽样分布\n   1. 随机样本：设X1，X2，···， Xn是相互独立的随机变量，且每个Xi都与总体X具有相同的概率密度函数f(x)，则称X1，X2，···， Xn为来自总体X的容量为n的随机样本。随机样本的联合概率密度函数为 f(x1，x2，···，xn) = f(x1)f(x2)···f(xn)\n   2. 统计量：\n      1. 定义：设X1，X2，···， Xn是来自总体的随机样本，若样本的函数T = T(X1，X2，···， Xn)不含任何未知参数，则称T为统计量\n      2. 常见统计量：\n         1. 样本均值：ˉX= 1/n ∑(i=1 到 n) Xi（对应观测样本的 x̄ = 1/n ∑(i=1 到 n) xi是具体数值，而ˉX是随机变量）\n         2. 样本方差：S^2 = 1/(n-1) ∑(i=1 到 n) (Xi - ˉX)^2（对应观测样本的 s^2 = 1/(n-1) ∑(i=1 到 n) (xi - x̄)^2是具体数值，而S^2是随机变量）\n      3. 抽样分布定义：统计量的概率分布称为抽样分布，它描述了统计量的取值规律，是进行统计推断（如估计总体参数、检验假设）的重要依据，通过抽样分布可将样本信息与总体参数关联起来\n7. 样本均值的抽样分布\n   1. 核心结论：\n      1. 期望：样本均值的期望等于总体均值，即 E[X] = μ\n      2. 方差：样本均值的方差等于总体方差除以样本量，即 Var(ˉX) = σ^2/n（若总体方差为σ^2)\n   2. 两种情况的抽样分布形态：\n        | 总体分布情况 | 样本均值ˉX的抽样分布 | 适用条件 |\n        | :---: | :---: | :---: |\n        | 总体服从正态分布 (X ∼ N(μ，σ^2)) | X ∼ N(μ，σ^2/n) | 无论样本量n大小，均成立 |\n        | 总体分布未知（但总体均值μ、方差σ^2有限） | 当n足够大时，近似 X ∼ N(μ，σ^2/n) | 中心极限定理（CLT），通常 n≥30 时近似效果好；若n<30，需总体分布接近正态 |\n   3. 示例：\n      1. 已知：某大学学生平均年龄μ=22.3岁，标准差σ=4岁（方差σ^2=16），随机抽取n=64名学生\n      2. 求：样本平均年龄大于23岁的概率 P(ˉX > 23)\n      3. 解：因 n=64 ≥ 30，由CLT，X ∼ N(μ = 22.3，σ^2/n = 16/64) = N(22.3，0.25)标准化得 Z = (ˉX - μ) / √σ ∼ N(0，1)，则 P(ˉX > 23) = P(Z > (23-22.3)/√0.25) = P(Z > 1.40)。查标准正态分布表，P(Z ≤ 1.40) = 0.9192，所以P(Z > 1.40) = 1 - 0.9192 = 0.0808\n8. 中心极限定理（CLT）的用途\n   1. 获取样本均值的抽样分布：基于总体参数 (μ，σ^2)和样本量n，确定ˉX的分布形态（近似正态分布），为后续统计计算奠定基础\n   2. 推断未知总体均值μ：\n      1. 假设检验：判断样本均值x̄是否支持对μ的某个假设（如“μ = μ0”）\n      2. 估计：通过样本均值及抽样分布，给出μ的估计区间（如置信区间）\n      3. 质量控制：监测生产过程中产品指标的均值是否在合理范围内，判断过程是否稳定\n9. 两均值差的抽样分布（ˉX1 - ˉX2）\n   1. 定理：设从两个总体中分别抽取独立样本：  \n        样本1：容量n1，来自均值μ1，方差σ^2(1)的总体  \n        样本2：容量n2，来自均值μ2，方差σ^2(2)的总体  \n        则当n1和n2足够大时（通常≥30），或两个总体均服从正态分布时，两样本均值差 ˉX1 - ˉX2 近似服从正态分布：ˉX1 - ˉX2 ∼ N(μ1-μ2，σ^2(1)/n1 + σ^2(2)/n2) （注意加减号）\n10. X^2分布\n    1. 定义：设X1，X2，···，Xn是来自正态总体N(μ，σ^2)的随机样本，S^2为样本方差，则统计量 X^2 = (n-1)S^2 / σ^2，服从自由度为 v = n-1 的X^2分布，记为 X^2 ∼ X^2(v)\n    2. 形态：\n       1. 取值范围：X^2 ≥ 0（非负）\n       2. 自由度影响：自由度v越小，分布越偏右；v越大，分布越接近正态分布\n       3. 分位数：用 X^2(a)(v) 表示自由度为v的X^2分布中，右侧面积为a的分位数（如v=7时，X^2(0.05)(7) = 14.067，X^2(0.95)(7) = 2.167）\n       4. 区间概率：如 95% 的X^2值落在X^2(0.975)(v)与X^2(0.025)(v)之间，若X^2值超出此范围，可能表明假设的总体方差σ^2不合理\n    3. 用途：主要用于**统计推断**，核心是检验 “观测数据与预期数据的差异是否由随机因素导致”，具体应用包括：\n       1. 总体方差的区间估计和假设检验（如判断总体方差是否等于某个假设值）\n       2. 拟合优度检验（检验观测数据是否符合某一理论分布，如正态分布、二项分布）\n       3. 独立性检验（检验两个分类变量是否独立）\n11. t分布（Student t -Distribution）\n    1. 定义：\n       1. 基础定义：设 Z ∼ N(0，1)（标准正态分布），V ∼ X^2(v)（自由度v的X^2分布），且Z与V独立，则随机变量 T = Z / √(V/v) 服从自由度为v的t分布，记作 T ∼ t(v)\n       2. 推论（样本均值相关）：设 X1，X2，···，Xn 是来自正态总体N(μ，σ^2)的随机样本，ˉX为样本均值，S^2为样本方差，则统计量 T = (ˉX - μ) / (S/√n)，服从自由度为 v = n-1 的t分布\n    2. 形态：\n       1. 对称性：钟形，关于t=0对称（与标准正态分布类似）\n       2. 方差特性：方差 = v / v-2 (v>2)，大于1，故比标准正态分布更分散（尾部更粗）\n       3. 自由度影响：自由度v越大，t分布越接近标准正态分布（v趋近于无穷时，t分布趋近于N(0,1)）\n       4. 分位数：用ta(v)表示自由度为v的t分布中，右侧面积为a的分位数，由对称性得t1-a(v) = -ta(v)\n    3. 用途：\n       1. 核心场景：总体方差σ^2未知时的统计推断，具体包括：\n          1. 总体均值μ的区间估计和假设检验（如样本量较小时，用S替代σ，用 t 分布而非正态分布）\n          2. 两独立样本均值差的检验（当两总体方差未知且可能相等或不等时，用t分布或近似t分布）\n          3. 配对样本均值差的检验（如同一组对象前后两次测量的均值差检验）\n       2. 注意事项：\n          1. 使用 t 分布的前提是总体服从正态分布（或样本量较大时，由CLT近似正态，但t分布的使用与CLT无直接关联）\n          2. 若总体不服从正态且样本量小（n<30），则t分布的近似效果差，不宜使用\n12. F分布\n    1. 定义\n       1. 基础定义：设 U ∼ X^2(v1)（自由度v1的X^2分布），V ∼ X^2(v2)（自由度v2的X^2分布），且U与V独立，则随机变量 F = (U/v1)/(V/v2) 服从自由度为(v1，v2)的F分布，记为 F ∼ F(v1，v2)，其中v1为分子自由度，v2为分母自由度\n       2. 推论（样本方差相关）：设 S^2(1) 是来自正态总体 N(μ1，σ^2(1)) 的样本（容量n1）的方差，S^2(2) 是来自正态总体 N(μ2，σ^2(2)) 的样本（容量n2）的方差，且两样本独立，则统计量 F = (S^2(1)/σ^2(1)) / (S^2(2)/σ^2(2)) = σ^2(2)S^2(1) / σ^2(1)S^2(2) 服从自由度为(v1 = n1 - 1，v2 = n2 - 1)的F分布，\n    2. 形态\n       1. 取值范围：F≥0（非负）\n       2. 自由度影响：分布形态由分子自由度v1和分母自由度v2共同决定，通常为右偏分布，v1和v2越大，分布越接近正态分布\n       3. 分位数：用fa(v1，v2)表示自由度为(v1，v2)的F分布中，右侧面积为a的分位数\n       4. 分位数关系：fa(v1，v2) = 1 / (f1-a(v2，v1))，用于计算低尾分位数\n    3. 用途：\n       1. 核心场景：方差分析（Analysis of Variance，ANOVA），用于检验多个总体均值是否相等，具体包括：\n          1. 单因素方差分析（如检验三种油漆的平均干燥时间是否相等）：通过比较 “组间方差”（样本均值间的变异）与 “组内方差”（样本内部的变异）的比值（F统计量），判断均值是否存在显著差异\n          2. 两总体方差的比较：检验两个正态总体的方差是否相等（如判断两样本的方差是否齐性，为两样本均值检验选择方法）\n          3. 多因素方差分析：分析多个因素对因变量的影响及因素间的交互作用\n13. 本章关键问题：\n    1. 在数据分布描述中，异常值的判断标准是什么？为什么在计算样本方差时，分母使用n−1而非n？\n       1. 异常值判断标准：若某个观测值落在 **Q1−1.5IQR以下或Q3+1.5IQR以上**，则该观测值可能为异常值\n       2. 样本方差分母用n−1的原因：为了实现**无偏估计**，由于样本均值x̄是通过样本数据计算得出的，存在 “自由度损失” —— ∑(i=1 到 n) (xi - x̄) = 0，即n个偏差中只有n−1个是独立的若用\n    2. 心极限定理（CLT）的核心内容是什么？其在样本均值抽样分布和两均值差抽样分布中有哪些具体应用？\n       1. 中心极限定理（CLT）核心内容：设总体的均值为μ、方差为σ^2（有限），从该总体中抽取容量为n的随机样本，当n足够大时（通常n≥30），样本均值ˉX的抽样分布近似服从均值为μ，方差为σ^2/n的正态分布（即近似 ˉX ∼ N(μ，σ^2/n)）且该近似效果与总体原始分布无关（即使总体非正态，只要n足够大，样本均值仍近似正态）\n       2. 在样本均值抽样分布中的应用：\n          1. 当总体分布未知时，若n≥30，可通过CLT认为ˉX近似正态，进而计算与样本均值相关的概率\n          2. 当n<30时，若总体分布接近正态CLT的近似效果仍可接受；若总体严重非正态，则需增大样本量以满足CLT条件\n       3. CLT 可推广到两独立样本场景\n    3. `X^2分布、T分布、F分布的核心用途有何差异？分别适用于哪些统计推断场景？`\n       1. X^2分布、T分布、F分布的核心用途及适用场景存在显著差异，具体如下表所示：\n            | 分布类型 | 核心用途 | 适用场景示例 |\n            | :---: | :---: | :---: |\n            | X^2分布 | 围绕方差与数据拟合程度展开，用于检验 “观测数据与预期数据的差异是否由随机因素导致” | 1. **总体方差推断**：总体方差σ^2的区间估计和假设检验（如判断汽车电池寿命的标准差是否为 1 年）<br>2. **拟合优度检验**：检验观测数据是否符合某一理论分布（如检验学生成绩是否服从正态分布）<br>3. **独立性检验**：检验两个分类变量是否独立（如检验 “性别” 与 “是否购买某产品” 是否独立） |\n            | T分布 | 围绕总体方差未知时的均值推断展开，解决 “总体方差σ^2未知，无法使用正态分布” 的问题 | 1. **单总体均值推断**：总体方差未知时，总体均值μ的区间估计和假设检验（如样本量较小时，检验化工过程的产量均值是否为 500g/ml）<br>2. **两样本均值差推断**：两总体方差未知时，检验两总体均值是否相等（如检验两种药物的疗效均值是否有差异）<br>3. **配对样本推断**：检验配对数据的均值差（如检验同一组患者用药前后的血压均值差） |\n            | F分布 | 围绕方差比值与多总体均值比较展开，核心是 “通过方差比值判断差异是否显著” | 1. **两总体方差比较**：检验两个正态总体的方差是否相等（如判断两批产品的质量波动是否一致，即方差齐性检验）<br>2. **方差分析（ANOVA）**：检验多个总体的均值是否相等（如检验三种不同品牌油漆的平均干燥时间是否有差异）<br>3. **多因素方差分析**：分析多个因素对因变量的影响及因素间的交互作用（如分析 “温度”“压力” 对产品产量的影响） |\n       2. 三者的核心差异在于：X^2分布聚焦 “方差与拟合度”，T分布聚焦 “方差未知时的均值”，F分布聚焦 “方差比值与多均值比较”，分别对应统计推断中不同维度的问题\n\n## 今日总结\n1. 今天在记笔记时要加入表格，发现：\n   1. `为了避免序号被打乱，要通过缩进确保表格属于上一级列表项`\n   2. `若需要在表格中加入序列需要使用<br>标签进行换行`\n2. 今天在记笔记时要插入图片，步骤如下：\n   1. `在source文件夹里创建一个images文件夹用于存放图片`\n   2. `在Markdown文件中用语法：！\\[图片描述]\\[/images/图片名]`\n   3. `注意：此方法只能在发布出来的博客中看见图片`\n   4. 过程中在终端中下载了安装 hexo-asset-img 插件\n3. 今天看见Stela在跑步，和她约了下次一起跑步\n4. 英语口语学习\n5. 今天的网球活动感觉打的越来越好了\n\n## 摘录\n1. 管理情绪主要包括三个方面的内容：一是认识自己的情绪；二是疏解自己的情绪；三是适当表达自己的情绪。\n2. 脱困四问：\n   1. Emotion：我正处于何种情绪里？这种情绪的程度如何？\n   2. Event：我为什么产生这样的情绪？（注意：需要客观真实看待所发生的事情，不能带有主观倾向）\n   3. Target：我的初衷是什么？\n   4. Action：接下来我该怎么做？我可以做些什么？\n3. 生活的本质在于追求快乐，而让自己的人生变得快乐的途径有两种：不断地发现有限生命中的快乐时光，并增加它；发现那些令自己不快乐的时光，并尽可能减少它。 —— 亚里士多德\n4. 两弊相衡取其轻，两利相权取其重","source":"_posts/2025-10-29.md","raw":"---\ntitle: 2025.10.30\ndate: 2025-10-29 16:25:23\ntags:\n---\n\n# Overview\n1. 学习笔记\n2. 今日总结\n3. 摘录\n\n## 学习笔记\n\n### 概率\n1. 数据与数据表示\n   1. 图表类型：\n      1. 柱状图（Bar graph）\n      2. 饼图（Pie Chart）\n      3. 交叉表（Cross Table）：可以变成并排的簇状图（几个柱作为一个整体）或堆叠的分组条形图（一个柱上有几个不同的特性）\n      4. 直方图（Histogram）\n      5. 累积频率图（Ogive）：连接各区间上限累积百分比的线，展示累积频率分布\n      6. 茎叶图（Stem and Leaf Plot）：同时展示数据的分布和原始值（中间的主干数据加上两边的枝干数据）\n      7. 时间序列图（Time Series Plot）：横轴为时间，纵轴为序列值，展示数据随时间的变化趋势\n      8. 散点图（Scatterplot）：观测两个定量变量的关系，需关注关联方向（正 / 负）、形式（线性 / 非线性）、强度（紧密 / 松散）\n   2. 频率表\n      1. 分类数据频率表：列出类别及对应数量（频率），相对频率表则列出百分比（比例）\n         1. 频率表：  \n            | 舱位 | 数量 |  \n            | --- | --- |  \n            | 头等舱（First） | 324 |  \n            | 二等舱（Second） | 285 |  \n            | 三等舱（Third） | 710 |  \n            | 船员（Crew） | 889 |  \n         2. 相对频率表  \n             | 舱位 | 百分比（%） |  \n             | --- | --- |  \n             | 头等舱（First） | 14.67 |  \n             | 二等舱（Second） | 12.91 |  \n             | 三等舱（Third） | 32.16 |  \n             | 船员（Crew） | 40.26 |  \n      2. 数值数据频率表：\n         1. 构建规则：根据样本量n选择，如下表：\n            | 样本量（n） | 组数（k） |  \n            | --- | --- |  \n            | <50 | 5-7 |  \n            | 50-100 | 7-8 |  \n            | 101-500 | 8-10 |  \n            | 501-1000 | 10-11 |  \n            | 1001-5000 | 11-14 |  \n            | >5000 | 14-20 |  \n         2. 选择组宽：class width = (最大观测值 - 最小观测值) / 组数k （注意：需向上取整（根据数据小数位数））\n         3. 组的要求：包含所有数据且不重叠，每个观测属于唯一一组\n2. 四种测量尺度\n    | 尺度类型 | 核心特征 | 示例 |\n    | :---: | :---: | :---: |\n    | 名义尺度（Nominal） | 仅用于命名 / 标签，非定量值，无顺序和大小关系 | 欧洲国家、运动员 T 恤号码、性别、发色 |\n    | 顺序尺度（Ordinal） | 有顺序，非定量值，无法精确衡量差值 | 幸福感等级、服务满意度 |\n    | 区间尺度（Interval） | 定量，有顺序，可衡量差值，无 “真零”（零无实际意义），无法计算比率 | 摄氏温度（60℃与 50℃差值 = 80℃与 70℃差值 = 10℃，但 0℃不代表无温度） |\n    | 比率尺度（Ratio） | 定量，有顺序，可衡量差值，有 “真零”（零代表无），可计算比率 | 体重（20kg 是 10kg 的 2 倍）、身高 |\n3. 分布描述\n   1. 集中趋势测量（反映数据典型值）\n      1. 均值（Mean，x̄）：算术平均，公式为 x̄ = (∑(i=1 到 n) xi) / (n - 1)\n      2. 中位数（Median，m）：有序数据的中点，即第 50 百分位数\n      3. 众数（Mode）：数据中出现频率最高的数值，可能有多个（如双峰、多峰分布）\n   2. 离散程度测量（反映数据变异性）\n      1. 范围（Range）：最大值与最小值的差值，公式为 Range = 最大观测值 - 最小观测值\n      2. 四分位距（Interquartile Range，IQR）：上四分位数（Q3）与下四分位数（Q1）的差值，公式为 IQR = Q3 - Q1\n         1. 计算Q1和Q3的规则：\n            1. 若n为奇数：Q1是**前**(n+1/2)-1个数据的中位数，Q3是**后**(n+1/2)-1个数据的中位数\n            2. 若n为偶数：Q1是**前**n/2个数据的中位数，Q1是**后**n/2个数据的中位数\n      3. 方差（Variance，s^2）与标准差（Standard Deviation，s）：\n         1. 方差：衡量数据与均值的偏离程度，样本方差公式为 s^2 = ∑(i=1 到 n) (xi - x̄)^2 / n-1 （**分母用n-1是因为∑(xi - x̄) = 0，即仅n−1个偏差可自由变化**）\n         2. 标准差：方差的平方根，单位与原始数据一致，`值越大说明数据越分散，越小则越集中`\n      4. 形状（反映数据分布形态）：\n         1. 偏度（Skewness）：衡量分布的不对称性\n            1. 负偏（Negatively skewed）：均值 < 中位数 < 众数，分布左侧长尾\n            2. 正态（Normal，无偏）：均值 = 中位数 = 众数，分布对称\n            3. 正偏（Positively skewed）：众数 < 中位数 < 均值，分布右侧长尾\n         2. 众数数量：\n            1. 单峰（Unimodal）：只有一个众数\n            2. 双峰（Bimodal）：有两个众数\n            3. 多峰（Multimodal）：有三个及以上众数\n         3. 异常值（Outliers）：\n            1. 定义：远离数据主体的观测值，可能由实验误差导致，有时需从数据集中剔除\n            2. 判断标准：若观测值落在`Q1 - 1.5IQR以下`或`Q3 + 1.5IQR以上`，则可能为异常值\n4. 箱线图（Box-and-whisker plot）\n   1. 定义：一种图形化展示数据分布的工具，呈现中位数、Q1、Q3及潜在异常值\n   2. 组成部分：\n      1. 箱体：从Q1延伸至Q3，箱内横线代表中位数\n      2. 须（Whiskers）：从箱体两端延伸至 Q1 - 1.5IQR 和 Q3 + 1.5IQR 范围内的最小和最大数据点\n      3. 异常值：超出须范围的数据点，单独标记\n   3. 用途：作为诊断工具，直观观察数据分布的集中趋势、离散程度和异常值，非用于正式的异常值检验\n![箱线图](/images/箱线图.png)\n5. 随机变量及其性质\n   1. 随机变量定义：设随机实验的样本空间为S，若对每个样本点 s∈S，都有唯一的实数X(s)与之对应，则称X=X(s)为随机变量\n      1. 示例：抛 10 次硬币实验，样本空间S = {s|s是十次正反面的序列}，定义随机变量X(s)为序列中正面出现的次数，则X(s)的取值范围为Rx = {1，2，···，10}\n   2. 随机变量类型\n      1. 离散随机变量（Discrete Random Variable）：取值为有限个或可列无限个\n      2. 连续随机变量（Continuous Random Variable）：取值充满某个区间\n   3. 随机变量的特征\n      1. 均值（期望，Mean/Expectation，μ）：\n         1. 离散随机变量：μ = E[X] = ∑x xp(x)，其中p(x) = P(X = x)为概率质量函数\n         2. 连续随机变量：μ = E[X] = ∫(负无穷 到 正无穷) xf(x)dx，其中f(x)为概率密度函数，且∫(负无穷 到 正无穷) f(x)dx = 1\n      2. 中位数（Median，m）：\n         1. 离散随机变量：满足 P(X ≤ m) ≥ 1/2 且 P(X ≥ m) ≥ 1/2 的数值\n         2. 连续随机变量：概率密度函数下面积被x=m分为两部分，每部分面积为1/2，即 ∫(负无穷 到 m) f(x)dx = 1/2\n      3. 众数（Mode）：概率密度函数（或概率质量函数）的局部最大值点，可能有多个\n      4. 方差（Variance，σ^2）：衡量随机变量取值与均值的偏离程度，公式为σ^2 = E[(X−μ)^2]，其中：\n         1. 离散随机变量：σ^2 = ∑x (x-μ)^2p(x)\n         2. 连续随机变量：σ^2 = ∫(负无穷 到 正无穷) (x-μ)^f(x)dx\n      5. `累积分布函数（Cumulative Distribution Function，CDF，F(x)）：F(x) = P(X≤x)，其中：`\n         1. 离散随机变量：F(x) = ∑(t≤x) p(t)\n         2. 离散随机变量：F(x) = ∫(负无穷 到 x) f(t)dt\n6. 抽样分布\n   1. 随机样本：设X1，X2，···， Xn是相互独立的随机变量，且每个Xi都与总体X具有相同的概率密度函数f(x)，则称X1，X2，···， Xn为来自总体X的容量为n的随机样本。随机样本的联合概率密度函数为 f(x1，x2，···，xn) = f(x1)f(x2)···f(xn)\n   2. 统计量：\n      1. 定义：设X1，X2，···， Xn是来自总体的随机样本，若样本的函数T = T(X1，X2，···， Xn)不含任何未知参数，则称T为统计量\n      2. 常见统计量：\n         1. 样本均值：ˉX= 1/n ∑(i=1 到 n) Xi（对应观测样本的 x̄ = 1/n ∑(i=1 到 n) xi是具体数值，而ˉX是随机变量）\n         2. 样本方差：S^2 = 1/(n-1) ∑(i=1 到 n) (Xi - ˉX)^2（对应观测样本的 s^2 = 1/(n-1) ∑(i=1 到 n) (xi - x̄)^2是具体数值，而S^2是随机变量）\n      3. 抽样分布定义：统计量的概率分布称为抽样分布，它描述了统计量的取值规律，是进行统计推断（如估计总体参数、检验假设）的重要依据，通过抽样分布可将样本信息与总体参数关联起来\n7. 样本均值的抽样分布\n   1. 核心结论：\n      1. 期望：样本均值的期望等于总体均值，即 E[X] = μ\n      2. 方差：样本均值的方差等于总体方差除以样本量，即 Var(ˉX) = σ^2/n（若总体方差为σ^2)\n   2. 两种情况的抽样分布形态：\n        | 总体分布情况 | 样本均值ˉX的抽样分布 | 适用条件 |\n        | :---: | :---: | :---: |\n        | 总体服从正态分布 (X ∼ N(μ，σ^2)) | X ∼ N(μ，σ^2/n) | 无论样本量n大小，均成立 |\n        | 总体分布未知（但总体均值μ、方差σ^2有限） | 当n足够大时，近似 X ∼ N(μ，σ^2/n) | 中心极限定理（CLT），通常 n≥30 时近似效果好；若n<30，需总体分布接近正态 |\n   3. 示例：\n      1. 已知：某大学学生平均年龄μ=22.3岁，标准差σ=4岁（方差σ^2=16），随机抽取n=64名学生\n      2. 求：样本平均年龄大于23岁的概率 P(ˉX > 23)\n      3. 解：因 n=64 ≥ 30，由CLT，X ∼ N(μ = 22.3，σ^2/n = 16/64) = N(22.3，0.25)标准化得 Z = (ˉX - μ) / √σ ∼ N(0，1)，则 P(ˉX > 23) = P(Z > (23-22.3)/√0.25) = P(Z > 1.40)。查标准正态分布表，P(Z ≤ 1.40) = 0.9192，所以P(Z > 1.40) = 1 - 0.9192 = 0.0808\n8. 中心极限定理（CLT）的用途\n   1. 获取样本均值的抽样分布：基于总体参数 (μ，σ^2)和样本量n，确定ˉX的分布形态（近似正态分布），为后续统计计算奠定基础\n   2. 推断未知总体均值μ：\n      1. 假设检验：判断样本均值x̄是否支持对μ的某个假设（如“μ = μ0”）\n      2. 估计：通过样本均值及抽样分布，给出μ的估计区间（如置信区间）\n      3. 质量控制：监测生产过程中产品指标的均值是否在合理范围内，判断过程是否稳定\n9. 两均值差的抽样分布（ˉX1 - ˉX2）\n   1. 定理：设从两个总体中分别抽取独立样本：  \n        样本1：容量n1，来自均值μ1，方差σ^2(1)的总体  \n        样本2：容量n2，来自均值μ2，方差σ^2(2)的总体  \n        则当n1和n2足够大时（通常≥30），或两个总体均服从正态分布时，两样本均值差 ˉX1 - ˉX2 近似服从正态分布：ˉX1 - ˉX2 ∼ N(μ1-μ2，σ^2(1)/n1 + σ^2(2)/n2) （注意加减号）\n10. X^2分布\n    1. 定义：设X1，X2，···，Xn是来自正态总体N(μ，σ^2)的随机样本，S^2为样本方差，则统计量 X^2 = (n-1)S^2 / σ^2，服从自由度为 v = n-1 的X^2分布，记为 X^2 ∼ X^2(v)\n    2. 形态：\n       1. 取值范围：X^2 ≥ 0（非负）\n       2. 自由度影响：自由度v越小，分布越偏右；v越大，分布越接近正态分布\n       3. 分位数：用 X^2(a)(v) 表示自由度为v的X^2分布中，右侧面积为a的分位数（如v=7时，X^2(0.05)(7) = 14.067，X^2(0.95)(7) = 2.167）\n       4. 区间概率：如 95% 的X^2值落在X^2(0.975)(v)与X^2(0.025)(v)之间，若X^2值超出此范围，可能表明假设的总体方差σ^2不合理\n    3. 用途：主要用于**统计推断**，核心是检验 “观测数据与预期数据的差异是否由随机因素导致”，具体应用包括：\n       1. 总体方差的区间估计和假设检验（如判断总体方差是否等于某个假设值）\n       2. 拟合优度检验（检验观测数据是否符合某一理论分布，如正态分布、二项分布）\n       3. 独立性检验（检验两个分类变量是否独立）\n11. t分布（Student t -Distribution）\n    1. 定义：\n       1. 基础定义：设 Z ∼ N(0，1)（标准正态分布），V ∼ X^2(v)（自由度v的X^2分布），且Z与V独立，则随机变量 T = Z / √(V/v) 服从自由度为v的t分布，记作 T ∼ t(v)\n       2. 推论（样本均值相关）：设 X1，X2，···，Xn 是来自正态总体N(μ，σ^2)的随机样本，ˉX为样本均值，S^2为样本方差，则统计量 T = (ˉX - μ) / (S/√n)，服从自由度为 v = n-1 的t分布\n    2. 形态：\n       1. 对称性：钟形，关于t=0对称（与标准正态分布类似）\n       2. 方差特性：方差 = v / v-2 (v>2)，大于1，故比标准正态分布更分散（尾部更粗）\n       3. 自由度影响：自由度v越大，t分布越接近标准正态分布（v趋近于无穷时，t分布趋近于N(0,1)）\n       4. 分位数：用ta(v)表示自由度为v的t分布中，右侧面积为a的分位数，由对称性得t1-a(v) = -ta(v)\n    3. 用途：\n       1. 核心场景：总体方差σ^2未知时的统计推断，具体包括：\n          1. 总体均值μ的区间估计和假设检验（如样本量较小时，用S替代σ，用 t 分布而非正态分布）\n          2. 两独立样本均值差的检验（当两总体方差未知且可能相等或不等时，用t分布或近似t分布）\n          3. 配对样本均值差的检验（如同一组对象前后两次测量的均值差检验）\n       2. 注意事项：\n          1. 使用 t 分布的前提是总体服从正态分布（或样本量较大时，由CLT近似正态，但t分布的使用与CLT无直接关联）\n          2. 若总体不服从正态且样本量小（n<30），则t分布的近似效果差，不宜使用\n12. F分布\n    1. 定义\n       1. 基础定义：设 U ∼ X^2(v1)（自由度v1的X^2分布），V ∼ X^2(v2)（自由度v2的X^2分布），且U与V独立，则随机变量 F = (U/v1)/(V/v2) 服从自由度为(v1，v2)的F分布，记为 F ∼ F(v1，v2)，其中v1为分子自由度，v2为分母自由度\n       2. 推论（样本方差相关）：设 S^2(1) 是来自正态总体 N(μ1，σ^2(1)) 的样本（容量n1）的方差，S^2(2) 是来自正态总体 N(μ2，σ^2(2)) 的样本（容量n2）的方差，且两样本独立，则统计量 F = (S^2(1)/σ^2(1)) / (S^2(2)/σ^2(2)) = σ^2(2)S^2(1) / σ^2(1)S^2(2) 服从自由度为(v1 = n1 - 1，v2 = n2 - 1)的F分布，\n    2. 形态\n       1. 取值范围：F≥0（非负）\n       2. 自由度影响：分布形态由分子自由度v1和分母自由度v2共同决定，通常为右偏分布，v1和v2越大，分布越接近正态分布\n       3. 分位数：用fa(v1，v2)表示自由度为(v1，v2)的F分布中，右侧面积为a的分位数\n       4. 分位数关系：fa(v1，v2) = 1 / (f1-a(v2，v1))，用于计算低尾分位数\n    3. 用途：\n       1. 核心场景：方差分析（Analysis of Variance，ANOVA），用于检验多个总体均值是否相等，具体包括：\n          1. 单因素方差分析（如检验三种油漆的平均干燥时间是否相等）：通过比较 “组间方差”（样本均值间的变异）与 “组内方差”（样本内部的变异）的比值（F统计量），判断均值是否存在显著差异\n          2. 两总体方差的比较：检验两个正态总体的方差是否相等（如判断两样本的方差是否齐性，为两样本均值检验选择方法）\n          3. 多因素方差分析：分析多个因素对因变量的影响及因素间的交互作用\n13. 本章关键问题：\n    1. 在数据分布描述中，异常值的判断标准是什么？为什么在计算样本方差时，分母使用n−1而非n？\n       1. 异常值判断标准：若某个观测值落在 **Q1−1.5IQR以下或Q3+1.5IQR以上**，则该观测值可能为异常值\n       2. 样本方差分母用n−1的原因：为了实现**无偏估计**，由于样本均值x̄是通过样本数据计算得出的，存在 “自由度损失” —— ∑(i=1 到 n) (xi - x̄) = 0，即n个偏差中只有n−1个是独立的若用\n    2. 心极限定理（CLT）的核心内容是什么？其在样本均值抽样分布和两均值差抽样分布中有哪些具体应用？\n       1. 中心极限定理（CLT）核心内容：设总体的均值为μ、方差为σ^2（有限），从该总体中抽取容量为n的随机样本，当n足够大时（通常n≥30），样本均值ˉX的抽样分布近似服从均值为μ，方差为σ^2/n的正态分布（即近似 ˉX ∼ N(μ，σ^2/n)）且该近似效果与总体原始分布无关（即使总体非正态，只要n足够大，样本均值仍近似正态）\n       2. 在样本均值抽样分布中的应用：\n          1. 当总体分布未知时，若n≥30，可通过CLT认为ˉX近似正态，进而计算与样本均值相关的概率\n          2. 当n<30时，若总体分布接近正态CLT的近似效果仍可接受；若总体严重非正态，则需增大样本量以满足CLT条件\n       3. CLT 可推广到两独立样本场景\n    3. `X^2分布、T分布、F分布的核心用途有何差异？分别适用于哪些统计推断场景？`\n       1. X^2分布、T分布、F分布的核心用途及适用场景存在显著差异，具体如下表所示：\n            | 分布类型 | 核心用途 | 适用场景示例 |\n            | :---: | :---: | :---: |\n            | X^2分布 | 围绕方差与数据拟合程度展开，用于检验 “观测数据与预期数据的差异是否由随机因素导致” | 1. **总体方差推断**：总体方差σ^2的区间估计和假设检验（如判断汽车电池寿命的标准差是否为 1 年）<br>2. **拟合优度检验**：检验观测数据是否符合某一理论分布（如检验学生成绩是否服从正态分布）<br>3. **独立性检验**：检验两个分类变量是否独立（如检验 “性别” 与 “是否购买某产品” 是否独立） |\n            | T分布 | 围绕总体方差未知时的均值推断展开，解决 “总体方差σ^2未知，无法使用正态分布” 的问题 | 1. **单总体均值推断**：总体方差未知时，总体均值μ的区间估计和假设检验（如样本量较小时，检验化工过程的产量均值是否为 500g/ml）<br>2. **两样本均值差推断**：两总体方差未知时，检验两总体均值是否相等（如检验两种药物的疗效均值是否有差异）<br>3. **配对样本推断**：检验配对数据的均值差（如检验同一组患者用药前后的血压均值差） |\n            | F分布 | 围绕方差比值与多总体均值比较展开，核心是 “通过方差比值判断差异是否显著” | 1. **两总体方差比较**：检验两个正态总体的方差是否相等（如判断两批产品的质量波动是否一致，即方差齐性检验）<br>2. **方差分析（ANOVA）**：检验多个总体的均值是否相等（如检验三种不同品牌油漆的平均干燥时间是否有差异）<br>3. **多因素方差分析**：分析多个因素对因变量的影响及因素间的交互作用（如分析 “温度”“压力” 对产品产量的影响） |\n       2. 三者的核心差异在于：X^2分布聚焦 “方差与拟合度”，T分布聚焦 “方差未知时的均值”，F分布聚焦 “方差比值与多均值比较”，分别对应统计推断中不同维度的问题\n\n## 今日总结\n1. 今天在记笔记时要加入表格，发现：\n   1. `为了避免序号被打乱，要通过缩进确保表格属于上一级列表项`\n   2. `若需要在表格中加入序列需要使用<br>标签进行换行`\n2. 今天在记笔记时要插入图片，步骤如下：\n   1. `在source文件夹里创建一个images文件夹用于存放图片`\n   2. `在Markdown文件中用语法：！\\[图片描述]\\[/images/图片名]`\n   3. `注意：此方法只能在发布出来的博客中看见图片`\n   4. 过程中在终端中下载了安装 hexo-asset-img 插件\n3. 今天看见Stela在跑步，和她约了下次一起跑步\n4. 英语口语学习\n5. 今天的网球活动感觉打的越来越好了\n\n## 摘录\n1. 管理情绪主要包括三个方面的内容：一是认识自己的情绪；二是疏解自己的情绪；三是适当表达自己的情绪。\n2. 脱困四问：\n   1. Emotion：我正处于何种情绪里？这种情绪的程度如何？\n   2. Event：我为什么产生这样的情绪？（注意：需要客观真实看待所发生的事情，不能带有主观倾向）\n   3. Target：我的初衷是什么？\n   4. Action：接下来我该怎么做？我可以做些什么？\n3. 生活的本质在于追求快乐，而让自己的人生变得快乐的途径有两种：不断地发现有限生命中的快乐时光，并增加它；发现那些令自己不快乐的时光，并尽可能减少它。 —— 亚里士多德\n4. 两弊相衡取其轻，两利相权取其重","slug":"2025-10-29","published":1,"updated":"2025-11-18T19:39:17.112Z","comments":1,"layout":"post","photos":[],"_id":"cuid1yWUDkUshlH9Iax2UKkdS","content":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>学习笔记</li>\n<li>今日总结</li>\n<li>摘录</li>\n</ol>\n<h2 id=\"学习笔记\"><a href=\"#学习笔记\" class=\"headerlink\" title=\"学习笔记\"></a>学习笔记</h2><h3 id=\"概率\"><a href=\"#概率\" class=\"headerlink\" title=\"概率\"></a>概率</h3><ol>\n<li>数据与数据表示<ol>\n<li>图表类型：<ol>\n<li>柱状图（Bar graph）</li>\n<li>饼图（Pie Chart）</li>\n<li>交叉表（Cross Table）：可以变成并排的簇状图（几个柱作为一个整体）或堆叠的分组条形图（一个柱上有几个不同的特性）</li>\n<li>直方图（Histogram）</li>\n<li>累积频率图（Ogive）：连接各区间上限累积百分比的线，展示累积频率分布</li>\n<li>茎叶图（Stem and Leaf Plot）：同时展示数据的分布和原始值（中间的主干数据加上两边的枝干数据）</li>\n<li>时间序列图（Time Series Plot）：横轴为时间，纵轴为序列值，展示数据随时间的变化趋势</li>\n<li>散点图（Scatterplot）：观测两个定量变量的关系，需关注关联方向（正 &#x2F; 负）、形式（线性 &#x2F; 非线性）、强度（紧密 &#x2F; 松散）</li>\n</ol>\n</li>\n<li>频率表<ol>\n<li>分类数据频率表：列出类别及对应数量（频率），相对频率表则列出百分比（比例）<ol>\n<li>频率表：  <table>\n<thead>\n<tr>\n<th>舱位</th>\n<th>数量</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>头等舱（First）</td>\n<td>324</td>\n</tr>\n<tr>\n<td>二等舱（Second）</td>\n<td>285</td>\n</tr>\n<tr>\n<td>三等舱（Third）</td>\n<td>710</td>\n</tr>\n<tr>\n<td>船员（Crew）</td>\n<td>889</td>\n</tr>\n</tbody></table>\n</li>\n<li>相对频率表  <table>\n<thead>\n<tr>\n<th>舱位</th>\n<th>百分比（%）</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>头等舱（First）</td>\n<td>14.67</td>\n</tr>\n<tr>\n<td>二等舱（Second）</td>\n<td>12.91</td>\n</tr>\n<tr>\n<td>三等舱（Third）</td>\n<td>32.16</td>\n</tr>\n<tr>\n<td>船员（Crew）</td>\n<td>40.26</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n</li>\n<li>数值数据频率表：<ol>\n<li>构建规则：根据样本量n选择，如下表：<table>\n<thead>\n<tr>\n<th>样本量（n）</th>\n<th>组数（k）</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>&lt;50</td>\n<td>5-7</td>\n</tr>\n<tr>\n<td>50-100</td>\n<td>7-8</td>\n</tr>\n<tr>\n<td>101-500</td>\n<td>8-10</td>\n</tr>\n<tr>\n<td>501-1000</td>\n<td>10-11</td>\n</tr>\n<tr>\n<td>1001-5000</td>\n<td>11-14</td>\n</tr>\n<tr>\n<td>&gt;5000</td>\n<td>14-20</td>\n</tr>\n</tbody></table>\n</li>\n<li>选择组宽：class width &#x3D; (最大观测值 - 最小观测值) &#x2F; 组数k （注意：需向上取整（根据数据小数位数））</li>\n<li>组的要求：包含所有数据且不重叠，每个观测属于唯一一组</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>四种测量尺度<table>\n<thead>\n<tr>\n<th align=\"center\">尺度类型</th>\n<th align=\"center\">核心特征</th>\n<th align=\"center\">示例</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">名义尺度（Nominal）</td>\n<td align=\"center\">仅用于命名 &#x2F; 标签，非定量值，无顺序和大小关系</td>\n<td align=\"center\">欧洲国家、运动员 T 恤号码、性别、发色</td>\n</tr>\n<tr>\n<td align=\"center\">顺序尺度（Ordinal）</td>\n<td align=\"center\">有顺序，非定量值，无法精确衡量差值</td>\n<td align=\"center\">幸福感等级、服务满意度</td>\n</tr>\n<tr>\n<td align=\"center\">区间尺度（Interval）</td>\n<td align=\"center\">定量，有顺序，可衡量差值，无 “真零”（零无实际意义），无法计算比率</td>\n<td align=\"center\">摄氏温度（60℃与 50℃差值 &#x3D; 80℃与 70℃差值 &#x3D; 10℃，但 0℃不代表无温度）</td>\n</tr>\n<tr>\n<td align=\"center\">比率尺度（Ratio）</td>\n<td align=\"center\">定量，有顺序，可衡量差值，有 “真零”（零代表无），可计算比率</td>\n<td align=\"center\">体重（20kg 是 10kg 的 2 倍）、身高</td>\n</tr>\n</tbody></table>\n</li>\n<li>分布描述<ol>\n<li>集中趋势测量（反映数据典型值）<ol>\n<li>均值（Mean，x̄）：算术平均，公式为 x̄ &#x3D; (∑(i&#x3D;1 到 n) xi) &#x2F; (n - 1)</li>\n<li>中位数（Median，m）：有序数据的中点，即第 50 百分位数</li>\n<li>众数（Mode）：数据中出现频率最高的数值，可能有多个（如双峰、多峰分布）</li>\n</ol>\n</li>\n<li>离散程度测量（反映数据变异性）<ol>\n<li>范围（Range）：最大值与最小值的差值，公式为 Range &#x3D; 最大观测值 - 最小观测值</li>\n<li>四分位距（Interquartile Range，IQR）：上四分位数（Q3）与下四分位数（Q1）的差值，公式为 IQR &#x3D; Q3 - Q1<ol>\n<li>计算Q1和Q3的规则：<ol>\n<li>若n为奇数：Q1是<strong>前</strong>(n+1&#x2F;2)-1个数据的中位数，Q3是<strong>后</strong>(n+1&#x2F;2)-1个数据的中位数</li>\n<li>若n为偶数：Q1是<strong>前</strong>n&#x2F;2个数据的中位数，Q1是<strong>后</strong>n&#x2F;2个数据的中位数</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>方差（Variance，s^2）与标准差（Standard Deviation，s）：<ol>\n<li>方差：衡量数据与均值的偏离程度，样本方差公式为 s^2 &#x3D; ∑(i&#x3D;1 到 n) (xi - x̄)^2 &#x2F; n-1 （<strong>分母用n-1是因为∑(xi - x̄) &#x3D; 0，即仅n−1个偏差可自由变化</strong>）</li>\n<li>标准差：方差的平方根，单位与原始数据一致，<code>值越大说明数据越分散，越小则越集中</code></li>\n</ol>\n</li>\n<li>形状（反映数据分布形态）：<ol>\n<li>偏度（Skewness）：衡量分布的不对称性<ol>\n<li>负偏（Negatively skewed）：均值 &lt; 中位数 &lt; 众数，分布左侧长尾</li>\n<li>正态（Normal，无偏）：均值 &#x3D; 中位数 &#x3D; 众数，分布对称</li>\n<li>正偏（Positively skewed）：众数 &lt; 中位数 &lt; 均值，分布右侧长尾</li>\n</ol>\n</li>\n<li>众数数量：<ol>\n<li>单峰（Unimodal）：只有一个众数</li>\n<li>双峰（Bimodal）：有两个众数</li>\n<li>多峰（Multimodal）：有三个及以上众数</li>\n</ol>\n</li>\n<li>异常值（Outliers）：<ol>\n<li>定义：远离数据主体的观测值，可能由实验误差导致，有时需从数据集中剔除</li>\n<li>判断标准：若观测值落在<code>Q1 - 1.5IQR以下</code>或<code>Q3 + 1.5IQR以上</code>，则可能为异常值</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>箱线图（Box-and-whisker plot）<ol>\n<li>定义：一种图形化展示数据分布的工具，呈现中位数、Q1、Q3及潜在异常值</li>\n<li>组成部分：<ol>\n<li>箱体：从Q1延伸至Q3，箱内横线代表中位数</li>\n<li>须（Whiskers）：从箱体两端延伸至 Q1 - 1.5IQR 和 Q3 + 1.5IQR 范围内的最小和最大数据点</li>\n<li>异常值：超出须范围的数据点，单独标记</li>\n</ol>\n</li>\n<li>用途：作为诊断工具，直观观察数据分布的集中趋势、离散程度和异常值，非用于正式的异常值检验<br><img src=\"/images/%E7%AE%B1%E7%BA%BF%E5%9B%BE.png\" alt=\"箱线图\"></li>\n</ol>\n</li>\n<li>随机变量及其性质<ol>\n<li>随机变量定义：设随机实验的样本空间为S，若对每个样本点 s∈S，都有唯一的实数X(s)与之对应，则称X&#x3D;X(s)为随机变量<ol>\n<li>示例：抛 10 次硬币实验，样本空间S &#x3D; {s|s是十次正反面的序列}，定义随机变量X(s)为序列中正面出现的次数，则X(s)的取值范围为Rx &#x3D; {1，2，···，10}</li>\n</ol>\n</li>\n<li>随机变量类型<ol>\n<li>离散随机变量（Discrete Random Variable）：取值为有限个或可列无限个</li>\n<li>连续随机变量（Continuous Random Variable）：取值充满某个区间</li>\n</ol>\n</li>\n<li>随机变量的特征<ol>\n<li>均值（期望，Mean&#x2F;Expectation，μ）：<ol>\n<li>离散随机变量：μ &#x3D; E[X] &#x3D; ∑x xp(x)，其中p(x) &#x3D; P(X &#x3D; x)为概率质量函数</li>\n<li>连续随机变量：μ &#x3D; E[X] &#x3D; ∫(负无穷 到 正无穷) xf(x)dx，其中f(x)为概率密度函数，且∫(负无穷 到 正无穷) f(x)dx &#x3D; 1</li>\n</ol>\n</li>\n<li>中位数（Median，m）：<ol>\n<li>离散随机变量：满足 P(X ≤ m) ≥ 1&#x2F;2 且 P(X ≥ m) ≥ 1&#x2F;2 的数值</li>\n<li>连续随机变量：概率密度函数下面积被x&#x3D;m分为两部分，每部分面积为1&#x2F;2，即 ∫(负无穷 到 m) f(x)dx &#x3D; 1&#x2F;2</li>\n</ol>\n</li>\n<li>众数（Mode）：概率密度函数（或概率质量函数）的局部最大值点，可能有多个</li>\n<li>方差（Variance，σ^2）：衡量随机变量取值与均值的偏离程度，公式为σ^2 &#x3D; E[(X−μ)^2]，其中：<ol>\n<li>离散随机变量：σ^2 &#x3D; ∑x (x-μ)^2p(x)</li>\n<li>连续随机变量：σ^2 &#x3D; ∫(负无穷 到 正无穷) (x-μ)^f(x)dx</li>\n</ol>\n</li>\n<li><code>累积分布函数（Cumulative Distribution Function，CDF，F(x)）：F(x) = P(X≤x)，其中：</code><ol>\n<li>离散随机变量：F(x) &#x3D; ∑(t≤x) p(t)</li>\n<li>离散随机变量：F(x) &#x3D; ∫(负无穷 到 x) f(t)dt</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>抽样分布<ol>\n<li>随机样本：设X1，X2，···， Xn是相互独立的随机变量，且每个Xi都与总体X具有相同的概率密度函数f(x)，则称X1，X2，···， Xn为来自总体X的容量为n的随机样本。随机样本的联合概率密度函数为 f(x1，x2，···，xn) &#x3D; f(x1)f(x2)···f(xn)</li>\n<li>统计量：<ol>\n<li>定义：设X1，X2，···， Xn是来自总体的随机样本，若样本的函数T &#x3D; T(X1，X2，···， Xn)不含任何未知参数，则称T为统计量</li>\n<li>常见统计量：<ol>\n<li>样本均值：ˉX&#x3D; 1&#x2F;n ∑(i&#x3D;1 到 n) Xi（对应观测样本的 x̄ &#x3D; 1&#x2F;n ∑(i&#x3D;1 到 n) xi是具体数值，而ˉX是随机变量）</li>\n<li>样本方差：S^2 &#x3D; 1&#x2F;(n-1) ∑(i&#x3D;1 到 n) (Xi - ˉX)^2（对应观测样本的 s^2 &#x3D; 1&#x2F;(n-1) ∑(i&#x3D;1 到 n) (xi - x̄)^2是具体数值，而S^2是随机变量）</li>\n</ol>\n</li>\n<li>抽样分布定义：统计量的概率分布称为抽样分布，它描述了统计量的取值规律，是进行统计推断（如估计总体参数、检验假设）的重要依据，通过抽样分布可将样本信息与总体参数关联起来</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>样本均值的抽样分布<ol>\n<li>核心结论：<ol>\n<li>期望：样本均值的期望等于总体均值，即 E[X] &#x3D; μ</li>\n<li>方差：样本均值的方差等于总体方差除以样本量，即 Var(ˉX) &#x3D; σ^2&#x2F;n（若总体方差为σ^2)</li>\n</ol>\n</li>\n<li>两种情况的抽样分布形态：<table>\n<thead>\n<tr>\n<th align=\"center\">总体分布情况</th>\n<th align=\"center\">样本均值ˉX的抽样分布</th>\n<th align=\"center\">适用条件</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">总体服从正态分布 (X ∼ N(μ，σ^2))</td>\n<td align=\"center\">X ∼ N(μ，σ^2&#x2F;n)</td>\n<td align=\"center\">无论样本量n大小，均成立</td>\n</tr>\n<tr>\n<td align=\"center\">总体分布未知（但总体均值μ、方差σ^2有限）</td>\n<td align=\"center\">当n足够大时，近似 X ∼ N(μ，σ^2&#x2F;n)</td>\n<td align=\"center\">中心极限定理（CLT），通常 n≥30 时近似效果好；若n&lt;30，需总体分布接近正态</td>\n</tr>\n</tbody></table>\n</li>\n<li>示例：<ol>\n<li>已知：某大学学生平均年龄μ&#x3D;22.3岁，标准差σ&#x3D;4岁（方差σ^2&#x3D;16），随机抽取n&#x3D;64名学生</li>\n<li>求：样本平均年龄大于23岁的概率 P(ˉX &gt; 23)</li>\n<li>解：因 n&#x3D;64 ≥ 30，由CLT，X ∼ N(μ &#x3D; 22.3，σ^2&#x2F;n &#x3D; 16&#x2F;64) &#x3D; N(22.3，0.25)标准化得 Z &#x3D; (ˉX - μ) &#x2F; √σ ∼ N(0，1)，则 P(ˉX &gt; 23) &#x3D; P(Z &gt; (23-22.3)&#x2F;√0.25) &#x3D; P(Z &gt; 1.40)。查标准正态分布表，P(Z ≤ 1.40) &#x3D; 0.9192，所以P(Z &gt; 1.40) &#x3D; 1 - 0.9192 &#x3D; 0.0808</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>中心极限定理（CLT）的用途<ol>\n<li>获取样本均值的抽样分布：基于总体参数 (μ，σ^2)和样本量n，确定ˉX的分布形态（近似正态分布），为后续统计计算奠定基础</li>\n<li>推断未知总体均值μ：<ol>\n<li>假设检验：判断样本均值x̄是否支持对μ的某个假设（如“μ &#x3D; μ0”）</li>\n<li>估计：通过样本均值及抽样分布，给出μ的估计区间（如置信区间）</li>\n<li>质量控制：监测生产过程中产品指标的均值是否在合理范围内，判断过程是否稳定</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>两均值差的抽样分布（ˉX1 - ˉX2）<ol>\n<li>定理：设从两个总体中分别抽取独立样本：<br>  样本1：容量n1，来自均值μ1，方差σ^2(1)的总体<br>  样本2：容量n2，来自均值μ2，方差σ^2(2)的总体<br>  则当n1和n2足够大时（通常≥30），或两个总体均服从正态分布时，两样本均值差 ˉX1 - ˉX2 近似服从正态分布：ˉX1 - ˉX2 ∼ N(μ1-μ2，σ^2(1)&#x2F;n1 + σ^2(2)&#x2F;n2) （注意加减号）</li>\n</ol>\n</li>\n<li>X^2分布<ol>\n<li>定义：设X1，X2，···，Xn是来自正态总体N(μ，σ^2)的随机样本，S^2为样本方差，则统计量 X^2 &#x3D; (n-1)S^2 &#x2F; σ^2，服从自由度为 v &#x3D; n-1 的X^2分布，记为 X^2 ∼ X^2(v)</li>\n<li>形态：<ol>\n<li>取值范围：X^2 ≥ 0（非负）</li>\n<li>自由度影响：自由度v越小，分布越偏右；v越大，分布越接近正态分布</li>\n<li>分位数：用 X^2(a)(v) 表示自由度为v的X^2分布中，右侧面积为a的分位数（如v&#x3D;7时，X^2(0.05)(7) &#x3D; 14.067，X^2(0.95)(7) &#x3D; 2.167）</li>\n<li>区间概率：如 95% 的X^2值落在X^2(0.975)(v)与X^2(0.025)(v)之间，若X^2值超出此范围，可能表明假设的总体方差σ^2不合理</li>\n</ol>\n</li>\n<li>用途：主要用于<strong>统计推断</strong>，核心是检验 “观测数据与预期数据的差异是否由随机因素导致”，具体应用包括：<ol>\n<li>总体方差的区间估计和假设检验（如判断总体方差是否等于某个假设值）</li>\n<li>拟合优度检验（检验观测数据是否符合某一理论分布，如正态分布、二项分布）</li>\n<li>独立性检验（检验两个分类变量是否独立）</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>t分布（Student t -Distribution）<ol>\n<li>定义：<ol>\n<li>基础定义：设 Z ∼ N(0，1)（标准正态分布），V ∼ X^2(v)（自由度v的X^2分布），且Z与V独立，则随机变量 T &#x3D; Z &#x2F; √(V&#x2F;v) 服从自由度为v的t分布，记作 T ∼ t(v)</li>\n<li>推论（样本均值相关）：设 X1，X2，···，Xn 是来自正态总体N(μ，σ^2)的随机样本，ˉX为样本均值，S^2为样本方差，则统计量 T &#x3D; (ˉX - μ) &#x2F; (S&#x2F;√n)，服从自由度为 v &#x3D; n-1 的t分布</li>\n</ol>\n</li>\n<li>形态：<ol>\n<li>对称性：钟形，关于t&#x3D;0对称（与标准正态分布类似）</li>\n<li>方差特性：方差 &#x3D; v &#x2F; v-2 (v&gt;2)，大于1，故比标准正态分布更分散（尾部更粗）</li>\n<li>自由度影响：自由度v越大，t分布越接近标准正态分布（v趋近于无穷时，t分布趋近于N(0,1)）</li>\n<li>分位数：用ta(v)表示自由度为v的t分布中，右侧面积为a的分位数，由对称性得t1-a(v) &#x3D; -ta(v)</li>\n</ol>\n</li>\n<li>用途：<ol>\n<li>核心场景：总体方差σ^2未知时的统计推断，具体包括：<ol>\n<li>总体均值μ的区间估计和假设检验（如样本量较小时，用S替代σ，用 t 分布而非正态分布）</li>\n<li>两独立样本均值差的检验（当两总体方差未知且可能相等或不等时，用t分布或近似t分布）</li>\n<li>配对样本均值差的检验（如同一组对象前后两次测量的均值差检验）</li>\n</ol>\n</li>\n<li>注意事项：<ol>\n<li>使用 t 分布的前提是总体服从正态分布（或样本量较大时，由CLT近似正态，但t分布的使用与CLT无直接关联）</li>\n<li>若总体不服从正态且样本量小（n&lt;30），则t分布的近似效果差，不宜使用</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>F分布<ol>\n<li>定义<ol>\n<li>基础定义：设 U ∼ X^2(v1)（自由度v1的X^2分布），V ∼ X^2(v2)（自由度v2的X^2分布），且U与V独立，则随机变量 F &#x3D; (U&#x2F;v1)&#x2F;(V&#x2F;v2) 服从自由度为(v1，v2)的F分布，记为 F ∼ F(v1，v2)，其中v1为分子自由度，v2为分母自由度</li>\n<li>推论（样本方差相关）：设 S^2(1) 是来自正态总体 N(μ1，σ^2(1)) 的样本（容量n1）的方差，S^2(2) 是来自正态总体 N(μ2，σ^2(2)) 的样本（容量n2）的方差，且两样本独立，则统计量 F &#x3D; (S^2(1)&#x2F;σ^2(1)) &#x2F; (S^2(2)&#x2F;σ^2(2)) &#x3D; σ^2(2)S^2(1) &#x2F; σ^2(1)S^2(2) 服从自由度为(v1 &#x3D; n1 - 1，v2 &#x3D; n2 - 1)的F分布，</li>\n</ol>\n</li>\n<li>形态<ol>\n<li>取值范围：F≥0（非负）</li>\n<li>自由度影响：分布形态由分子自由度v1和分母自由度v2共同决定，通常为右偏分布，v1和v2越大，分布越接近正态分布</li>\n<li>分位数：用fa(v1，v2)表示自由度为(v1，v2)的F分布中，右侧面积为a的分位数</li>\n<li>分位数关系：fa(v1，v2) &#x3D; 1 &#x2F; (f1-a(v2，v1))，用于计算低尾分位数</li>\n</ol>\n</li>\n<li>用途：<ol>\n<li>核心场景：方差分析（Analysis of Variance，ANOVA），用于检验多个总体均值是否相等，具体包括：<ol>\n<li>单因素方差分析（如检验三种油漆的平均干燥时间是否相等）：通过比较 “组间方差”（样本均值间的变异）与 “组内方差”（样本内部的变异）的比值（F统计量），判断均值是否存在显著差异</li>\n<li>两总体方差的比较：检验两个正态总体的方差是否相等（如判断两样本的方差是否齐性，为两样本均值检验选择方法）</li>\n<li>多因素方差分析：分析多个因素对因变量的影响及因素间的交互作用</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>本章关键问题：<ol>\n<li>在数据分布描述中，异常值的判断标准是什么？为什么在计算样本方差时，分母使用n−1而非n？<ol>\n<li>异常值判断标准：若某个观测值落在 <strong>Q1−1.5IQR以下或Q3+1.5IQR以上</strong>，则该观测值可能为异常值</li>\n<li>样本方差分母用n−1的原因：为了实现<strong>无偏估计</strong>，由于样本均值x̄是通过样本数据计算得出的，存在 “自由度损失” —— ∑(i&#x3D;1 到 n) (xi - x̄) &#x3D; 0，即n个偏差中只有n−1个是独立的若用</li>\n</ol>\n</li>\n<li>心极限定理（CLT）的核心内容是什么？其在样本均值抽样分布和两均值差抽样分布中有哪些具体应用？<ol>\n<li>中心极限定理（CLT）核心内容：设总体的均值为μ、方差为σ^2（有限），从该总体中抽取容量为n的随机样本，当n足够大时（通常n≥30），样本均值ˉX的抽样分布近似服从均值为μ，方差为σ^2&#x2F;n的正态分布（即近似 ˉX ∼ N(μ，σ^2&#x2F;n)）且该近似效果与总体原始分布无关（即使总体非正态，只要n足够大，样本均值仍近似正态）</li>\n<li>在样本均值抽样分布中的应用：<ol>\n<li>当总体分布未知时，若n≥30，可通过CLT认为ˉX近似正态，进而计算与样本均值相关的概率</li>\n<li>当n&lt;30时，若总体分布接近正态CLT的近似效果仍可接受；若总体严重非正态，则需增大样本量以满足CLT条件</li>\n</ol>\n</li>\n<li>CLT 可推广到两独立样本场景</li>\n</ol>\n</li>\n<li><code>X^2分布、T分布、F分布的核心用途有何差异？分别适用于哪些统计推断场景？</code><ol>\n<li>X^2分布、T分布、F分布的核心用途及适用场景存在显著差异，具体如下表所示：<table>\n<thead>\n<tr>\n<th align=\"center\">分布类型</th>\n<th align=\"center\">核心用途</th>\n<th align=\"center\">适用场景示例</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">X^2分布</td>\n<td align=\"center\">围绕方差与数据拟合程度展开，用于检验 “观测数据与预期数据的差异是否由随机因素导致”</td>\n<td align=\"center\">1. <strong>总体方差推断</strong>：总体方差σ^2的区间估计和假设检验（如判断汽车电池寿命的标准差是否为 1 年）<br>2. <strong>拟合优度检验</strong>：检验观测数据是否符合某一理论分布（如检验学生成绩是否服从正态分布）<br>3. <strong>独立性检验</strong>：检验两个分类变量是否独立（如检验 “性别” 与 “是否购买某产品” 是否独立）</td>\n</tr>\n<tr>\n<td align=\"center\">T分布</td>\n<td align=\"center\">围绕总体方差未知时的均值推断展开，解决 “总体方差σ^2未知，无法使用正态分布” 的问题</td>\n<td align=\"center\">1. <strong>单总体均值推断</strong>：总体方差未知时，总体均值μ的区间估计和假设检验（如样本量较小时，检验化工过程的产量均值是否为 500g&#x2F;ml）<br>2. <strong>两样本均值差推断</strong>：两总体方差未知时，检验两总体均值是否相等（如检验两种药物的疗效均值是否有差异）<br>3. <strong>配对样本推断</strong>：检验配对数据的均值差（如检验同一组患者用药前后的血压均值差）</td>\n</tr>\n<tr>\n<td align=\"center\">F分布</td>\n<td align=\"center\">围绕方差比值与多总体均值比较展开，核心是 “通过方差比值判断差异是否显著”</td>\n<td align=\"center\">1. <strong>两总体方差比较</strong>：检验两个正态总体的方差是否相等（如判断两批产品的质量波动是否一致，即方差齐性检验）<br>2. <strong>方差分析（ANOVA）</strong>：检验多个总体的均值是否相等（如检验三种不同品牌油漆的平均干燥时间是否有差异）<br>3. <strong>多因素方差分析</strong>：分析多个因素对因变量的影响及因素间的交互作用（如分析 “温度”“压力” 对产品产量的影响）</td>\n</tr>\n</tbody></table>\n</li>\n<li>三者的核心差异在于：X^2分布聚焦 “方差与拟合度”，T分布聚焦 “方差未知时的均值”，F分布聚焦 “方差比值与多均值比较”，分别对应统计推断中不同维度的问题</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"今日总结\"><a href=\"#今日总结\" class=\"headerlink\" title=\"今日总结\"></a>今日总结</h2><ol>\n<li>今天在记笔记时要加入表格，发现：<ol>\n<li><code>为了避免序号被打乱，要通过缩进确保表格属于上一级列表项</code></li>\n<li><code>若需要在表格中加入序列需要使用&lt;br&gt;标签进行换行</code></li>\n</ol>\n</li>\n<li>今天在记笔记时要插入图片，步骤如下：<ol>\n<li><code>在source文件夹里创建一个images文件夹用于存放图片</code></li>\n<li><code>在Markdown文件中用语法：！\\[图片描述]\\[/images/图片名]</code></li>\n<li><code>注意：此方法只能在发布出来的博客中看见图片</code></li>\n<li>过程中在终端中下载了安装 hexo-asset-img 插件</li>\n</ol>\n</li>\n<li>今天看见Stela在跑步，和她约了下次一起跑步</li>\n<li>英语口语学习</li>\n<li>今天的网球活动感觉打的越来越好了</li>\n</ol>\n<h2 id=\"摘录\"><a href=\"#摘录\" class=\"headerlink\" title=\"摘录\"></a>摘录</h2><ol>\n<li>管理情绪主要包括三个方面的内容：一是认识自己的情绪；二是疏解自己的情绪；三是适当表达自己的情绪。</li>\n<li>脱困四问：<ol>\n<li>Emotion：我正处于何种情绪里？这种情绪的程度如何？</li>\n<li>Event：我为什么产生这样的情绪？（注意：需要客观真实看待所发生的事情，不能带有主观倾向）</li>\n<li>Target：我的初衷是什么？</li>\n<li>Action：接下来我该怎么做？我可以做些什么？</li>\n</ol>\n</li>\n<li>生活的本质在于追求快乐，而让自己的人生变得快乐的途径有两种：不断地发现有限生命中的快乐时光，并增加它；发现那些令自己不快乐的时光，并尽可能减少它。 —— 亚里士多德</li>\n<li>两弊相衡取其轻，两利相权取其重</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>学习笔记</li>\n<li>今日总结</li>\n<li>摘录</li>\n</ol>\n<h2 id=\"学习笔记\"><a href=\"#学习笔记\" class=\"headerlink\" title=\"学习笔记\"></a>学习笔记</h2><h3 id=\"概率\"><a href=\"#概率\" class=\"headerlink\" title=\"概率\"></a>概率</h3><ol>\n<li>数据与数据表示<ol>\n<li>图表类型：<ol>\n<li>柱状图（Bar graph）</li>\n<li>饼图（Pie Chart）</li>\n<li>交叉表（Cross Table）：可以变成并排的簇状图（几个柱作为一个整体）或堆叠的分组条形图（一个柱上有几个不同的特性）</li>\n<li>直方图（Histogram）</li>\n<li>累积频率图（Ogive）：连接各区间上限累积百分比的线，展示累积频率分布</li>\n<li>茎叶图（Stem and Leaf Plot）：同时展示数据的分布和原始值（中间的主干数据加上两边的枝干数据）</li>\n<li>时间序列图（Time Series Plot）：横轴为时间，纵轴为序列值，展示数据随时间的变化趋势</li>\n<li>散点图（Scatterplot）：观测两个定量变量的关系，需关注关联方向（正 &#x2F; 负）、形式（线性 &#x2F; 非线性）、强度（紧密 &#x2F; 松散）</li>\n</ol>\n</li>\n<li>频率表<ol>\n<li>分类数据频率表：列出类别及对应数量（频率），相对频率表则列出百分比（比例）<ol>\n<li>频率表：  <table>\n<thead>\n<tr>\n<th>舱位</th>\n<th>数量</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>头等舱（First）</td>\n<td>324</td>\n</tr>\n<tr>\n<td>二等舱（Second）</td>\n<td>285</td>\n</tr>\n<tr>\n<td>三等舱（Third）</td>\n<td>710</td>\n</tr>\n<tr>\n<td>船员（Crew）</td>\n<td>889</td>\n</tr>\n</tbody></table>\n</li>\n<li>相对频率表  <table>\n<thead>\n<tr>\n<th>舱位</th>\n<th>百分比（%）</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>头等舱（First）</td>\n<td>14.67</td>\n</tr>\n<tr>\n<td>二等舱（Second）</td>\n<td>12.91</td>\n</tr>\n<tr>\n<td>三等舱（Third）</td>\n<td>32.16</td>\n</tr>\n<tr>\n<td>船员（Crew）</td>\n<td>40.26</td>\n</tr>\n</tbody></table>\n</li>\n</ol>\n</li>\n<li>数值数据频率表：<ol>\n<li>构建规则：根据样本量n选择，如下表：<table>\n<thead>\n<tr>\n<th>样本量（n）</th>\n<th>组数（k）</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>&lt;50</td>\n<td>5-7</td>\n</tr>\n<tr>\n<td>50-100</td>\n<td>7-8</td>\n</tr>\n<tr>\n<td>101-500</td>\n<td>8-10</td>\n</tr>\n<tr>\n<td>501-1000</td>\n<td>10-11</td>\n</tr>\n<tr>\n<td>1001-5000</td>\n<td>11-14</td>\n</tr>\n<tr>\n<td>&gt;5000</td>\n<td>14-20</td>\n</tr>\n</tbody></table>\n</li>\n<li>选择组宽：class width &#x3D; (最大观测值 - 最小观测值) &#x2F; 组数k （注意：需向上取整（根据数据小数位数））</li>\n<li>组的要求：包含所有数据且不重叠，每个观测属于唯一一组</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>四种测量尺度<table>\n<thead>\n<tr>\n<th align=\"center\">尺度类型</th>\n<th align=\"center\">核心特征</th>\n<th align=\"center\">示例</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">名义尺度（Nominal）</td>\n<td align=\"center\">仅用于命名 &#x2F; 标签，非定量值，无顺序和大小关系</td>\n<td align=\"center\">欧洲国家、运动员 T 恤号码、性别、发色</td>\n</tr>\n<tr>\n<td align=\"center\">顺序尺度（Ordinal）</td>\n<td align=\"center\">有顺序，非定量值，无法精确衡量差值</td>\n<td align=\"center\">幸福感等级、服务满意度</td>\n</tr>\n<tr>\n<td align=\"center\">区间尺度（Interval）</td>\n<td align=\"center\">定量，有顺序，可衡量差值，无 “真零”（零无实际意义），无法计算比率</td>\n<td align=\"center\">摄氏温度（60℃与 50℃差值 &#x3D; 80℃与 70℃差值 &#x3D; 10℃，但 0℃不代表无温度）</td>\n</tr>\n<tr>\n<td align=\"center\">比率尺度（Ratio）</td>\n<td align=\"center\">定量，有顺序，可衡量差值，有 “真零”（零代表无），可计算比率</td>\n<td align=\"center\">体重（20kg 是 10kg 的 2 倍）、身高</td>\n</tr>\n</tbody></table>\n</li>\n<li>分布描述<ol>\n<li>集中趋势测量（反映数据典型值）<ol>\n<li>均值（Mean，x̄）：算术平均，公式为 x̄ &#x3D; (∑(i&#x3D;1 到 n) xi) &#x2F; (n - 1)</li>\n<li>中位数（Median，m）：有序数据的中点，即第 50 百分位数</li>\n<li>众数（Mode）：数据中出现频率最高的数值，可能有多个（如双峰、多峰分布）</li>\n</ol>\n</li>\n<li>离散程度测量（反映数据变异性）<ol>\n<li>范围（Range）：最大值与最小值的差值，公式为 Range &#x3D; 最大观测值 - 最小观测值</li>\n<li>四分位距（Interquartile Range，IQR）：上四分位数（Q3）与下四分位数（Q1）的差值，公式为 IQR &#x3D; Q3 - Q1<ol>\n<li>计算Q1和Q3的规则：<ol>\n<li>若n为奇数：Q1是<strong>前</strong>(n+1&#x2F;2)-1个数据的中位数，Q3是<strong>后</strong>(n+1&#x2F;2)-1个数据的中位数</li>\n<li>若n为偶数：Q1是<strong>前</strong>n&#x2F;2个数据的中位数，Q1是<strong>后</strong>n&#x2F;2个数据的中位数</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>方差（Variance，s^2）与标准差（Standard Deviation，s）：<ol>\n<li>方差：衡量数据与均值的偏离程度，样本方差公式为 s^2 &#x3D; ∑(i&#x3D;1 到 n) (xi - x̄)^2 &#x2F; n-1 （<strong>分母用n-1是因为∑(xi - x̄) &#x3D; 0，即仅n−1个偏差可自由变化</strong>）</li>\n<li>标准差：方差的平方根，单位与原始数据一致，<code>值越大说明数据越分散，越小则越集中</code></li>\n</ol>\n</li>\n<li>形状（反映数据分布形态）：<ol>\n<li>偏度（Skewness）：衡量分布的不对称性<ol>\n<li>负偏（Negatively skewed）：均值 &lt; 中位数 &lt; 众数，分布左侧长尾</li>\n<li>正态（Normal，无偏）：均值 &#x3D; 中位数 &#x3D; 众数，分布对称</li>\n<li>正偏（Positively skewed）：众数 &lt; 中位数 &lt; 均值，分布右侧长尾</li>\n</ol>\n</li>\n<li>众数数量：<ol>\n<li>单峰（Unimodal）：只有一个众数</li>\n<li>双峰（Bimodal）：有两个众数</li>\n<li>多峰（Multimodal）：有三个及以上众数</li>\n</ol>\n</li>\n<li>异常值（Outliers）：<ol>\n<li>定义：远离数据主体的观测值，可能由实验误差导致，有时需从数据集中剔除</li>\n<li>判断标准：若观测值落在<code>Q1 - 1.5IQR以下</code>或<code>Q3 + 1.5IQR以上</code>，则可能为异常值</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>箱线图（Box-and-whisker plot）<ol>\n<li>定义：一种图形化展示数据分布的工具，呈现中位数、Q1、Q3及潜在异常值</li>\n<li>组成部分：<ol>\n<li>箱体：从Q1延伸至Q3，箱内横线代表中位数</li>\n<li>须（Whiskers）：从箱体两端延伸至 Q1 - 1.5IQR 和 Q3 + 1.5IQR 范围内的最小和最大数据点</li>\n<li>异常值：超出须范围的数据点，单独标记</li>\n</ol>\n</li>\n<li>用途：作为诊断工具，直观观察数据分布的集中趋势、离散程度和异常值，非用于正式的异常值检验<br><img src=\"/images/%E7%AE%B1%E7%BA%BF%E5%9B%BE.png\" alt=\"箱线图\"></li>\n</ol>\n</li>\n<li>随机变量及其性质<ol>\n<li>随机变量定义：设随机实验的样本空间为S，若对每个样本点 s∈S，都有唯一的实数X(s)与之对应，则称X&#x3D;X(s)为随机变量<ol>\n<li>示例：抛 10 次硬币实验，样本空间S &#x3D; {s|s是十次正反面的序列}，定义随机变量X(s)为序列中正面出现的次数，则X(s)的取值范围为Rx &#x3D; {1，2，···，10}</li>\n</ol>\n</li>\n<li>随机变量类型<ol>\n<li>离散随机变量（Discrete Random Variable）：取值为有限个或可列无限个</li>\n<li>连续随机变量（Continuous Random Variable）：取值充满某个区间</li>\n</ol>\n</li>\n<li>随机变量的特征<ol>\n<li>均值（期望，Mean&#x2F;Expectation，μ）：<ol>\n<li>离散随机变量：μ &#x3D; E[X] &#x3D; ∑x xp(x)，其中p(x) &#x3D; P(X &#x3D; x)为概率质量函数</li>\n<li>连续随机变量：μ &#x3D; E[X] &#x3D; ∫(负无穷 到 正无穷) xf(x)dx，其中f(x)为概率密度函数，且∫(负无穷 到 正无穷) f(x)dx &#x3D; 1</li>\n</ol>\n</li>\n<li>中位数（Median，m）：<ol>\n<li>离散随机变量：满足 P(X ≤ m) ≥ 1&#x2F;2 且 P(X ≥ m) ≥ 1&#x2F;2 的数值</li>\n<li>连续随机变量：概率密度函数下面积被x&#x3D;m分为两部分，每部分面积为1&#x2F;2，即 ∫(负无穷 到 m) f(x)dx &#x3D; 1&#x2F;2</li>\n</ol>\n</li>\n<li>众数（Mode）：概率密度函数（或概率质量函数）的局部最大值点，可能有多个</li>\n<li>方差（Variance，σ^2）：衡量随机变量取值与均值的偏离程度，公式为σ^2 &#x3D; E[(X−μ)^2]，其中：<ol>\n<li>离散随机变量：σ^2 &#x3D; ∑x (x-μ)^2p(x)</li>\n<li>连续随机变量：σ^2 &#x3D; ∫(负无穷 到 正无穷) (x-μ)^f(x)dx</li>\n</ol>\n</li>\n<li><code>累积分布函数（Cumulative Distribution Function，CDF，F(x)）：F(x) = P(X≤x)，其中：</code><ol>\n<li>离散随机变量：F(x) &#x3D; ∑(t≤x) p(t)</li>\n<li>离散随机变量：F(x) &#x3D; ∫(负无穷 到 x) f(t)dt</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>抽样分布<ol>\n<li>随机样本：设X1，X2，···， Xn是相互独立的随机变量，且每个Xi都与总体X具有相同的概率密度函数f(x)，则称X1，X2，···， Xn为来自总体X的容量为n的随机样本。随机样本的联合概率密度函数为 f(x1，x2，···，xn) &#x3D; f(x1)f(x2)···f(xn)</li>\n<li>统计量：<ol>\n<li>定义：设X1，X2，···， Xn是来自总体的随机样本，若样本的函数T &#x3D; T(X1，X2，···， Xn)不含任何未知参数，则称T为统计量</li>\n<li>常见统计量：<ol>\n<li>样本均值：ˉX&#x3D; 1&#x2F;n ∑(i&#x3D;1 到 n) Xi（对应观测样本的 x̄ &#x3D; 1&#x2F;n ∑(i&#x3D;1 到 n) xi是具体数值，而ˉX是随机变量）</li>\n<li>样本方差：S^2 &#x3D; 1&#x2F;(n-1) ∑(i&#x3D;1 到 n) (Xi - ˉX)^2（对应观测样本的 s^2 &#x3D; 1&#x2F;(n-1) ∑(i&#x3D;1 到 n) (xi - x̄)^2是具体数值，而S^2是随机变量）</li>\n</ol>\n</li>\n<li>抽样分布定义：统计量的概率分布称为抽样分布，它描述了统计量的取值规律，是进行统计推断（如估计总体参数、检验假设）的重要依据，通过抽样分布可将样本信息与总体参数关联起来</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>样本均值的抽样分布<ol>\n<li>核心结论：<ol>\n<li>期望：样本均值的期望等于总体均值，即 E[X] &#x3D; μ</li>\n<li>方差：样本均值的方差等于总体方差除以样本量，即 Var(ˉX) &#x3D; σ^2&#x2F;n（若总体方差为σ^2)</li>\n</ol>\n</li>\n<li>两种情况的抽样分布形态：<table>\n<thead>\n<tr>\n<th align=\"center\">总体分布情况</th>\n<th align=\"center\">样本均值ˉX的抽样分布</th>\n<th align=\"center\">适用条件</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">总体服从正态分布 (X ∼ N(μ，σ^2))</td>\n<td align=\"center\">X ∼ N(μ，σ^2&#x2F;n)</td>\n<td align=\"center\">无论样本量n大小，均成立</td>\n</tr>\n<tr>\n<td align=\"center\">总体分布未知（但总体均值μ、方差σ^2有限）</td>\n<td align=\"center\">当n足够大时，近似 X ∼ N(μ，σ^2&#x2F;n)</td>\n<td align=\"center\">中心极限定理（CLT），通常 n≥30 时近似效果好；若n&lt;30，需总体分布接近正态</td>\n</tr>\n</tbody></table>\n</li>\n<li>示例：<ol>\n<li>已知：某大学学生平均年龄μ&#x3D;22.3岁，标准差σ&#x3D;4岁（方差σ^2&#x3D;16），随机抽取n&#x3D;64名学生</li>\n<li>求：样本平均年龄大于23岁的概率 P(ˉX &gt; 23)</li>\n<li>解：因 n&#x3D;64 ≥ 30，由CLT，X ∼ N(μ &#x3D; 22.3，σ^2&#x2F;n &#x3D; 16&#x2F;64) &#x3D; N(22.3，0.25)标准化得 Z &#x3D; (ˉX - μ) &#x2F; √σ ∼ N(0，1)，则 P(ˉX &gt; 23) &#x3D; P(Z &gt; (23-22.3)&#x2F;√0.25) &#x3D; P(Z &gt; 1.40)。查标准正态分布表，P(Z ≤ 1.40) &#x3D; 0.9192，所以P(Z &gt; 1.40) &#x3D; 1 - 0.9192 &#x3D; 0.0808</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>中心极限定理（CLT）的用途<ol>\n<li>获取样本均值的抽样分布：基于总体参数 (μ，σ^2)和样本量n，确定ˉX的分布形态（近似正态分布），为后续统计计算奠定基础</li>\n<li>推断未知总体均值μ：<ol>\n<li>假设检验：判断样本均值x̄是否支持对μ的某个假设（如“μ &#x3D; μ0”）</li>\n<li>估计：通过样本均值及抽样分布，给出μ的估计区间（如置信区间）</li>\n<li>质量控制：监测生产过程中产品指标的均值是否在合理范围内，判断过程是否稳定</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>两均值差的抽样分布（ˉX1 - ˉX2）<ol>\n<li>定理：设从两个总体中分别抽取独立样本：<br>  样本1：容量n1，来自均值μ1，方差σ^2(1)的总体<br>  样本2：容量n2，来自均值μ2，方差σ^2(2)的总体<br>  则当n1和n2足够大时（通常≥30），或两个总体均服从正态分布时，两样本均值差 ˉX1 - ˉX2 近似服从正态分布：ˉX1 - ˉX2 ∼ N(μ1-μ2，σ^2(1)&#x2F;n1 + σ^2(2)&#x2F;n2) （注意加减号）</li>\n</ol>\n</li>\n<li>X^2分布<ol>\n<li>定义：设X1，X2，···，Xn是来自正态总体N(μ，σ^2)的随机样本，S^2为样本方差，则统计量 X^2 &#x3D; (n-1)S^2 &#x2F; σ^2，服从自由度为 v &#x3D; n-1 的X^2分布，记为 X^2 ∼ X^2(v)</li>\n<li>形态：<ol>\n<li>取值范围：X^2 ≥ 0（非负）</li>\n<li>自由度影响：自由度v越小，分布越偏右；v越大，分布越接近正态分布</li>\n<li>分位数：用 X^2(a)(v) 表示自由度为v的X^2分布中，右侧面积为a的分位数（如v&#x3D;7时，X^2(0.05)(7) &#x3D; 14.067，X^2(0.95)(7) &#x3D; 2.167）</li>\n<li>区间概率：如 95% 的X^2值落在X^2(0.975)(v)与X^2(0.025)(v)之间，若X^2值超出此范围，可能表明假设的总体方差σ^2不合理</li>\n</ol>\n</li>\n<li>用途：主要用于<strong>统计推断</strong>，核心是检验 “观测数据与预期数据的差异是否由随机因素导致”，具体应用包括：<ol>\n<li>总体方差的区间估计和假设检验（如判断总体方差是否等于某个假设值）</li>\n<li>拟合优度检验（检验观测数据是否符合某一理论分布，如正态分布、二项分布）</li>\n<li>独立性检验（检验两个分类变量是否独立）</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>t分布（Student t -Distribution）<ol>\n<li>定义：<ol>\n<li>基础定义：设 Z ∼ N(0，1)（标准正态分布），V ∼ X^2(v)（自由度v的X^2分布），且Z与V独立，则随机变量 T &#x3D; Z &#x2F; √(V&#x2F;v) 服从自由度为v的t分布，记作 T ∼ t(v)</li>\n<li>推论（样本均值相关）：设 X1，X2，···，Xn 是来自正态总体N(μ，σ^2)的随机样本，ˉX为样本均值，S^2为样本方差，则统计量 T &#x3D; (ˉX - μ) &#x2F; (S&#x2F;√n)，服从自由度为 v &#x3D; n-1 的t分布</li>\n</ol>\n</li>\n<li>形态：<ol>\n<li>对称性：钟形，关于t&#x3D;0对称（与标准正态分布类似）</li>\n<li>方差特性：方差 &#x3D; v &#x2F; v-2 (v&gt;2)，大于1，故比标准正态分布更分散（尾部更粗）</li>\n<li>自由度影响：自由度v越大，t分布越接近标准正态分布（v趋近于无穷时，t分布趋近于N(0,1)）</li>\n<li>分位数：用ta(v)表示自由度为v的t分布中，右侧面积为a的分位数，由对称性得t1-a(v) &#x3D; -ta(v)</li>\n</ol>\n</li>\n<li>用途：<ol>\n<li>核心场景：总体方差σ^2未知时的统计推断，具体包括：<ol>\n<li>总体均值μ的区间估计和假设检验（如样本量较小时，用S替代σ，用 t 分布而非正态分布）</li>\n<li>两独立样本均值差的检验（当两总体方差未知且可能相等或不等时，用t分布或近似t分布）</li>\n<li>配对样本均值差的检验（如同一组对象前后两次测量的均值差检验）</li>\n</ol>\n</li>\n<li>注意事项：<ol>\n<li>使用 t 分布的前提是总体服从正态分布（或样本量较大时，由CLT近似正态，但t分布的使用与CLT无直接关联）</li>\n<li>若总体不服从正态且样本量小（n&lt;30），则t分布的近似效果差，不宜使用</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>F分布<ol>\n<li>定义<ol>\n<li>基础定义：设 U ∼ X^2(v1)（自由度v1的X^2分布），V ∼ X^2(v2)（自由度v2的X^2分布），且U与V独立，则随机变量 F &#x3D; (U&#x2F;v1)&#x2F;(V&#x2F;v2) 服从自由度为(v1，v2)的F分布，记为 F ∼ F(v1，v2)，其中v1为分子自由度，v2为分母自由度</li>\n<li>推论（样本方差相关）：设 S^2(1) 是来自正态总体 N(μ1，σ^2(1)) 的样本（容量n1）的方差，S^2(2) 是来自正态总体 N(μ2，σ^2(2)) 的样本（容量n2）的方差，且两样本独立，则统计量 F &#x3D; (S^2(1)&#x2F;σ^2(1)) &#x2F; (S^2(2)&#x2F;σ^2(2)) &#x3D; σ^2(2)S^2(1) &#x2F; σ^2(1)S^2(2) 服从自由度为(v1 &#x3D; n1 - 1，v2 &#x3D; n2 - 1)的F分布，</li>\n</ol>\n</li>\n<li>形态<ol>\n<li>取值范围：F≥0（非负）</li>\n<li>自由度影响：分布形态由分子自由度v1和分母自由度v2共同决定，通常为右偏分布，v1和v2越大，分布越接近正态分布</li>\n<li>分位数：用fa(v1，v2)表示自由度为(v1，v2)的F分布中，右侧面积为a的分位数</li>\n<li>分位数关系：fa(v1，v2) &#x3D; 1 &#x2F; (f1-a(v2，v1))，用于计算低尾分位数</li>\n</ol>\n</li>\n<li>用途：<ol>\n<li>核心场景：方差分析（Analysis of Variance，ANOVA），用于检验多个总体均值是否相等，具体包括：<ol>\n<li>单因素方差分析（如检验三种油漆的平均干燥时间是否相等）：通过比较 “组间方差”（样本均值间的变异）与 “组内方差”（样本内部的变异）的比值（F统计量），判断均值是否存在显著差异</li>\n<li>两总体方差的比较：检验两个正态总体的方差是否相等（如判断两样本的方差是否齐性，为两样本均值检验选择方法）</li>\n<li>多因素方差分析：分析多个因素对因变量的影响及因素间的交互作用</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>本章关键问题：<ol>\n<li>在数据分布描述中，异常值的判断标准是什么？为什么在计算样本方差时，分母使用n−1而非n？<ol>\n<li>异常值判断标准：若某个观测值落在 <strong>Q1−1.5IQR以下或Q3+1.5IQR以上</strong>，则该观测值可能为异常值</li>\n<li>样本方差分母用n−1的原因：为了实现<strong>无偏估计</strong>，由于样本均值x̄是通过样本数据计算得出的，存在 “自由度损失” —— ∑(i&#x3D;1 到 n) (xi - x̄) &#x3D; 0，即n个偏差中只有n−1个是独立的若用</li>\n</ol>\n</li>\n<li>心极限定理（CLT）的核心内容是什么？其在样本均值抽样分布和两均值差抽样分布中有哪些具体应用？<ol>\n<li>中心极限定理（CLT）核心内容：设总体的均值为μ、方差为σ^2（有限），从该总体中抽取容量为n的随机样本，当n足够大时（通常n≥30），样本均值ˉX的抽样分布近似服从均值为μ，方差为σ^2&#x2F;n的正态分布（即近似 ˉX ∼ N(μ，σ^2&#x2F;n)）且该近似效果与总体原始分布无关（即使总体非正态，只要n足够大，样本均值仍近似正态）</li>\n<li>在样本均值抽样分布中的应用：<ol>\n<li>当总体分布未知时，若n≥30，可通过CLT认为ˉX近似正态，进而计算与样本均值相关的概率</li>\n<li>当n&lt;30时，若总体分布接近正态CLT的近似效果仍可接受；若总体严重非正态，则需增大样本量以满足CLT条件</li>\n</ol>\n</li>\n<li>CLT 可推广到两独立样本场景</li>\n</ol>\n</li>\n<li><code>X^2分布、T分布、F分布的核心用途有何差异？分别适用于哪些统计推断场景？</code><ol>\n<li>X^2分布、T分布、F分布的核心用途及适用场景存在显著差异，具体如下表所示：<table>\n<thead>\n<tr>\n<th align=\"center\">分布类型</th>\n<th align=\"center\">核心用途</th>\n<th align=\"center\">适用场景示例</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">X^2分布</td>\n<td align=\"center\">围绕方差与数据拟合程度展开，用于检验 “观测数据与预期数据的差异是否由随机因素导致”</td>\n<td align=\"center\">1. <strong>总体方差推断</strong>：总体方差σ^2的区间估计和假设检验（如判断汽车电池寿命的标准差是否为 1 年）<br>2. <strong>拟合优度检验</strong>：检验观测数据是否符合某一理论分布（如检验学生成绩是否服从正态分布）<br>3. <strong>独立性检验</strong>：检验两个分类变量是否独立（如检验 “性别” 与 “是否购买某产品” 是否独立）</td>\n</tr>\n<tr>\n<td align=\"center\">T分布</td>\n<td align=\"center\">围绕总体方差未知时的均值推断展开，解决 “总体方差σ^2未知，无法使用正态分布” 的问题</td>\n<td align=\"center\">1. <strong>单总体均值推断</strong>：总体方差未知时，总体均值μ的区间估计和假设检验（如样本量较小时，检验化工过程的产量均值是否为 500g&#x2F;ml）<br>2. <strong>两样本均值差推断</strong>：两总体方差未知时，检验两总体均值是否相等（如检验两种药物的疗效均值是否有差异）<br>3. <strong>配对样本推断</strong>：检验配对数据的均值差（如检验同一组患者用药前后的血压均值差）</td>\n</tr>\n<tr>\n<td align=\"center\">F分布</td>\n<td align=\"center\">围绕方差比值与多总体均值比较展开，核心是 “通过方差比值判断差异是否显著”</td>\n<td align=\"center\">1. <strong>两总体方差比较</strong>：检验两个正态总体的方差是否相等（如判断两批产品的质量波动是否一致，即方差齐性检验）<br>2. <strong>方差分析（ANOVA）</strong>：检验多个总体的均值是否相等（如检验三种不同品牌油漆的平均干燥时间是否有差异）<br>3. <strong>多因素方差分析</strong>：分析多个因素对因变量的影响及因素间的交互作用（如分析 “温度”“压力” 对产品产量的影响）</td>\n</tr>\n</tbody></table>\n</li>\n<li>三者的核心差异在于：X^2分布聚焦 “方差与拟合度”，T分布聚焦 “方差未知时的均值”，F分布聚焦 “方差比值与多均值比较”，分别对应统计推断中不同维度的问题</li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"今日总结\"><a href=\"#今日总结\" class=\"headerlink\" title=\"今日总结\"></a>今日总结</h2><ol>\n<li>今天在记笔记时要加入表格，发现：<ol>\n<li><code>为了避免序号被打乱，要通过缩进确保表格属于上一级列表项</code></li>\n<li><code>若需要在表格中加入序列需要使用&lt;br&gt;标签进行换行</code></li>\n</ol>\n</li>\n<li>今天在记笔记时要插入图片，步骤如下：<ol>\n<li><code>在source文件夹里创建一个images文件夹用于存放图片</code></li>\n<li><code>在Markdown文件中用语法：！\\[图片描述]\\[/images/图片名]</code></li>\n<li><code>注意：此方法只能在发布出来的博客中看见图片</code></li>\n<li>过程中在终端中下载了安装 hexo-asset-img 插件</li>\n</ol>\n</li>\n<li>今天看见Stela在跑步，和她约了下次一起跑步</li>\n<li>英语口语学习</li>\n<li>今天的网球活动感觉打的越来越好了</li>\n</ol>\n<h2 id=\"摘录\"><a href=\"#摘录\" class=\"headerlink\" title=\"摘录\"></a>摘录</h2><ol>\n<li>管理情绪主要包括三个方面的内容：一是认识自己的情绪；二是疏解自己的情绪；三是适当表达自己的情绪。</li>\n<li>脱困四问：<ol>\n<li>Emotion：我正处于何种情绪里？这种情绪的程度如何？</li>\n<li>Event：我为什么产生这样的情绪？（注意：需要客观真实看待所发生的事情，不能带有主观倾向）</li>\n<li>Target：我的初衷是什么？</li>\n<li>Action：接下来我该怎么做？我可以做些什么？</li>\n</ol>\n</li>\n<li>生活的本质在于追求快乐，而让自己的人生变得快乐的途径有两种：不断地发现有限生命中的快乐时光，并增加它；发现那些令自己不快乐的时光，并尽可能减少它。 —— 亚里士多德</li>\n<li>两弊相衡取其轻，两利相权取其重</li>\n</ol>\n"},{"title":"2025.9.24","date":"2025-09-24T08:00:56.000Z","_content":"# Summary\n1. Python学习（文件）\n2. 第一次网球社团活动\n3. 每日英语","source":"_posts/2025-9-24.md","raw":"---\ntitle: 2025.9.24\ndate: 2025-09-24 16:00:56\ntags:\n---\n# Summary\n1. Python学习（文件）\n2. 第一次网球社团活动\n3. 每日英语","slug":"2025-9-24","published":1,"updated":"2025-11-18T19:39:17.126Z","comments":1,"layout":"post","photos":[],"_id":"cuidNH3W1gOnkTCGymHQJwDkV","content":"<h1 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h1><ol>\n<li>Python学习（文件）</li>\n<li>第一次网球社团活动</li>\n<li>每日英语</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h1><ol>\n<li>Python学习（文件）</li>\n<li>第一次网球社团活动</li>\n<li>每日英语</li>\n</ol>\n"},{"title":"2025.9.10","date":"2025-09-10T10:21:33.000Z","_content":"# Overview\n今天跟随视频一步步搭建了属于自己的博客，我把整个过程以及所学记录下来\n\n## 流程\n### 安装hexo\n1. 安装nodejs\n2. 打开终端并切换到root用户（输入了 sudo su）\n   - 该过程中打开 设置 -> 系统 -> 开发者选项 -> 开启“启用Sudo” -> 选择运行模式“内联”\n   - 之后重启终端 -> 输入sudo whoami -> 显示 laptop-lv27uskg\\admin【表示当前以管理员权限执行了命令（laptop-lv27uskg 是我的计算机名，admin 是我的用户名），这说明 sudo 配置生效了。】\n3. 终端输入 node -v 和 npm -v（查看版本）\n   - 输入npm -v后显示:\n```powershell\n https:/go.microsoft.com/fwlink/?LinkID=135170 中的 about_Execution_Policies。\n所在位置 行:1 字符: 1\n+ npm -v\n+ ~~~\n    + CategoryInfo          : SecurityError: (:) []，PSSecurityException\n    + FullyQualifiedErrorId : UnauthorizedAccess\n```\n    - 终端输入：Get-ExecutionPolicy，显示：Restricted\n    - 终端输入：Set-ExecutionPolicy RemoteSigned\n    - 再次执行 Get-ExecutionPolicy，确认显示为 RemoteSigned\n    - 上面的步骤设置允许运行本地创建的脚本，同时对从网络下载的脚本进行安全检查，是比较平衡的安全策略。\n4. 终端输入：npm install -g cnpm --registry=https://registry.npmmirror.com\n   - 安装成功，接下来就可以使用 cnpm 命令来替代 npm 进行包管理了\n5. 终端输入：cnpm install -g hexo-cli\n   - 安装好hexo了\n6. 在E盘创建blog文件夹，并通过终端cd操作将路径改到创建好的blog文件夹\n7. 终端输入：sudo hexo init, 报错：\n```powershell\nINFO  Cloning hexo-starter https://github.com/hexojs/hexo-starter.git\n'git' 不是内部或外部命令，也不是可运行的程序\n或批处理文件。\nWARN  git clone failed. Copying data instead\nFATAL Something's wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.html\nError: EPERM: operation not permitted, mkdir 'E:\\'\n    at async Object.mkdir (node:internal/fs/promises:860:10)\n```\n    - 报错原因是缺少 Git 环境\n    - 通过Git 官网 下载 Windows 版本\n8. 再次输入：sudo hexo init\n   - 此时Hexo 已经成功初始化完成，现在博客项目基础框架已经搭建好了\n   - 输入：ls （查看当前目录下的文件）\n### 将博客部署到远端的GitHub上公开使用\n1. 创建并登录GitHub账号\n2. 创建一个仓库(repository)\n    - 注意：创建仓库时起的名字必须符合格式：名字.github.io\n3. 终端在blog文件路径下输入：cnmp install --save hexo-deployer-git\n4. 终端输入：notepad _config.yml, 打开文件后修改最下面的Deployment部分：\n```\n# Deployment\n## Docs: https://hexo.io/docs/one-command-deployment\ndeploy:\n  type: 'git'\n  repo: https://github.com/Maverick-Yza/Maverick-Yza-github.io.git\n  branch: master\n```\n5. 终端输入：hexo d （部署到远端）\n### 过程所学\n1. 打开终端输入的左边显示的是你当前操作所在的路径\n   2. cd 后跟你想更改的路径\n   3. pwd —— 查看当前路径\n2. 每次更新完博客后需要在终端输入：hexo clean、hexo g、hexo d。使其保存并部署到远端","source":"_posts/2025-9-10.md","raw":"---\ntitle: 2025.9.10\ndate: 2025-09-10 18:21:33\ntags:\n---\n# Overview\n今天跟随视频一步步搭建了属于自己的博客，我把整个过程以及所学记录下来\n\n## 流程\n### 安装hexo\n1. 安装nodejs\n2. 打开终端并切换到root用户（输入了 sudo su）\n   - 该过程中打开 设置 -> 系统 -> 开发者选项 -> 开启“启用Sudo” -> 选择运行模式“内联”\n   - 之后重启终端 -> 输入sudo whoami -> 显示 laptop-lv27uskg\\admin【表示当前以管理员权限执行了命令（laptop-lv27uskg 是我的计算机名，admin 是我的用户名），这说明 sudo 配置生效了。】\n3. 终端输入 node -v 和 npm -v（查看版本）\n   - 输入npm -v后显示:\n```powershell\n https:/go.microsoft.com/fwlink/?LinkID=135170 中的 about_Execution_Policies。\n所在位置 行:1 字符: 1\n+ npm -v\n+ ~~~\n    + CategoryInfo          : SecurityError: (:) []，PSSecurityException\n    + FullyQualifiedErrorId : UnauthorizedAccess\n```\n    - 终端输入：Get-ExecutionPolicy，显示：Restricted\n    - 终端输入：Set-ExecutionPolicy RemoteSigned\n    - 再次执行 Get-ExecutionPolicy，确认显示为 RemoteSigned\n    - 上面的步骤设置允许运行本地创建的脚本，同时对从网络下载的脚本进行安全检查，是比较平衡的安全策略。\n4. 终端输入：npm install -g cnpm --registry=https://registry.npmmirror.com\n   - 安装成功，接下来就可以使用 cnpm 命令来替代 npm 进行包管理了\n5. 终端输入：cnpm install -g hexo-cli\n   - 安装好hexo了\n6. 在E盘创建blog文件夹，并通过终端cd操作将路径改到创建好的blog文件夹\n7. 终端输入：sudo hexo init, 报错：\n```powershell\nINFO  Cloning hexo-starter https://github.com/hexojs/hexo-starter.git\n'git' 不是内部或外部命令，也不是可运行的程序\n或批处理文件。\nWARN  git clone failed. Copying data instead\nFATAL Something's wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.html\nError: EPERM: operation not permitted, mkdir 'E:\\'\n    at async Object.mkdir (node:internal/fs/promises:860:10)\n```\n    - 报错原因是缺少 Git 环境\n    - 通过Git 官网 下载 Windows 版本\n8. 再次输入：sudo hexo init\n   - 此时Hexo 已经成功初始化完成，现在博客项目基础框架已经搭建好了\n   - 输入：ls （查看当前目录下的文件）\n### 将博客部署到远端的GitHub上公开使用\n1. 创建并登录GitHub账号\n2. 创建一个仓库(repository)\n    - 注意：创建仓库时起的名字必须符合格式：名字.github.io\n3. 终端在blog文件路径下输入：cnmp install --save hexo-deployer-git\n4. 终端输入：notepad _config.yml, 打开文件后修改最下面的Deployment部分：\n```\n# Deployment\n## Docs: https://hexo.io/docs/one-command-deployment\ndeploy:\n  type: 'git'\n  repo: https://github.com/Maverick-Yza/Maverick-Yza-github.io.git\n  branch: master\n```\n5. 终端输入：hexo d （部署到远端）\n### 过程所学\n1. 打开终端输入的左边显示的是你当前操作所在的路径\n   2. cd 后跟你想更改的路径\n   3. pwd —— 查看当前路径\n2. 每次更新完博客后需要在终端输入：hexo clean、hexo g、hexo d。使其保存并部署到远端","slug":"2025-9-10","published":1,"updated":"2025-11-18T19:39:17.141Z","comments":1,"layout":"post","photos":[],"_id":"cuidST83bSlJNZq9bjdU9gbWP","content":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><p>今天跟随视频一步步搭建了属于自己的博客，我把整个过程以及所学记录下来</p>\n<h2 id=\"流程\"><a href=\"#流程\" class=\"headerlink\" title=\"流程\"></a>流程</h2><h3 id=\"安装hexo\"><a href=\"#安装hexo\" class=\"headerlink\" title=\"安装hexo\"></a>安装hexo</h3><ol>\n<li>安装nodejs</li>\n<li>打开终端并切换到root用户（输入了 sudo su）<ul>\n<li>该过程中打开 设置 -&gt; 系统 -&gt; 开发者选项 -&gt; 开启“启用Sudo” -&gt; 选择运行模式“内联”</li>\n<li>之后重启终端 -&gt; 输入sudo whoami -&gt; 显示 laptop-lv27uskg\\admin【表示当前以管理员权限执行了命令（laptop-lv27uskg 是我的计算机名，admin 是我的用户名），这说明 sudo 配置生效了。】</li>\n</ul>\n</li>\n<li>终端输入 node -v 和 npm -v（查看版本）<ul>\n<li>输入npm -v后显示:</li>\n</ul>\n</li>\n</ol>\n<figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> https:/go.microsoft.com/fwlink/?LinkID=<span class=\"number\">135170</span> 中的 about_Execution_Policies。</span><br><span class=\"line\">所在位置 行:<span class=\"number\">1</span> 字符: <span class=\"number\">1</span></span><br><span class=\"line\">+ npm <span class=\"literal\">-v</span></span><br><span class=\"line\">+ ~~~</span><br><span class=\"line\">    + CategoryInfo          : SecurityError: (:) []，PSSecurityException</span><br><span class=\"line\">    + FullyQualifiedErrorId : UnauthorizedAccess</span><br></pre></td></tr></table></figure>\n<pre><code>- 终端输入：Get-ExecutionPolicy，显示：Restricted\n- 终端输入：Set-ExecutionPolicy RemoteSigned\n- 再次执行 Get-ExecutionPolicy，确认显示为 RemoteSigned\n- 上面的步骤设置允许运行本地创建的脚本，同时对从网络下载的脚本进行安全检查，是比较平衡的安全策略。\n</code></pre>\n<ol start=\"4\">\n<li>终端输入：npm install -g cnpm –registry&#x3D;<a href=\"https://registry.npmmirror.com/\">https://registry.npmmirror.com</a><ul>\n<li>安装成功，接下来就可以使用 cnpm 命令来替代 npm 进行包管理了</li>\n</ul>\n</li>\n<li>终端输入：cnpm install -g hexo-cli<ul>\n<li>安装好hexo了</li>\n</ul>\n</li>\n<li>在E盘创建blog文件夹，并通过终端cd操作将路径改到创建好的blog文件夹</li>\n<li>终端输入：sudo hexo init, 报错：</li>\n</ol>\n<figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">INFO  Cloning hexo<span class=\"literal\">-starter</span> https://github.com/hexojs/hexo<span class=\"literal\">-starter</span>.git</span><br><span class=\"line\"><span class=\"string\">&#x27;git&#x27;</span> 不是内部或外部命令，也不是可运行的程序</span><br><span class=\"line\">或批处理文件。</span><br><span class=\"line\">WARN  git clone failed. Copying <span class=\"keyword\">data</span> instead</span><br><span class=\"line\">FATAL Something<span class=\"string\">&#x27;s wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.html</span></span><br><span class=\"line\"><span class=\"string\">Error: EPERM: operation not permitted, mkdir &#x27;</span>E:\\<span class=\"string\">&#x27;</span></span><br><span class=\"line\"><span class=\"string\">    at async Object.mkdir (node:internal/fs/promises:860:10)</span></span><br></pre></td></tr></table></figure>\n<pre><code>- 报错原因是缺少 Git 环境\n- 通过Git 官网 下载 Windows 版本\n</code></pre>\n<ol start=\"8\">\n<li>再次输入：sudo hexo init<ul>\n<li>此时Hexo 已经成功初始化完成，现在博客项目基础框架已经搭建好了</li>\n<li>输入：ls （查看当前目录下的文件）</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"将博客部署到远端的GitHub上公开使用\"><a href=\"#将博客部署到远端的GitHub上公开使用\" class=\"headerlink\" title=\"将博客部署到远端的GitHub上公开使用\"></a>将博客部署到远端的GitHub上公开使用</h3><ol>\n<li>创建并登录GitHub账号</li>\n<li>创建一个仓库(repository)<ul>\n<li>注意：创建仓库时起的名字必须符合格式：名字.github.io</li>\n</ul>\n</li>\n<li>终端在blog文件路径下输入：cnmp install –save hexo-deployer-git</li>\n<li>终端输入：notepad _config.yml, 打开文件后修改最下面的Deployment部分：</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Deployment</span><br><span class=\"line\">## Docs: https://hexo.io/docs/one-command-deployment</span><br><span class=\"line\">deploy:</span><br><span class=\"line\">  type: &#x27;git&#x27;</span><br><span class=\"line\">  repo: https://github.com/Maverick-Yza/Maverick-Yza-github.io.git</span><br><span class=\"line\">  branch: master</span><br></pre></td></tr></table></figure>\n<ol start=\"5\">\n<li>终端输入：hexo d （部署到远端）</li>\n</ol>\n<h3 id=\"过程所学\"><a href=\"#过程所学\" class=\"headerlink\" title=\"过程所学\"></a>过程所学</h3><ol>\n<li>打开终端输入的左边显示的是你当前操作所在的路径<ol start=\"2\">\n<li>cd 后跟你想更改的路径</li>\n<li>pwd —— 查看当前路径</li>\n</ol>\n</li>\n<li>每次更新完博客后需要在终端输入：hexo clean、hexo g、hexo d。使其保存并部署到远端</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><p>今天跟随视频一步步搭建了属于自己的博客，我把整个过程以及所学记录下来</p>\n<h2 id=\"流程\"><a href=\"#流程\" class=\"headerlink\" title=\"流程\"></a>流程</h2><h3 id=\"安装hexo\"><a href=\"#安装hexo\" class=\"headerlink\" title=\"安装hexo\"></a>安装hexo</h3><ol>\n<li>安装nodejs</li>\n<li>打开终端并切换到root用户（输入了 sudo su）<ul>\n<li>该过程中打开 设置 -&gt; 系统 -&gt; 开发者选项 -&gt; 开启“启用Sudo” -&gt; 选择运行模式“内联”</li>\n<li>之后重启终端 -&gt; 输入sudo whoami -&gt; 显示 laptop-lv27uskg\\admin【表示当前以管理员权限执行了命令（laptop-lv27uskg 是我的计算机名，admin 是我的用户名），这说明 sudo 配置生效了。】</li>\n</ul>\n</li>\n<li>终端输入 node -v 和 npm -v（查看版本）<ul>\n<li>输入npm -v后显示:</li>\n</ul>\n</li>\n</ol>\n<figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> https:/go.microsoft.com/fwlink/?LinkID=<span class=\"number\">135170</span> 中的 about_Execution_Policies。</span><br><span class=\"line\">所在位置 行:<span class=\"number\">1</span> 字符: <span class=\"number\">1</span></span><br><span class=\"line\">+ npm <span class=\"literal\">-v</span></span><br><span class=\"line\">+ ~~~</span><br><span class=\"line\">    + CategoryInfo          : SecurityError: (:) []，PSSecurityException</span><br><span class=\"line\">    + FullyQualifiedErrorId : UnauthorizedAccess</span><br></pre></td></tr></table></figure>\n<pre><code>- 终端输入：Get-ExecutionPolicy，显示：Restricted\n- 终端输入：Set-ExecutionPolicy RemoteSigned\n- 再次执行 Get-ExecutionPolicy，确认显示为 RemoteSigned\n- 上面的步骤设置允许运行本地创建的脚本，同时对从网络下载的脚本进行安全检查，是比较平衡的安全策略。\n</code></pre>\n<ol start=\"4\">\n<li>终端输入：npm install -g cnpm –registry&#x3D;<a href=\"https://registry.npmmirror.com/\">https://registry.npmmirror.com</a><ul>\n<li>安装成功，接下来就可以使用 cnpm 命令来替代 npm 进行包管理了</li>\n</ul>\n</li>\n<li>终端输入：cnpm install -g hexo-cli<ul>\n<li>安装好hexo了</li>\n</ul>\n</li>\n<li>在E盘创建blog文件夹，并通过终端cd操作将路径改到创建好的blog文件夹</li>\n<li>终端输入：sudo hexo init, 报错：</li>\n</ol>\n<figure class=\"highlight powershell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">INFO  Cloning hexo<span class=\"literal\">-starter</span> https://github.com/hexojs/hexo<span class=\"literal\">-starter</span>.git</span><br><span class=\"line\"><span class=\"string\">&#x27;git&#x27;</span> 不是内部或外部命令，也不是可运行的程序</span><br><span class=\"line\">或批处理文件。</span><br><span class=\"line\">WARN  git clone failed. Copying <span class=\"keyword\">data</span> instead</span><br><span class=\"line\">FATAL Something<span class=\"string\">&#x27;s wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.html</span></span><br><span class=\"line\"><span class=\"string\">Error: EPERM: operation not permitted, mkdir &#x27;</span>E:\\<span class=\"string\">&#x27;</span></span><br><span class=\"line\"><span class=\"string\">    at async Object.mkdir (node:internal/fs/promises:860:10)</span></span><br></pre></td></tr></table></figure>\n<pre><code>- 报错原因是缺少 Git 环境\n- 通过Git 官网 下载 Windows 版本\n</code></pre>\n<ol start=\"8\">\n<li>再次输入：sudo hexo init<ul>\n<li>此时Hexo 已经成功初始化完成，现在博客项目基础框架已经搭建好了</li>\n<li>输入：ls （查看当前目录下的文件）</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"将博客部署到远端的GitHub上公开使用\"><a href=\"#将博客部署到远端的GitHub上公开使用\" class=\"headerlink\" title=\"将博客部署到远端的GitHub上公开使用\"></a>将博客部署到远端的GitHub上公开使用</h3><ol>\n<li>创建并登录GitHub账号</li>\n<li>创建一个仓库(repository)<ul>\n<li>注意：创建仓库时起的名字必须符合格式：名字.github.io</li>\n</ul>\n</li>\n<li>终端在blog文件路径下输入：cnmp install –save hexo-deployer-git</li>\n<li>终端输入：notepad _config.yml, 打开文件后修改最下面的Deployment部分：</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># Deployment</span><br><span class=\"line\">## Docs: https://hexo.io/docs/one-command-deployment</span><br><span class=\"line\">deploy:</span><br><span class=\"line\">  type: &#x27;git&#x27;</span><br><span class=\"line\">  repo: https://github.com/Maverick-Yza/Maverick-Yza-github.io.git</span><br><span class=\"line\">  branch: master</span><br></pre></td></tr></table></figure>\n<ol start=\"5\">\n<li>终端输入：hexo d （部署到远端）</li>\n</ol>\n<h3 id=\"过程所学\"><a href=\"#过程所学\" class=\"headerlink\" title=\"过程所学\"></a>过程所学</h3><ol>\n<li>打开终端输入的左边显示的是你当前操作所在的路径<ol start=\"2\">\n<li>cd 后跟你想更改的路径</li>\n<li>pwd —— 查看当前路径</li>\n</ol>\n</li>\n<li>每次更新完博客后需要在终端输入：hexo clean、hexo g、hexo d。使其保存并部署到远端</li>\n</ol>\n"},{"title":"Game_On","date":"2025-09-10T07:59:34.000Z","_content":"# 这既是结束亦是开始\n\n### 今天通过跟随一个视频一步步搭建了属于我的博客，虽然过程中只是盲目的跟随人家的脚步，都不知道自己做的这些每一步都有什么用，但是过程中我也收获了很多，在此之前没有怎么用过电脑的终端，每次打开电脑终端总觉得自己不可能看得懂这一行行的代码，但是今天通过搭建博客我渐渐能看懂一些了，就像：pwd-查看当前路径；cd-进入某个盘和文件中···。我开始对这些代码感兴趣了。  \n### 我计划将此博客作为我蜕变的见证，我将会在学习、生活、社交等每一个方面提升自己，只为不辜负那些支持与信任。所以我会在此博客中发布一系列有关我提升种子，相信总有一天会收获相应的花朵。\n\n\n","source":"_posts/Game-On.md","raw":"---\ntitle: Game_On\ndate: 2025-09-10 15:59:34\ntags:\n---\n# 这既是结束亦是开始\n\n### 今天通过跟随一个视频一步步搭建了属于我的博客，虽然过程中只是盲目的跟随人家的脚步，都不知道自己做的这些每一步都有什么用，但是过程中我也收获了很多，在此之前没有怎么用过电脑的终端，每次打开电脑终端总觉得自己不可能看得懂这一行行的代码，但是今天通过搭建博客我渐渐能看懂一些了，就像：pwd-查看当前路径；cd-进入某个盘和文件中···。我开始对这些代码感兴趣了。  \n### 我计划将此博客作为我蜕变的见证，我将会在学习、生活、社交等每一个方面提升自己，只为不辜负那些支持与信任。所以我会在此博客中发布一系列有关我提升种子，相信总有一天会收获相应的花朵。\n\n\n","slug":"Game-On","published":1,"updated":"2025-11-18T19:39:17.152Z","comments":1,"layout":"post","photos":[],"_id":"cuidjq0TFiJXDZS1CGjLBaa9K","content":"<h1 id=\"这既是结束亦是开始\"><a href=\"#这既是结束亦是开始\" class=\"headerlink\" title=\"这既是结束亦是开始\"></a>这既是结束亦是开始</h1><h3 id=\"今天通过跟随一个视频一步步搭建了属于我的博客，虽然过程中只是盲目的跟随人家的脚步，都不知道自己做的这些每一步都有什么用，但是过程中我也收获了很多，在此之前没有怎么用过电脑的终端，每次打开电脑终端总觉得自己不可能看得懂这一行行的代码，但是今天通过搭建博客我渐渐能看懂一些了，就像：pwd-查看当前路径；cd-进入某个盘和文件中···。我开始对这些代码感兴趣了。\"><a href=\"#今天通过跟随一个视频一步步搭建了属于我的博客，虽然过程中只是盲目的跟随人家的脚步，都不知道自己做的这些每一步都有什么用，但是过程中我也收获了很多，在此之前没有怎么用过电脑的终端，每次打开电脑终端总觉得自己不可能看得懂这一行行的代码，但是今天通过搭建博客我渐渐能看懂一些了，就像：pwd-查看当前路径；cd-进入某个盘和文件中···。我开始对这些代码感兴趣了。\" class=\"headerlink\" title=\"今天通过跟随一个视频一步步搭建了属于我的博客，虽然过程中只是盲目的跟随人家的脚步，都不知道自己做的这些每一步都有什么用，但是过程中我也收获了很多，在此之前没有怎么用过电脑的终端，每次打开电脑终端总觉得自己不可能看得懂这一行行的代码，但是今天通过搭建博客我渐渐能看懂一些了，就像：pwd-查看当前路径；cd-进入某个盘和文件中···。我开始对这些代码感兴趣了。\"></a>今天通过跟随一个视频一步步搭建了属于我的博客，虽然过程中只是盲目的跟随人家的脚步，都不知道自己做的这些每一步都有什么用，但是过程中我也收获了很多，在此之前没有怎么用过电脑的终端，每次打开电脑终端总觉得自己不可能看得懂这一行行的代码，但是今天通过搭建博客我渐渐能看懂一些了，就像：pwd-查看当前路径；cd-进入某个盘和文件中···。我开始对这些代码感兴趣了。</h3><h3 id=\"我计划将此博客作为我蜕变的见证，我将会在学习、生活、社交等每一个方面提升自己，只为不辜负那些支持与信任。所以我会在此博客中发布一系列有关我提升种子，相信总有一天会收获相应的花朵。\"><a href=\"#我计划将此博客作为我蜕变的见证，我将会在学习、生活、社交等每一个方面提升自己，只为不辜负那些支持与信任。所以我会在此博客中发布一系列有关我提升种子，相信总有一天会收获相应的花朵。\" class=\"headerlink\" title=\"我计划将此博客作为我蜕变的见证，我将会在学习、生活、社交等每一个方面提升自己，只为不辜负那些支持与信任。所以我会在此博客中发布一系列有关我提升种子，相信总有一天会收获相应的花朵。\"></a>我计划将此博客作为我蜕变的见证，我将会在学习、生活、社交等每一个方面提升自己，只为不辜负那些支持与信任。所以我会在此博客中发布一系列有关我提升种子，相信总有一天会收获相应的花朵。</h3>","excerpt":"","more":"<h1 id=\"这既是结束亦是开始\"><a href=\"#这既是结束亦是开始\" class=\"headerlink\" title=\"这既是结束亦是开始\"></a>这既是结束亦是开始</h1><h3 id=\"今天通过跟随一个视频一步步搭建了属于我的博客，虽然过程中只是盲目的跟随人家的脚步，都不知道自己做的这些每一步都有什么用，但是过程中我也收获了很多，在此之前没有怎么用过电脑的终端，每次打开电脑终端总觉得自己不可能看得懂这一行行的代码，但是今天通过搭建博客我渐渐能看懂一些了，就像：pwd-查看当前路径；cd-进入某个盘和文件中···。我开始对这些代码感兴趣了。\"><a href=\"#今天通过跟随一个视频一步步搭建了属于我的博客，虽然过程中只是盲目的跟随人家的脚步，都不知道自己做的这些每一步都有什么用，但是过程中我也收获了很多，在此之前没有怎么用过电脑的终端，每次打开电脑终端总觉得自己不可能看得懂这一行行的代码，但是今天通过搭建博客我渐渐能看懂一些了，就像：pwd-查看当前路径；cd-进入某个盘和文件中···。我开始对这些代码感兴趣了。\" class=\"headerlink\" title=\"今天通过跟随一个视频一步步搭建了属于我的博客，虽然过程中只是盲目的跟随人家的脚步，都不知道自己做的这些每一步都有什么用，但是过程中我也收获了很多，在此之前没有怎么用过电脑的终端，每次打开电脑终端总觉得自己不可能看得懂这一行行的代码，但是今天通过搭建博客我渐渐能看懂一些了，就像：pwd-查看当前路径；cd-进入某个盘和文件中···。我开始对这些代码感兴趣了。\"></a>今天通过跟随一个视频一步步搭建了属于我的博客，虽然过程中只是盲目的跟随人家的脚步，都不知道自己做的这些每一步都有什么用，但是过程中我也收获了很多，在此之前没有怎么用过电脑的终端，每次打开电脑终端总觉得自己不可能看得懂这一行行的代码，但是今天通过搭建博客我渐渐能看懂一些了，就像：pwd-查看当前路径；cd-进入某个盘和文件中···。我开始对这些代码感兴趣了。</h3><h3 id=\"我计划将此博客作为我蜕变的见证，我将会在学习、生活、社交等每一个方面提升自己，只为不辜负那些支持与信任。所以我会在此博客中发布一系列有关我提升种子，相信总有一天会收获相应的花朵。\"><a href=\"#我计划将此博客作为我蜕变的见证，我将会在学习、生活、社交等每一个方面提升自己，只为不辜负那些支持与信任。所以我会在此博客中发布一系列有关我提升种子，相信总有一天会收获相应的花朵。\" class=\"headerlink\" title=\"我计划将此博客作为我蜕变的见证，我将会在学习、生活、社交等每一个方面提升自己，只为不辜负那些支持与信任。所以我会在此博客中发布一系列有关我提升种子，相信总有一天会收获相应的花朵。\"></a>我计划将此博客作为我蜕变的见证，我将会在学习、生活、社交等每一个方面提升自己，只为不辜负那些支持与信任。所以我会在此博客中发布一系列有关我提升种子，相信总有一天会收获相应的花朵。</h3>"},{"title":"2025.9.23","date":"2025-09-23T10:33:06.000Z","_content":"# Summary\n1. Python学习（封装、继承、多态、单例模式、魔法方法&属性）\n2. **之后的学习计划：算法与数据结构 --> 计算机基础知识（数据库、计算机组成原理、操作系统、计算机网络）\n3. 沟通完节目灯光安排\n4. 每日英语","source":"_posts/2025-9-23.md","raw":"---\ntitle: 2025.9.23\ndate: 2025-09-23 18:33:06\ntags:\n---\n# Summary\n1. Python学习（封装、继承、多态、单例模式、魔法方法&属性）\n2. **之后的学习计划：算法与数据结构 --> 计算机基础知识（数据库、计算机组成原理、操作系统、计算机网络）\n3. 沟通完节目灯光安排\n4. 每日英语","slug":"2025-9-23","published":1,"updated":"2025-11-18T19:39:17.130Z","comments":1,"layout":"post","photos":[],"_id":"cuidDKO7pcz_rDZbaTEsc4pGx","content":"<h1 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h1><ol>\n<li>Python学习（封装、继承、多态、单例模式、魔法方法&amp;属性）</li>\n<li>**之后的学习计划：算法与数据结构 –&gt; 计算机基础知识（数据库、计算机组成原理、操作系统、计算机网络）</li>\n<li>沟通完节目灯光安排</li>\n<li>每日英语</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h1><ol>\n<li>Python学习（封装、继承、多态、单例模式、魔法方法&amp;属性）</li>\n<li>**之后的学习计划：算法与数据结构 –&gt; 计算机基础知识（数据库、计算机组成原理、操作系统、计算机网络）</li>\n<li>沟通完节目灯光安排</li>\n<li>每日英语</li>\n</ol>\n"},{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","slug":"hello-world","published":1,"date":"2025-11-19T21:38:16.079Z","updated":"2025-11-18T19:39:17.099Z","comments":1,"layout":"post","photos":[],"_id":"cuidJV83XPDW_4dwuU3gO7Pv9","content":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n","excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n"},{"title":"2025.9.22","date":"2025-09-22T04:04:09.000Z","_content":"# Overview\n1. 9.17--9.21 总结与反思\n2. 学习了本周以及假期的课件\n\n## 9.17--9.21 总结与反思\n过去几天有点放纵了，还是有点没克服因为一些身体上的原因而不影响状态，而且接下来必须做到睡前不看手机，并且需要注意在进行了比较剧烈的运动的当晚就要早点休息以防影响第二天的状态。  \n过去几天摩羯身上也接连出现状况导致心情有点受影响，不过现在我感觉我找到了担心的分界线，其实主要就是保持毛发和环境的干净，除此之外只要不是持续几天的异常都没必要太过担心。  \n不过还是有一些好事情发生的，比如：上周末通知了我的节目被通过了，这次一定要不留遗憾的表演成功；此外各个社团的招新也结束了，这周总算可以开始社团活动了，期待遇见优秀的人吧；最后唯一在过去几天里完成不错的就是依旧保持每天背单词了，总算一天不落的完成了开学打卡，期待下一次累签。\n## 课件知识点\n\n### 数据科学（统计）\n**核心目标：想要找到一个适合工业数据的模型，以实现两大功能\n—— `解释数据背后的现象、对新场景下的行为进行预测`**\n1. 数据拟合核心内容\n   2. 拟合目标：建立自变量（如质量）与因变量（如距离）的关系，找到最优拟合曲线\n   3. 拟合评估指标：\n      4. 最小二乘法目标函数：计算观测值与预测值差值平方和，最小化该值即最小化方差\n      5. 平均均方误差：衡量模型拟合误差，公式为（误差总和/数据长度）\n      6. 决定系数R²：反映模型对数据变异性的解释能力，越接近1代表模型越能解释数据的底层逻辑\n   7. 多项式拟合时用到的拟合工具：Python pylab库函数，polyfit（求n次多项式系数，如n=1求直线系数）、polyval（根据模型计算预测值）\n8. 模型选择的关键矛盾：拟合优度与泛化能力\n   9. 高阶模型的 “虚假优势” -- 虽然在案例中的16 次多项式在训练数据上的R^2最高，但其并不能代表模型对新数据的适配能力（即泛化能力）\n      10. 矛盾现象的根本原因：源于训练误差的局限性 -- 训练误差仅反映模型在训练数据上的表现\n      11. **过度拟合**的本质：当模型复杂度（如多项式次数）过高时，会 “拟合噪声而非数据底层规律”\n12. 泛化能力的评估方法：交叉验证\n    13. 核心逻辑：将数据分为训练集与测试集，用训练集构建模型后，在测试集上验证性能，测试误差更能反映泛化能力，且通常大于训练误差。\n    14. 常用交叉验证策略：\n        15. 留一法（Leave-one-out）：适用于小数据集，每次从原始数据中剔除 1 个样本作为测试集，剩余作为训练集，重复所有样本后取测试结果平均值。\n        16. k 折交叉验证（k-fold）：适用于大数据集，将数据划分为 k 个等规模子集，每次用 k-1 个子集训练，1 个子集测试，循环 k 次后评估。\n        17. 重复随机抽样验证：每次从数据中随机抽取 20%-50% 作为测试集，剩余为训练集，重复 k 次后取平均结果，降低随机划分带来的偏差。\n18. 模型复杂度的平衡策略\n    19. 理论指导优先若存在明确理论（如胡克定律表明弹簧受力与位移呈线性关系），即使高阶模型（如二次多项式）在训练数据上R^2更高，仍应优先选择符合理论的模型\n    20. `无理论时的搜索流程：`\n        21. 从低复杂度模型（如 1 次多项式）开始，在训练集上拟合\n        22. 在测试集上验证并记录R^2\n        23. 逐步提升模型复杂度，重复拟合与验证\n        24. 当测试集R^2开始下降时，停止提升复杂度，选择此前最优模型\n25. 课程核心结论 \n    26. 线性回归的价值：可用于构建从自变量到因变量的映射模型，实现对未知数据的预测，但需结合模型复杂度控制\n    27. `R^2的合理使用：R^2是评估模型拟合优度的重要指标，但 “更高的R^2” 不代表 “更优模型”，需警惕过度拟合导致的泛化能力下降`\n    28. 模型选择三原则：\n        29. 优先参考数据底层理论（如物理定律、业务逻辑）\n        30. 用交叉验证验证模型泛化能力\n        31. `在性能相近时，选择更简单的模型`\n\n### 概率\n1. Number systems（数字系统）：\n   2. natural numbers ℕ，integers ℤ，rational numbers ℚ，real numbers ℝ\n3. Closure（闭包）：\n   4. Definition：Let 𝑋 be a set of numbers. We say that 𝑋 is：\n      5. closed under addition（加法封闭） if 𝑥 + 𝑦 ∈ 𝑋 whenever 𝑥，𝑦 ∈ 𝑋\n      6. closed under multiplication（乘法封闭） if 𝑥𝑦 ∈ 𝑋 whenever 𝑥，𝑦 ∈ 𝑋\n      7. closed under subtraction（减法封闭） if 𝑥 − 𝑦 ∈ 𝑋 whenever 𝑥，𝑦 ∈ 𝑋\n      8. closed under division（除法封闭） if 𝑥/𝑦 ∈ 𝑋 whenever 𝑥，𝑦 ∈ 𝑋 and 𝑦 ≠ 0\n   9. 注意：要证明一个集合在某个运算下不是闭的，只要给出一个精心挑选的例子（反例）就足够了。但要证明它是闭包的，则需要一个一般的论证\n   10. `一个严格的证明必须从定义开始`\n11. Permutations（排列）\n    12. Definition：A permutation of objects is an arrangement of these objects in a row `in some order`\n    13. Theorem 1:The number of permutations, or ordered arrangements, of 𝑛 `distinct` objects is 𝑛(𝑛 − 1)(𝑛 − 2) ⋯ 2 ⋅ 1 = 𝑛!\n    14. `Theorem 2:If 𝑛 objects consisting of 𝑐 classes of identical objects with size 𝑛1 , 𝑛2 , ⋯ , 𝑛C such that 𝑛1 + 𝑛2 + ⋯ + 𝑛C = 𝑛 , then the number of permutations of these 𝑛 objects is：𝑛! / 𝑛1!𝑛2!···𝑛C!`\n        15. 多重集合的排列数公式的理解：如果n个元素完全不同，那么它们的排列数是 n!。现在的情况是：n个元素分为c类，同类元素完全相同，第i类有ni个元素，此时，“同类元素的重复” 会导致 “原本不同的排列被算成了相同的”，所以要除以每一类重复元素内部的排列数\n    16. Theorem 3：The number of permutations, or ordered arrangements, of 𝑛 distinct objects taken 𝑟 at a time , where 𝑟 ≤ 𝑛, is given by：𝑃(n,r) = n(n-1)(n-2)···(n-r+1) = n! / (n-r)!\n17. Combinations（组合）\n    18. Theorem:Suppose we are now interested in the number of subsets of size 𝑟, where 𝑟 ≤ 𝑛, that can be chosen from 𝑛 distinct objects. The order of elements in each subset makes no difference.We denote as C(n,r) = n! / r!(n-r)!\n    19. 注意：C(n,r) = C(n,n-r)\n20. Probability of Counting:Permutations and combinations can be used in finding probabilities.\n","source":"_posts/2025-9-22.md","raw":"---\ntitle: 2025.9.22\ndate: 2025-09-22 12:04:09\ntags:\n---\n# Overview\n1. 9.17--9.21 总结与反思\n2. 学习了本周以及假期的课件\n\n## 9.17--9.21 总结与反思\n过去几天有点放纵了，还是有点没克服因为一些身体上的原因而不影响状态，而且接下来必须做到睡前不看手机，并且需要注意在进行了比较剧烈的运动的当晚就要早点休息以防影响第二天的状态。  \n过去几天摩羯身上也接连出现状况导致心情有点受影响，不过现在我感觉我找到了担心的分界线，其实主要就是保持毛发和环境的干净，除此之外只要不是持续几天的异常都没必要太过担心。  \n不过还是有一些好事情发生的，比如：上周末通知了我的节目被通过了，这次一定要不留遗憾的表演成功；此外各个社团的招新也结束了，这周总算可以开始社团活动了，期待遇见优秀的人吧；最后唯一在过去几天里完成不错的就是依旧保持每天背单词了，总算一天不落的完成了开学打卡，期待下一次累签。\n## 课件知识点\n\n### 数据科学（统计）\n**核心目标：想要找到一个适合工业数据的模型，以实现两大功能\n—— `解释数据背后的现象、对新场景下的行为进行预测`**\n1. 数据拟合核心内容\n   2. 拟合目标：建立自变量（如质量）与因变量（如距离）的关系，找到最优拟合曲线\n   3. 拟合评估指标：\n      4. 最小二乘法目标函数：计算观测值与预测值差值平方和，最小化该值即最小化方差\n      5. 平均均方误差：衡量模型拟合误差，公式为（误差总和/数据长度）\n      6. 决定系数R²：反映模型对数据变异性的解释能力，越接近1代表模型越能解释数据的底层逻辑\n   7. 多项式拟合时用到的拟合工具：Python pylab库函数，polyfit（求n次多项式系数，如n=1求直线系数）、polyval（根据模型计算预测值）\n8. 模型选择的关键矛盾：拟合优度与泛化能力\n   9. 高阶模型的 “虚假优势” -- 虽然在案例中的16 次多项式在训练数据上的R^2最高，但其并不能代表模型对新数据的适配能力（即泛化能力）\n      10. 矛盾现象的根本原因：源于训练误差的局限性 -- 训练误差仅反映模型在训练数据上的表现\n      11. **过度拟合**的本质：当模型复杂度（如多项式次数）过高时，会 “拟合噪声而非数据底层规律”\n12. 泛化能力的评估方法：交叉验证\n    13. 核心逻辑：将数据分为训练集与测试集，用训练集构建模型后，在测试集上验证性能，测试误差更能反映泛化能力，且通常大于训练误差。\n    14. 常用交叉验证策略：\n        15. 留一法（Leave-one-out）：适用于小数据集，每次从原始数据中剔除 1 个样本作为测试集，剩余作为训练集，重复所有样本后取测试结果平均值。\n        16. k 折交叉验证（k-fold）：适用于大数据集，将数据划分为 k 个等规模子集，每次用 k-1 个子集训练，1 个子集测试，循环 k 次后评估。\n        17. 重复随机抽样验证：每次从数据中随机抽取 20%-50% 作为测试集，剩余为训练集，重复 k 次后取平均结果，降低随机划分带来的偏差。\n18. 模型复杂度的平衡策略\n    19. 理论指导优先若存在明确理论（如胡克定律表明弹簧受力与位移呈线性关系），即使高阶模型（如二次多项式）在训练数据上R^2更高，仍应优先选择符合理论的模型\n    20. `无理论时的搜索流程：`\n        21. 从低复杂度模型（如 1 次多项式）开始，在训练集上拟合\n        22. 在测试集上验证并记录R^2\n        23. 逐步提升模型复杂度，重复拟合与验证\n        24. 当测试集R^2开始下降时，停止提升复杂度，选择此前最优模型\n25. 课程核心结论 \n    26. 线性回归的价值：可用于构建从自变量到因变量的映射模型，实现对未知数据的预测，但需结合模型复杂度控制\n    27. `R^2的合理使用：R^2是评估模型拟合优度的重要指标，但 “更高的R^2” 不代表 “更优模型”，需警惕过度拟合导致的泛化能力下降`\n    28. 模型选择三原则：\n        29. 优先参考数据底层理论（如物理定律、业务逻辑）\n        30. 用交叉验证验证模型泛化能力\n        31. `在性能相近时，选择更简单的模型`\n\n### 概率\n1. Number systems（数字系统）：\n   2. natural numbers ℕ，integers ℤ，rational numbers ℚ，real numbers ℝ\n3. Closure（闭包）：\n   4. Definition：Let 𝑋 be a set of numbers. We say that 𝑋 is：\n      5. closed under addition（加法封闭） if 𝑥 + 𝑦 ∈ 𝑋 whenever 𝑥，𝑦 ∈ 𝑋\n      6. closed under multiplication（乘法封闭） if 𝑥𝑦 ∈ 𝑋 whenever 𝑥，𝑦 ∈ 𝑋\n      7. closed under subtraction（减法封闭） if 𝑥 − 𝑦 ∈ 𝑋 whenever 𝑥，𝑦 ∈ 𝑋\n      8. closed under division（除法封闭） if 𝑥/𝑦 ∈ 𝑋 whenever 𝑥，𝑦 ∈ 𝑋 and 𝑦 ≠ 0\n   9. 注意：要证明一个集合在某个运算下不是闭的，只要给出一个精心挑选的例子（反例）就足够了。但要证明它是闭包的，则需要一个一般的论证\n   10. `一个严格的证明必须从定义开始`\n11. Permutations（排列）\n    12. Definition：A permutation of objects is an arrangement of these objects in a row `in some order`\n    13. Theorem 1:The number of permutations, or ordered arrangements, of 𝑛 `distinct` objects is 𝑛(𝑛 − 1)(𝑛 − 2) ⋯ 2 ⋅ 1 = 𝑛!\n    14. `Theorem 2:If 𝑛 objects consisting of 𝑐 classes of identical objects with size 𝑛1 , 𝑛2 , ⋯ , 𝑛C such that 𝑛1 + 𝑛2 + ⋯ + 𝑛C = 𝑛 , then the number of permutations of these 𝑛 objects is：𝑛! / 𝑛1!𝑛2!···𝑛C!`\n        15. 多重集合的排列数公式的理解：如果n个元素完全不同，那么它们的排列数是 n!。现在的情况是：n个元素分为c类，同类元素完全相同，第i类有ni个元素，此时，“同类元素的重复” 会导致 “原本不同的排列被算成了相同的”，所以要除以每一类重复元素内部的排列数\n    16. Theorem 3：The number of permutations, or ordered arrangements, of 𝑛 distinct objects taken 𝑟 at a time , where 𝑟 ≤ 𝑛, is given by：𝑃(n,r) = n(n-1)(n-2)···(n-r+1) = n! / (n-r)!\n17. Combinations（组合）\n    18. Theorem:Suppose we are now interested in the number of subsets of size 𝑟, where 𝑟 ≤ 𝑛, that can be chosen from 𝑛 distinct objects. The order of elements in each subset makes no difference.We denote as C(n,r) = n! / r!(n-r)!\n    19. 注意：C(n,r) = C(n,n-r)\n20. Probability of Counting:Permutations and combinations can be used in finding probabilities.\n","slug":"2025-9-22","published":1,"updated":"2025-11-18T19:39:17.132Z","comments":1,"layout":"post","photos":[],"_id":"cuidQrAS1AwkDBQKGRbpYFPEf","content":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>9.17–9.21 总结与反思</li>\n<li>学习了本周以及假期的课件</li>\n</ol>\n<h2 id=\"9-17–9-21-总结与反思\"><a href=\"#9-17–9-21-总结与反思\" class=\"headerlink\" title=\"9.17–9.21 总结与反思\"></a>9.17–9.21 总结与反思</h2><p>过去几天有点放纵了，还是有点没克服因为一些身体上的原因而不影响状态，而且接下来必须做到睡前不看手机，并且需要注意在进行了比较剧烈的运动的当晚就要早点休息以防影响第二天的状态。<br>过去几天摩羯身上也接连出现状况导致心情有点受影响，不过现在我感觉我找到了担心的分界线，其实主要就是保持毛发和环境的干净，除此之外只要不是持续几天的异常都没必要太过担心。<br>不过还是有一些好事情发生的，比如：上周末通知了我的节目被通过了，这次一定要不留遗憾的表演成功；此外各个社团的招新也结束了，这周总算可以开始社团活动了，期待遇见优秀的人吧；最后唯一在过去几天里完成不错的就是依旧保持每天背单词了，总算一天不落的完成了开学打卡，期待下一次累签。</p>\n<h2 id=\"课件知识点\"><a href=\"#课件知识点\" class=\"headerlink\" title=\"课件知识点\"></a>课件知识点</h2><h3 id=\"数据科学（统计）\"><a href=\"#数据科学（统计）\" class=\"headerlink\" title=\"数据科学（统计）\"></a>数据科学（统计）</h3><p><strong>核心目标：想要找到一个适合工业数据的模型，以实现两大功能<br>—— <code>解释数据背后的现象、对新场景下的行为进行预测</code></strong></p>\n<ol>\n<li>数据拟合核心内容<ol start=\"2\">\n<li>拟合目标：建立自变量（如质量）与因变量（如距离）的关系，找到最优拟合曲线</li>\n<li>拟合评估指标：<ol start=\"4\">\n<li>最小二乘法目标函数：计算观测值与预测值差值平方和，最小化该值即最小化方差</li>\n<li>平均均方误差：衡量模型拟合误差，公式为（误差总和&#x2F;数据长度）</li>\n<li>决定系数R²：反映模型对数据变异性的解释能力，越接近1代表模型越能解释数据的底层逻辑</li>\n</ol>\n</li>\n<li>多项式拟合时用到的拟合工具：Python pylab库函数，polyfit（求n次多项式系数，如n&#x3D;1求直线系数）、polyval（根据模型计算预测值）</li>\n</ol>\n</li>\n<li>模型选择的关键矛盾：拟合优度与泛化能力<ol start=\"9\">\n<li>高阶模型的 “虚假优势” – 虽然在案例中的16 次多项式在训练数据上的R^2最高，但其并不能代表模型对新数据的适配能力（即泛化能力）<ol start=\"10\">\n<li>矛盾现象的根本原因：源于训练误差的局限性 – 训练误差仅反映模型在训练数据上的表现</li>\n<li><strong>过度拟合</strong>的本质：当模型复杂度（如多项式次数）过高时，会 “拟合噪声而非数据底层规律”</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>泛化能力的评估方法：交叉验证<ol start=\"13\">\n<li>核心逻辑：将数据分为训练集与测试集，用训练集构建模型后，在测试集上验证性能，测试误差更能反映泛化能力，且通常大于训练误差。</li>\n<li>常用交叉验证策略：<ol start=\"15\">\n<li>留一法（Leave-one-out）：适用于小数据集，每次从原始数据中剔除 1 个样本作为测试集，剩余作为训练集，重复所有样本后取测试结果平均值。</li>\n<li>k 折交叉验证（k-fold）：适用于大数据集，将数据划分为 k 个等规模子集，每次用 k-1 个子集训练，1 个子集测试，循环 k 次后评估。</li>\n<li>重复随机抽样验证：每次从数据中随机抽取 20%-50% 作为测试集，剩余为训练集，重复 k 次后取平均结果，降低随机划分带来的偏差。</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>模型复杂度的平衡策略<ol start=\"19\">\n<li>理论指导优先若存在明确理论（如胡克定律表明弹簧受力与位移呈线性关系），即使高阶模型（如二次多项式）在训练数据上R^2更高，仍应优先选择符合理论的模型</li>\n<li><code>无理论时的搜索流程：</code><ol start=\"21\">\n<li>从低复杂度模型（如 1 次多项式）开始，在训练集上拟合</li>\n<li>在测试集上验证并记录R^2</li>\n<li>逐步提升模型复杂度，重复拟合与验证</li>\n<li>当测试集R^2开始下降时，停止提升复杂度，选择此前最优模型</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>课程核心结论 <ol start=\"26\">\n<li>线性回归的价值：可用于构建从自变量到因变量的映射模型，实现对未知数据的预测，但需结合模型复杂度控制</li>\n<li><code>R^2的合理使用：R^2是评估模型拟合优度的重要指标，但 “更高的R^2” 不代表 “更优模型”，需警惕过度拟合导致的泛化能力下降</code></li>\n<li>模型选择三原则：<ol start=\"29\">\n<li>优先参考数据底层理论（如物理定律、业务逻辑）</li>\n<li>用交叉验证验证模型泛化能力</li>\n<li><code>在性能相近时，选择更简单的模型</code></li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h3 id=\"概率\"><a href=\"#概率\" class=\"headerlink\" title=\"概率\"></a>概率</h3><ol>\n<li>Number systems（数字系统）：<ol start=\"2\">\n<li>natural numbers ℕ，integers ℤ，rational numbers ℚ，real numbers ℝ</li>\n</ol>\n</li>\n<li>Closure（闭包）：<ol start=\"4\">\n<li>Definition：Let 𝑋 be a set of numbers. We say that 𝑋 is：<ol start=\"5\">\n<li>closed under addition（加法封闭） if 𝑥 + 𝑦 ∈ 𝑋 whenever 𝑥，𝑦 ∈ 𝑋</li>\n<li>closed under multiplication（乘法封闭） if 𝑥𝑦 ∈ 𝑋 whenever 𝑥，𝑦 ∈ 𝑋</li>\n<li>closed under subtraction（减法封闭） if 𝑥 − 𝑦 ∈ 𝑋 whenever 𝑥，𝑦 ∈ 𝑋</li>\n<li>closed under division（除法封闭） if 𝑥&#x2F;𝑦 ∈ 𝑋 whenever 𝑥，𝑦 ∈ 𝑋 and 𝑦 ≠ 0</li>\n</ol>\n</li>\n<li>注意：要证明一个集合在某个运算下不是闭的，只要给出一个精心挑选的例子（反例）就足够了。但要证明它是闭包的，则需要一个一般的论证</li>\n<li><code>一个严格的证明必须从定义开始</code></li>\n</ol>\n</li>\n<li>Permutations（排列）<ol start=\"12\">\n<li>Definition：A permutation of objects is an arrangement of these objects in a row <code>in some order</code></li>\n<li>Theorem 1:The number of permutations, or ordered arrangements, of 𝑛 <code>distinct</code> objects is 𝑛(𝑛 − 1)(𝑛 − 2) ⋯ 2 ⋅ 1 &#x3D; 𝑛!</li>\n<li><code>Theorem 2:If 𝑛 objects consisting of 𝑐 classes of identical objects with size 𝑛1 , 𝑛2 , ⋯ , 𝑛C such that 𝑛1 + 𝑛2 + ⋯ + 𝑛C = 𝑛 , then the number of permutations of these 𝑛 objects is：𝑛! / 𝑛1!𝑛2!···𝑛C!</code><ol start=\"15\">\n<li>多重集合的排列数公式的理解：如果n个元素完全不同，那么它们的排列数是 n!。现在的情况是：n个元素分为c类，同类元素完全相同，第i类有ni个元素，此时，“同类元素的重复” 会导致 “原本不同的排列被算成了相同的”，所以要除以每一类重复元素内部的排列数</li>\n</ol>\n</li>\n<li>Theorem 3：The number of permutations, or ordered arrangements, of 𝑛 distinct objects taken 𝑟 at a time , where 𝑟 ≤ 𝑛, is given by：𝑃(n,r) &#x3D; n(n-1)(n-2)···(n-r+1) &#x3D; n! &#x2F; (n-r)!</li>\n</ol>\n</li>\n<li>Combinations（组合）<ol start=\"18\">\n<li>Theorem:Suppose we are now interested in the number of subsets of size 𝑟, where 𝑟 ≤ 𝑛, that can be chosen from 𝑛 distinct objects. The order of elements in each subset makes no difference.We denote as C(n,r) &#x3D; n! &#x2F; r!(n-r)!</li>\n<li>注意：C(n,r) &#x3D; C(n,n-r)</li>\n</ol>\n</li>\n<li>Probability of Counting:Permutations and combinations can be used in finding probabilities.</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h1><ol>\n<li>9.17–9.21 总结与反思</li>\n<li>学习了本周以及假期的课件</li>\n</ol>\n<h2 id=\"9-17–9-21-总结与反思\"><a href=\"#9-17–9-21-总结与反思\" class=\"headerlink\" title=\"9.17–9.21 总结与反思\"></a>9.17–9.21 总结与反思</h2><p>过去几天有点放纵了，还是有点没克服因为一些身体上的原因而不影响状态，而且接下来必须做到睡前不看手机，并且需要注意在进行了比较剧烈的运动的当晚就要早点休息以防影响第二天的状态。<br>过去几天摩羯身上也接连出现状况导致心情有点受影响，不过现在我感觉我找到了担心的分界线，其实主要就是保持毛发和环境的干净，除此之外只要不是持续几天的异常都没必要太过担心。<br>不过还是有一些好事情发生的，比如：上周末通知了我的节目被通过了，这次一定要不留遗憾的表演成功；此外各个社团的招新也结束了，这周总算可以开始社团活动了，期待遇见优秀的人吧；最后唯一在过去几天里完成不错的就是依旧保持每天背单词了，总算一天不落的完成了开学打卡，期待下一次累签。</p>\n<h2 id=\"课件知识点\"><a href=\"#课件知识点\" class=\"headerlink\" title=\"课件知识点\"></a>课件知识点</h2><h3 id=\"数据科学（统计）\"><a href=\"#数据科学（统计）\" class=\"headerlink\" title=\"数据科学（统计）\"></a>数据科学（统计）</h3><p><strong>核心目标：想要找到一个适合工业数据的模型，以实现两大功能<br>—— <code>解释数据背后的现象、对新场景下的行为进行预测</code></strong></p>\n<ol>\n<li>数据拟合核心内容<ol start=\"2\">\n<li>拟合目标：建立自变量（如质量）与因变量（如距离）的关系，找到最优拟合曲线</li>\n<li>拟合评估指标：<ol start=\"4\">\n<li>最小二乘法目标函数：计算观测值与预测值差值平方和，最小化该值即最小化方差</li>\n<li>平均均方误差：衡量模型拟合误差，公式为（误差总和&#x2F;数据长度）</li>\n<li>决定系数R²：反映模型对数据变异性的解释能力，越接近1代表模型越能解释数据的底层逻辑</li>\n</ol>\n</li>\n<li>多项式拟合时用到的拟合工具：Python pylab库函数，polyfit（求n次多项式系数，如n&#x3D;1求直线系数）、polyval（根据模型计算预测值）</li>\n</ol>\n</li>\n<li>模型选择的关键矛盾：拟合优度与泛化能力<ol start=\"9\">\n<li>高阶模型的 “虚假优势” – 虽然在案例中的16 次多项式在训练数据上的R^2最高，但其并不能代表模型对新数据的适配能力（即泛化能力）<ol start=\"10\">\n<li>矛盾现象的根本原因：源于训练误差的局限性 – 训练误差仅反映模型在训练数据上的表现</li>\n<li><strong>过度拟合</strong>的本质：当模型复杂度（如多项式次数）过高时，会 “拟合噪声而非数据底层规律”</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>泛化能力的评估方法：交叉验证<ol start=\"13\">\n<li>核心逻辑：将数据分为训练集与测试集，用训练集构建模型后，在测试集上验证性能，测试误差更能反映泛化能力，且通常大于训练误差。</li>\n<li>常用交叉验证策略：<ol start=\"15\">\n<li>留一法（Leave-one-out）：适用于小数据集，每次从原始数据中剔除 1 个样本作为测试集，剩余作为训练集，重复所有样本后取测试结果平均值。</li>\n<li>k 折交叉验证（k-fold）：适用于大数据集，将数据划分为 k 个等规模子集，每次用 k-1 个子集训练，1 个子集测试，循环 k 次后评估。</li>\n<li>重复随机抽样验证：每次从数据中随机抽取 20%-50% 作为测试集，剩余为训练集，重复 k 次后取平均结果，降低随机划分带来的偏差。</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>模型复杂度的平衡策略<ol start=\"19\">\n<li>理论指导优先若存在明确理论（如胡克定律表明弹簧受力与位移呈线性关系），即使高阶模型（如二次多项式）在训练数据上R^2更高，仍应优先选择符合理论的模型</li>\n<li><code>无理论时的搜索流程：</code><ol start=\"21\">\n<li>从低复杂度模型（如 1 次多项式）开始，在训练集上拟合</li>\n<li>在测试集上验证并记录R^2</li>\n<li>逐步提升模型复杂度，重复拟合与验证</li>\n<li>当测试集R^2开始下降时，停止提升复杂度，选择此前最优模型</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>课程核心结论 <ol start=\"26\">\n<li>线性回归的价值：可用于构建从自变量到因变量的映射模型，实现对未知数据的预测，但需结合模型复杂度控制</li>\n<li><code>R^2的合理使用：R^2是评估模型拟合优度的重要指标，但 “更高的R^2” 不代表 “更优模型”，需警惕过度拟合导致的泛化能力下降</code></li>\n<li>模型选择三原则：<ol start=\"29\">\n<li>优先参考数据底层理论（如物理定律、业务逻辑）</li>\n<li>用交叉验证验证模型泛化能力</li>\n<li><code>在性能相近时，选择更简单的模型</code></li>\n</ol>\n</li>\n</ol>\n</li>\n</ol>\n<h3 id=\"概率\"><a href=\"#概率\" class=\"headerlink\" title=\"概率\"></a>概率</h3><ol>\n<li>Number systems（数字系统）：<ol start=\"2\">\n<li>natural numbers ℕ，integers ℤ，rational numbers ℚ，real numbers ℝ</li>\n</ol>\n</li>\n<li>Closure（闭包）：<ol start=\"4\">\n<li>Definition：Let 𝑋 be a set of numbers. We say that 𝑋 is：<ol start=\"5\">\n<li>closed under addition（加法封闭） if 𝑥 + 𝑦 ∈ 𝑋 whenever 𝑥，𝑦 ∈ 𝑋</li>\n<li>closed under multiplication（乘法封闭） if 𝑥𝑦 ∈ 𝑋 whenever 𝑥，𝑦 ∈ 𝑋</li>\n<li>closed under subtraction（减法封闭） if 𝑥 − 𝑦 ∈ 𝑋 whenever 𝑥，𝑦 ∈ 𝑋</li>\n<li>closed under division（除法封闭） if 𝑥&#x2F;𝑦 ∈ 𝑋 whenever 𝑥，𝑦 ∈ 𝑋 and 𝑦 ≠ 0</li>\n</ol>\n</li>\n<li>注意：要证明一个集合在某个运算下不是闭的，只要给出一个精心挑选的例子（反例）就足够了。但要证明它是闭包的，则需要一个一般的论证</li>\n<li><code>一个严格的证明必须从定义开始</code></li>\n</ol>\n</li>\n<li>Permutations（排列）<ol start=\"12\">\n<li>Definition：A permutation of objects is an arrangement of these objects in a row <code>in some order</code></li>\n<li>Theorem 1:The number of permutations, or ordered arrangements, of 𝑛 <code>distinct</code> objects is 𝑛(𝑛 − 1)(𝑛 − 2) ⋯ 2 ⋅ 1 &#x3D; 𝑛!</li>\n<li><code>Theorem 2:If 𝑛 objects consisting of 𝑐 classes of identical objects with size 𝑛1 , 𝑛2 , ⋯ , 𝑛C such that 𝑛1 + 𝑛2 + ⋯ + 𝑛C = 𝑛 , then the number of permutations of these 𝑛 objects is：𝑛! / 𝑛1!𝑛2!···𝑛C!</code><ol start=\"15\">\n<li>多重集合的排列数公式的理解：如果n个元素完全不同，那么它们的排列数是 n!。现在的情况是：n个元素分为c类，同类元素完全相同，第i类有ni个元素，此时，“同类元素的重复” 会导致 “原本不同的排列被算成了相同的”，所以要除以每一类重复元素内部的排列数</li>\n</ol>\n</li>\n<li>Theorem 3：The number of permutations, or ordered arrangements, of 𝑛 distinct objects taken 𝑟 at a time , where 𝑟 ≤ 𝑛, is given by：𝑃(n,r) &#x3D; n(n-1)(n-2)···(n-r+1) &#x3D; n! &#x2F; (n-r)!</li>\n</ol>\n</li>\n<li>Combinations（组合）<ol start=\"18\">\n<li>Theorem:Suppose we are now interested in the number of subsets of size 𝑟, where 𝑟 ≤ 𝑛, that can be chosen from 𝑛 distinct objects. The order of elements in each subset makes no difference.We denote as C(n,r) &#x3D; n! &#x2F; r!(n-r)!</li>\n<li>注意：C(n,r) &#x3D; C(n,n-r)</li>\n</ol>\n</li>\n<li>Probability of Counting:Permutations and combinations can be used in finding probabilities.</li>\n</ol>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[],"Tag":[]}}