---
title: 2025.10.20
date: 2025-10-20 08:41:01
tags:
---
# Overview
1. 周末总结
2. 今日学习笔记
3. 今日总结

## 周末总结
这周末暂时放松了一下，不过还是弹了琴，新曲子虽然有点难以掌握节奏，但以及整体过了一遍了，感觉再练几次就能弹下来了；原本打算带摩羯出去逛逛，结果起床完了，不过还是决定周末下午出去，结果刚骑到公园走了几步就开始下雨了，无奈之下只能提前回家了，没事以后有的是机会

## 学习笔记

### 数据科学（统计）
1. 机器学习核心范式
   1. 机器学习的核心逻辑： “观察训练数据→推断数据生成过程→预测测试数据”
   2. 监督学习：给定特征 / 标签对，学习预测未知输入标签的规则
   3. 无监督学习：仅给定特征向量（无标签），将样本分组为 “自然聚类”，聚类是无监督学习的核心任务之一
2. 聚类（Clustering）的本质：优化问题，目标是找到聚类划分 C 以最小化聚类内差异（dissimilarity (C)），但需满足约束条件：
   1. 若不设约束，会导致每个样本单独成簇（无意义），因此需添加约束，如 “聚类间最小距离” 或 “指定聚类数量（k）”
   2. 核心逻辑：“大而差” 的聚类比 “小而差” 的聚类更差，需平衡聚类大小与内部一致性
3. 层次聚类（Hierarchical Clustering）
   1. 核心步骤：
      1. 初始状态：每个样本单独成簇，N 个样本对应 N 个簇
      2. 迭代合并：找到最相似（距离最近）的一对簇，合并为 1 个簇，簇数减少 1
      3. 终止条件：所有样本合并为 1 个簇（大小为 N）
   2. 簇间距离（链接度量）（Linkage Metrics）
      1. 单链接（Single-linkage）：簇间距离 = 两簇中任意样本的最短距离
      2. 全链接（Complete-linkage）：簇间距离 = 两簇中任意样本的最长距离  （`注意：比较的是谁的最长距离最小，而不是最大`）
      3. 平均链接（Average-linkage）：簇间距离 = 两簇中所有样本的平均距离
   3. 方法特点：
      1. 优势：可通过树状图选择聚类数量；结果具有确定性；链接准则灵活
      2. 劣势：速度慢，朴素算法时间复杂度为n^3，仅部分链接准则存在n^2优化算法
4. K-means 聚类
   1. 算法流程：
      1. 随机选k个样本作为初始值
      2. 将每个样本分配至最近的质心，形成k个簇
      3. 计算每个簇的新质心（簇内所有样本特征的平均值）
      4. 质心是否变化？
      5. 质心变化则返回第二步；质心不变则输出聚类结果
   2. 时间复杂度：knd （n：样本总数；d：计算单个样本与质心距离的耗时）
   3. 关键问题与解决办法：
      1. 问题1：k 值选择不当	
      2. 解决办法：
         1. 利用领域先验知识（如已知 5 种细菌，设 k=5）；
         2. 测试不同 k 值，评估聚类质量；
         3. 对部分数据运行层次聚类辅助选 k
      3. 问题2：依赖初始质心
      4. 解决办法：尝试多组随机初始质心，计算每组结果的差异，选择差异最小的结果作为最终聚类
5. 聚类评估方法
   1. 核心评估指标：总差异（dissimilarity）
      1. 聚类质量通过 “总差异” 衡量，计算公式为：dissimilarity(clusters) = ∑ c∈clusters variability(c)
      2. 其中variability(c)（簇内差异）= 簇内所有样本到该簇质心的距离平方和。总差异越小，聚类质量越好（簇内样本越集中）
   2. 代码实现核心函数
      1. dissimilarity(clusters)：计算所有簇的总差异
      2. trykmeans(examples, numClusters, numTrials)：运行 numTrials 次 K-means，返回总差异最小的结果
      3. printClustering(clustering)：输出各簇样本数与阳性率，辅助业务评估
6. 关键问题
   1. 层次聚类与 K-means 聚类在适用场景和性能上有何核心差异？如何根据数据特点选择这两种方法？
      1. 适用场景：
         1. 层次聚类适用于**无需提前确定聚类数量的场景**（可通过树状图灵活选 k），或对聚类结果确定性要求高的场景（如小样本数据的精细分组）
         2. K-means 适用于**已知聚类数量范围**（如通过领域知识确定 k）、追求高效聚类的场景（如大样本数据）
      2. 性能：
         1. 层次聚类速度慢（朴素算法n^3），仅小样本适用
         2. K-means 速度快（单次迭代 knd），可处理大样本，但结果依赖初始质心（需多组测试）
      3. **选择依据：**
         1. 选择层次聚类：若数据量小、需灵活选 k；；若需确定簇间关系（如层级结构）
         2. 选择K-means：若数据量大、已知 k 范围或可通过测试选 k；若需避免局部最优
   2. 在 K-means 聚类中，特征归一化（如 Z-Scaling）为何对聚类结果影响显著？
      1. 特征归一化的核心作用是消除特征量纲差异导致的权重失衡，避免数值范围大的特征主导距离计算（K-means 依赖样本与质心的距离）
      2. 未归一化的问题：患者数据中，“年龄”（如 20-80 岁）与 “ST 段抬高”（0/1 二元变量）数值范围差异极大，未归一化时，“年龄” 对距离的贡献远大于 “ST 段抬高”，导致聚类仅依赖年龄，无法捕捉 ST 段抬高（与心脏病风险直接相关）的特征，因此 k=2 时两簇阳性率接近（33.05% vs 33.33%），无实际意义
      3. 归一化的作用：Z-Scaling 后，所有特征均值为 0、标准差为 1，各特征对距离的贡献权重一致，聚类可同时考虑心率、既往病史、年龄、ST 段抬高的综合影响，k=2 时出现高风险簇（26 人，阳性率 69.23%）与低风险簇（224 人，阳性率 29.02%），聚类结果符合业务逻辑（高风险患者被有效区分），证明归一化能让 K-means 捕捉关键特征关联，提升聚类实用性
   3. 在聚类分析中，如何科学选择 K 值（聚类数量）？
      1. k 值选择方法：
         1. 利用领域先验知识（如已知 5 种细菌类型，直接设 k=5）
         2. 测试多组 k 值，通过 “总差异（dissimilarity）” 评估（总差异越小，聚类内一致性越高），同时结合业务指标（如患者聚类的阳性率）
         3. 对部分数据运行层次聚类，通过树状图的 “距离断点” 辅助确定 k 值范围
      2. k 值选择与业务目标的关系（以患者数据为例）：
         1. 若业务目标是`快速区分高 / 低风险患者`：选 k=2，此时高风险簇（26 人，69.23% 阳性率）与低风险簇（224 人，29.02% 阳性率）界限清晰，可快速筛选高风险人群
         2. 若业务目标是`细分高风险患者（如制定个性化干预方案）`：选 k=4 或 k=6，k=4 时出现两个高风险簇（69.23%、71.05%），k=6 时高风险簇进一步细分（最高 77.78% 阳性率），可针对不同高风险 subgroup 分析特征（如是否有多次既往心脏病发作），制定精准方案
         3. 若 k 值过大（如 k=10）：可能导致簇样本量过小（如部分簇仅 5-10 人），阳性率波动大（无统计意义），不符合 “稳定分组” 的业务需求，因此 k 值需在 “细分程度” 与 “簇稳定性” 间平衡

## 今日总结
1. 编程学习（进程）
2. 看书一章
3. 参加每周城市之旅活动，今天主要认识了一下小组成员以及了解了之后的安排，加了一个成员的微信，感觉通过介绍会是个不错的伙伴
4. 把之前没学完的ppt学完了
5. 英语学习